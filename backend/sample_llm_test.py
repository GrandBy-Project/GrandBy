#!/usr/bin/env python3
"""
Simple LLM Test with Sample Conversations
Test LLM prompts with predefined sample conversations
"""

import os
import sys
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append('/app')

from app.services.ai_call.llm_service import LLMService

def get_sample_conversations():
    """Get predefined sample conversations for testing."""
    
    # Sample Conversation 1: Positive mood, daily activities
    conversation_1 = [
        {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì¢‹ì•„ìš”."},
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ê¸°ë¶„ì´ ì¢‹ìœ¼ì‹œë‹¤ë‹ˆ ì €ë„ ê¸°ì©ë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ì–´ë–¤ ì¼ì´ ìˆìœ¼ì…¨ë‚˜ìš”?"},
        {"role": "user", "content": "ì•„ì¹¨ì— ì‚°ì±…ì„ í–ˆì–´ìš”. ë‚ ì”¨ê°€ ì •ë§ ì¢‹ì•˜ì–´ìš”."},
        {"role": "assistant", "content": "ì‚°ì±…í•˜ì…¨êµ°ìš”! ì¢‹ì€ ë‚ ì”¨ì— ì‚°ì±…í•˜ì‹œë©´ ê¸°ë¶„ì´ ë” ì¢‹ì•„ì§€ì‹œê² ì–´ìš”. ì–´ë””ë¡œ ì‚°ì±…í•˜ì…¨ë‚˜ìš”?"},
        {"role": "user", "content": "ê³µì›ì— ê°”ì–´ìš”. ê½ƒë„ í”¼ì–´ìˆê³  ìƒˆì†Œë¦¬ë„ ë“¤ë ¤ì„œ ì •ë§ ì¢‹ì•˜ì–´ìš”."},
        {"role": "assistant", "content": "ê³µì›ì—ì„œ ìì—°ì„ ë§Œë½í•˜ì…¨êµ°ìš”! ê·¸ëŸ° í™˜ê²½ì—ì„œ ì‚°ì±…í•˜ì‹œë©´ ë§ˆìŒë„ í¸ì•ˆí•´ì§€ì‹œê² ì–´ìš”."},
        {"role": "user", "content": "ë„¤, ê·¸ë¦¬ê³  ë‚´ì¼ì€ ë”¸ì´ë‘ ì ì‹¬ì„ ë¨¹ê¸°ë¡œ í–ˆì–´ìš”."},
        {"role": "assistant", "content": "ë”¸ë‹˜ê³¼ ì ì‹¬ ì•½ì†ì´ ìˆìœ¼ì‹œêµ°ìš”! ì–´ë–¤ ìŒì‹ì„ ë“œì‹¤ ì˜ˆì •ì¸ê°€ìš”?"},
        {"role": "user", "content": "ë”¸ì´ ì¢‹ì•„í•˜ëŠ” í•œì‹ì§‘ì— ê°ˆ ê±°ì˜ˆìš”. ë²Œì¨ë¶€í„° ê¸°ëŒ€ë¼ìš”."}
    ]
    
    # Sample Conversation 2: Health concerns, family
    conversation_2 = [
        {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ì¢€ í”¼ê³¤í•´ìš”."},
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! í”¼ê³¤í•˜ì‹œêµ°ìš”. í˜¹ì‹œ ëª¸ì´ ì•„í”„ì‹ ê°€ìš”?"},
        {"role": "user", "content": "ì–´ì œ ë°¤ì— ì ì„ ì˜ ëª» ì¤ì–´ìš”. ë¬´ë¦ì´ ì•„íŒŒì„œìš”."},
        {"role": "assistant", "content": "ë¬´ë¦ì´ ì•„í”„ì‹œêµ°ìš”. ë§ì´ ë¶ˆí¸í•˜ì…¨ì„ ê²ƒ ê°™ì•„ìš”. ì•½ì€ ë“œì…¨ë‚˜ìš”?"},
        {"role": "user", "content": "ì•„ì¹¨ì— ì§„í†µì œë¥¼ ë¨¹ì—ˆì–´ìš”. ê·¸ë˜ë„ ì•„ì§ ì¢€ ì•„íŒŒìš”."},
        {"role": "assistant", "content": "ì§„í†µì œë¥¼ ë“œì…¨êµ°ìš”. ë¬´ë¦ì´ ì•„í”„ë©´ ì›€ì§ì´ê¸°ë„ í˜ë“œì‹¤ ê²ƒ ê°™ì•„ìš”. ì˜¤ëŠ˜ì€ í‘¹ ì‰¬ì‹œëŠ” ê²Œ ì¢‹ê² ì–´ìš”."},
        {"role": "user", "content": "ë„¤, ì˜¤ëŠ˜ì€ ì§‘ì—ì„œ ì‰¬ë ¤ê³  í•´ìš”. ì•„ë“¤ì´ ì „í™”í•´ì„œ ë‚´ì¼ ë³‘ì›ì— ê°™ì´ ê°€ìê³  í–ˆì–´ìš”."},
        {"role": "assistant", "content": "ì•„ë“œë‹˜ì´ ë³‘ì›ì— ê°™ì´ ê°€ìê³  í•˜ì…¨êµ°ìš”! ì •ë§ ë‹¤í–‰ì´ì—ìš”. ë¬´ë¦ ê²€ì‚¬ë¥¼ ë°›ìœ¼ì‹¤ ê±´ê°€ìš”?"},
        {"role": "user", "content": "ë„¤, ì •í˜•ì™¸ê³¼ì— ê°€ì„œ ë¬´ë¦ì„ ë´ë‹¬ë¼ê³  í•  ê±°ì˜ˆìš”. ì•„ë“¤ì´ ìˆì–´ì„œ ë§ˆìŒì´ ë“ ë“ í•´ìš”."}
    ]
    
    return [
        {
            "name": "Sample 1: Positive Day",
            "description": "Good mood, park walk, daughter lunch plan",
            "conversation": conversation_1
        },
        {
            "name": "Sample 2: Health Concern", 
            "description": "Tired, knee pain, hospital visit with son",
            "conversation": conversation_2
        }
    ]

def test_conversation(conversation_data, llm_service):
    """Test a single conversation with LLM."""
    print(f"\nğŸ“ Testing: {conversation_data['name']}")
    print(f"ğŸ“ Description: {conversation_data['description']}")
    print("=" * 50)
    
    # Display conversation content
    print(f"\nğŸ’¬ Conversation Content:")
    print("-" * 30)
    for i, msg in enumerate(conversation_data['conversation'], 1):
        speaker = "Elderly" if msg['role'] == "user" else "AI"
        print(f"{i}. {speaker}: {msg['content']}")
    print("-" * 30)
    
    # Generate LLM summary
    print(f"\nğŸ¤– Generating LLM Summary...")
    print("=" * 40)
    
    try:
        summary = llm_service.summarize_call_conversation(conversation_data['conversation'])
        
        print(f"âœ… Summary Generated Successfully!")
        print(f"\nğŸ“ Generated Summary:")
        print("-" * 30)
        print(summary)
        print("-" * 30)
        
        return summary
        
    except Exception as e:
        print(f"âŒ Summary Generation Failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """Main function"""
    print("ğŸš€ LLM Prompt Test with Sample Conversations")
    print("=" * 50)
    
    # Initialize LLM service
    try:
        llm_service = LLMService()
        print("âœ… LLM Service initialized successfully")
    except Exception as e:
        print(f"âŒ Failed to initialize LLM service: {e}")
        print("Make sure OPENAI_API_KEY is set in docker environment")
        return
    
    # Get sample conversations
    sample_conversations = get_sample_conversations()
    
    print(f"\nğŸ“‹ Available Sample Conversations:")
    for i, conv in enumerate(sample_conversations, 1):
        print(f"{i}. {conv['name']} - {conv['description']}")
    
    # Test all conversations
    print(f"\nğŸ§ª Testing all sample conversations...")
    print("=" * 50)
    
    results = []
    for conv_data in sample_conversations:
        result = test_conversation(conv_data, llm_service)
        results.append({
            'name': conv_data['name'],
            'summary': result
        })
    
    # Summary of results
    print(f"\nğŸ“Š Test Results Summary:")
    print("=" * 50)
    for i, result in enumerate(results, 1):
        print(f"\n{i}. {result['name']}")
        if result['summary']:
            print(f"   âœ… Success - Generated {len(result['summary'])} characters")
        else:
            print(f"   âŒ Failed")

if __name__ == "__main__":
    main()
