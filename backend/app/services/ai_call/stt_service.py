"""
STT (Speech-to-Text) ì„œë¹„ìŠ¤
OpenAI Whisper API ì‚¬ìš© + ì‹¤ì‹œê°„ ì²­í¬ ê¸°ë°˜ ì²˜ë¦¬ ì§€ì›
"""

from openai import OpenAI
from app.config import settings
import logging
import time
import tempfile
import os
import asyncio

logger = logging.getLogger(__name__)


class STTService:
    """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        # Whisper medium ëª¨ë¸ ì‚¬ìš© (ì •í™•ë„ì™€ ì†ë„ì˜ ê· í˜•)
        self.model = "whisper-1"  # OpenAI APIëŠ” whisper-1ìœ¼ë¡œ í†µì¼
        # ì‹¤ì‹œê°„ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„¤ì • (TwilioëŠ” 8kHz ì‚¬ìš©)
        self.min_chunk_size = 8000 * 2 * 0.5  # 8kHz, 16bit, ìµœì†Œ 0.5ì´ˆ
    
    def transcribe_audio(self, audio_file_path: str, language: str = "ko"):
        """
        ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì‹¤í–‰ ì‹œê°„ ì¸¡ì • í¬í•¨)
        
        Args:
            audio_file_path: ìŒì„± íŒŒì¼ ê²½ë¡œ (local or URL)
            language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸: ko - í•œêµ­ì–´)
        
        Returns:
            tuple: (ë³€í™˜ëœ í…ìŠ¤íŠ¸, ì‹¤í–‰ ì‹œê°„)
        """
        try:
            start_time = time.time()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
            logger.info(f"ğŸ¤ STT ë³€í™˜ ì‹œì‘: {audio_file_path}")
            
            with open(audio_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model=self.model,
                    file=audio_file,
                    language=language,
                    response_format="text"
                )
            
            elapsed_time = time.time() - start_time  # ì†Œìš” ì‹œê°„ ê³„ì‚°
            logger.info(f"âœ… STT ë³€í™˜ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
            logger.info(f"ğŸ“ ë³€í™˜ ê²°ê³¼: {transcript[:100]}...")
            
            return transcript, elapsed_time
        except Exception as e:
            logger.error(f"âŒ STT ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    async def transcribe_audio_chunk(self, audio_chunk: bytes, language: str = "ko"):
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ (ë¹„ë™ê¸° ì²˜ë¦¬)
        
        Twilio mulaw ì˜¤ë””ì˜¤ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤.
        ì‘ì€ ì²­í¬ëŠ” ìë™ìœ¼ë¡œ í•„í„°ë§ë˜ì–´ ë¶ˆí•„ìš”í•œ API í˜¸ì¶œì„ ë°©ì§€í•©ë‹ˆë‹¤.
        
        Args:
            audio_chunk: ì˜¤ë””ì˜¤ ë°ì´í„° ì²­í¬ (ë°”ì´íŠ¸ í˜•ì‹, WAV ê¶Œì¥)
            language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: "ko" - í•œêµ­ì–´)
        
        Returns:
            tuple: (ë³€í™˜ëœ í…ìŠ¤íŠ¸, ì‹¤í–‰ ì‹œê°„)
            - ì²­í¬ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ("", 0) ë°˜í™˜
        """
        try:
            start_time = time.time()
            
            # ì²­í¬ í¬ê¸° ê²€ì¦: ìµœì†Œ 0.5ì´ˆ ì´ìƒì˜ ì˜¤ë””ì˜¤ë§Œ ì²˜ë¦¬
            if len(audio_chunk) < self.min_chunk_size:
                logger.debug(f"â­ï¸  ì²­í¬ê°€ ë„ˆë¬´ ì‘ì•„ ê±´ë„ˆëœ€: {len(audio_chunk)} bytes (ìµœì†Œ: {self.min_chunk_size})")
                return "", 0
            
            # ì„ì‹œ íŒŒì¼ ìƒì„± (Whisper APIëŠ” íŒŒì¼ ì…ë ¥ë§Œ ì§€ì›)
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_path = temp_file.name
                temp_file.write(audio_chunk)
            
            try:
                # ë¹„ë™ê¸°ë¡œ ë³€í™˜ ì‹¤í–‰ (ì´ë²¤íŠ¸ ë£¨í”„ ë¸”ë¡œí‚¹ ë°©ì§€)
                loop = asyncio.get_event_loop()
                transcript = await loop.run_in_executor(
                    None,
                    self._transcribe_file_sync,
                    temp_path,
                    language
                )
                
                elapsed_time = time.time() - start_time
                
                # ë³€í™˜ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ ë¡œê·¸ ì¶œë ¥
                if transcript and transcript.strip():
                    logger.info(f"ğŸ¤ [ì‹¤ì‹œê°„ STT] {transcript[:80]}... ({elapsed_time:.2f}ì´ˆ)")
                
                return transcript, elapsed_time
                
            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                    
        except Exception as e:
            logger.error(f"âŒ ì‹¤ì‹œê°„ STT ë³€í™˜ ì‹¤íŒ¨: {e}")
            return "", 0
    
    def _transcribe_file_sync(self, file_path: str, language: str) -> str:
        """
        ë™ê¸° ë°©ì‹ íŒŒì¼ ë³€í™˜ (executorì—ì„œ ì‹¤í–‰ìš©)
        
        ì´ ë©”ì„œë“œëŠ” ì§ì ‘ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”. 
        transcribe_audio_chunk()ì—ì„œ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        
        Args:
            file_path: ë³€í™˜í•  ìŒì„± íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ
        
        Returns:
            str: ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        with open(file_path, "rb") as audio_file:
            transcript = self.client.audio.transcriptions.create(
                model=self.model,
                file=audio_file,
                language=language,
                response_format="text"
            )
        return transcript
    
    def transcribe_audio_with_timestamps(self, audio_file_path: str):
        """
        íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ë³€í™˜
        
        Args:
            audio_file_path: ìŒì„± íŒŒì¼ ê²½ë¡œ
        
        Returns:
            dict: segmentsì™€ íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´
        """
        try:
            with open(audio_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model=self.model,
                    file=audio_file,
                    response_format="verbose_json",
                    timestamp_granularities=["segment"]
                )
            return transcript
        except Exception as e:
            logger.error(f"Failed to transcribe with timestamps: {e}")
            raise

