"""
STT (Speech-to-Text) ì„œë¹„ìŠ¤
OpenAI Whisper API ì‚¬ìš©
"""

from openai import OpenAI
from app.config import settings
import logging
import time

logger = logging.getLogger(__name__)


class STTService:
    """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        # Whisper medium ëª¨ë¸ ì‚¬ìš© (ì •í™•ë„ì™€ ì†ë„ì˜ ê· í˜•)
        self.model = "whisper-1"  # OpenAI APIëŠ” whisper-1ìœ¼ë¡œ í†µì¼
    
    def transcribe_audio(self, audio_file_path: str, language: str = "ko"):
        """
        ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì‹¤í–‰ ì‹œê°„ ì¸¡ì • í¬í•¨)
        
        Args:
            audio_file_path: ìŒì„± íŒŒì¼ ê²½ë¡œ (local or URL)
            language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸: ko - í•œêµ­ì–´)
        
        Returns:
            tuple: (ë³€í™˜ëœ í…ìŠ¤íŠ¸, ì‹¤í–‰ ì‹œê°„)
        """
        try:
            start_time = time.time()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
            logger.info(f"ğŸ¤ STT ë³€í™˜ ì‹œì‘: {audio_file_path}")
            
            with open(audio_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model=self.model,
                    file=audio_file,
                    language=language,
                    response_format="text"
                )
            
            elapsed_time = time.time() - start_time  # ì†Œìš” ì‹œê°„ ê³„ì‚°
            logger.info(f"âœ… STT ë³€í™˜ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
            logger.info(f"ğŸ“ ë³€í™˜ ê²°ê³¼: {transcript[:100]}...")
            
            return transcript, elapsed_time
        except Exception as e:
            logger.error(f"âŒ STT ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    def transcribe_audio_with_timestamps(self, audio_file_path: str):
        """
        íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ë³€í™˜
        
        Args:
            audio_file_path: ìŒì„± íŒŒì¼ ê²½ë¡œ
        
        Returns:
            dict: segmentsì™€ íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´
        """
        try:
            with open(audio_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model=self.model,
                    file=audio_file,
                    response_format="verbose_json",
                    timestamp_granularities=["segment"]
                )
            return transcript
        except Exception as e:
            logger.error(f"Failed to transcribe with timestamps: {e}")
            raise

