"""
STT (Speech-to-Text) ì„œë¹„ìŠ¤
Google Cloud Speech-to-Text + OpenAI Whisper + RTZR WebSocket STT ì§€ì›
"""

from openai import OpenAI
from google.cloud import speech
from google.api_core import retry
from app.config import settings
import logging
import time
import tempfile
import os
import asyncio
import io
import json
import requests
import base64

logger = logging.getLogger(__name__)


class STTService:
    """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì„œë¹„ìŠ¤ (Google, OpenAI, RTZR ì§€ì›)"""
    
    def __init__(self):
        # STT ì œê³µì ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì½ê¸°, ê¸°ë³¸ê°’: google)
        self.provider = getattr(settings, 'STT_PROVIDER', 'google').lower()
        logger.info(f"ğŸ” [STT Service] ì´ˆê¸°í™” ì‹œì‘ - ì œê³µì: {self.provider}")
        
        if self.provider == "google":
            logger.info(f"ğŸ” [STT Service] Google Cloud STT ì´ˆê¸°í™” ì¤‘...")
            self._init_google_stt()
        elif self.provider == "rtzr":
            logger.info(f"ğŸ” [STT Service] RTZR ìŠ¤íŠ¸ë¦¬ë° STT ì´ˆê¸°í™” ì¤‘...")
            self._init_rtzr_stt()
        else:  # openai
            logger.info(f"ğŸ” [STT Service] OpenAI Whisper ì´ˆê¸°í™” ì¤‘...")
            self._init_openai_whisper()
        
        logger.info(f"âœ… [STT Service] ì´ˆê¸°í™” ì™„ë£Œ: {self.provider.upper()}")
    
    def _init_google_stt(self):
        """Google Cloud STT ì´ˆê¸°í™”"""
        try:
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì¸ì¦ ì •ë³´ ì„¤ì •
            credentials_path = getattr(settings, 'GOOGLE_APPLICATION_CREDENTIALS', 'credentials/google-cloud-stt.json')
            if os.path.exists(credentials_path):
                os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path
                logger.info(f"âœ… Google Cloud ì¸ì¦ íŒŒì¼ ë¡œë“œ: {credentials_path}")
            
            self.google_client = speech.SpeechClient()
            
            # ê¸°ë³¸ ì¸ì‹ ì„¤ì •
            self.google_config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=8000,
                language_code="ko-KR",
                model="latest_short",  # ì „í™” í†µí™” ìµœì í™”
                enable_automatic_punctuation=True,
                use_enhanced=True,
                audio_channel_count=1,
                enable_word_time_offsets=True,  # ë‹¨ì–´ë³„ ì‹œê°„ ì •ë³´
                enable_word_confidence=True,    # ë‹¨ì–´ë³„ ì‹ ë¢°ë„
                max_alternatives=1,             # ìµœëŒ€ ëŒ€ì•ˆ ìˆ˜
            )
            
            logger.info("âœ… Google Cloud STT ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Google Cloud STT ì´ˆê¸°í™” ì‹¤íŒ¨, OpenAIë¡œ í´ë°±: {e}")
            self.provider = "openai"
            self._init_openai_whisper()
    
    def _init_openai_whisper(self):
        """OpenAI Whisper ì´ˆê¸°í™”"""
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = "whisper-1"
        self.min_chunk_size = 8000 * 2 * 0.5  # 8kHz, 16bit, ìµœì†Œ 0.5ì´ˆ
        logger.info("âœ… OpenAI Whisper ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_rtzr_stt(self):
        """RTZR ìŠ¤íŠ¸ë¦¬ë° STT ì´ˆê¸°í™”"""
        try:
            self.rtzr_client_id = settings.RTZR_CLIENT_ID
            self.rtzr_client_secret = settings.RTZR_CLIENT_SECRET
            self.rtzr_api_base = settings.RTZR_API_BASE
            
            if not self.rtzr_client_id or not self.rtzr_client_secret:
                raise ValueError("RTZR_CLIENT_IDì™€ RTZR_CLIENT_SECRETì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # â­ í† í° ìºì‹± ë³€ìˆ˜ ì´ˆê¸°í™”
            self._cached_token = None
            self._token_expires_at = 0
            
            # â­ WebSocket ì—°ê²° í’€ ì´ˆê¸°í™”
            self._rtzr_ws = None
            self._rtzr_ws_lock = asyncio.Lock()
            
            logger.info(f"âœ… RTZR STT ì´ˆê¸°í™” ì™„ë£Œ")
            logger.info(f"   - API Base: {self.rtzr_api_base}")
        except Exception as e:
            logger.error(f"âŒ RTZR STT ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def transcribe_audio(self, audio_file_path: str, language: str = "ko"):
        """
        ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì‹¤í–‰ ì‹œê°„ ì¸¡ì • í¬í•¨)
        
        Args:
            audio_file_path: ìŒì„± íŒŒì¼ ê²½ë¡œ (local or URL)
            language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸: ko - í•œêµ­ì–´)
        
        Returns:
            tuple: (ë³€í™˜ëœ í…ìŠ¤íŠ¸, ì‹¤í–‰ ì‹œê°„)
        """
        try:
            start_time = time.time()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
            logger.info(f"ğŸ¤ STT ë³€í™˜ ì‹œì‘: {audio_file_path}")
            
            with open(audio_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model=self.model,
                    file=audio_file,
                    language=language,
                    response_format="text",
                    temperature=0.0,  # ëœë¤ì„± ìµœì†Œí™”
                    prompt="ì´ ì…ë ¥ì€ ì „í™” ëŒ€í™”ì˜ í•œ ë¶€ë¶„ì…ë‹ˆë‹¤. ë§ì´ ì—†ìœ¼ë©´ ì•„ë¬´ê²ƒë„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”."
                )
            
            elapsed_time = time.time() - start_time  # ì†Œìš” ì‹œê°„ ê³„ì‚°
            logger.info(f"âœ… STT ë³€í™˜ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
            logger.info(f"ğŸ“ ë³€í™˜ ê²°ê³¼: {transcript[:100]}...")
            
            return transcript, elapsed_time
        except Exception as e:
            logger.error(f"âŒ STT ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    async def transcribe_audio_chunk(self, audio_chunk: bytes, language: str = "ko", intermediate_callback=None):
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ (ë¹„ë™ê¸° ì²˜ë¦¬)
        
        ì œê³µìì— ë”°ë¼ Google Cloud, OpenAI Whisper, ë˜ëŠ” RTZR ì‚¬ìš©
        RTZR ì‚¬ìš© ì‹œ ì¤‘ê°„ ê²°ê³¼ ì½œë°± ì§€ì›
        
        Args:
            audio_chunk: ì˜¤ë””ì˜¤ ë°ì´í„° ì²­í¬ (ë°”ì´íŠ¸ í˜•ì‹, WAV ê¶Œì¥)
            language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: "ko" - í•œêµ­ì–´)
            intermediate_callback: ì¤‘ê°„ ê²°ê³¼ ì½œë°± (RTZR ì „ìš©, optional)
        
        Returns:
            tuple: (ë³€í™˜ëœ í…ìŠ¤íŠ¸, ì‹¤í–‰ ì‹œê°„)
        """
        logger.info(f"ğŸ¤ [STT Service] transcribe_audio_chunk ì‹œì‘")
        logger.info(f"   - ì œê³µì: {self.provider}")
        logger.info(f"   - ì²­í¬ í¬ê¸°: {len(audio_chunk)} bytes")
        logger.info(f"   - ì–¸ì–´: {language}")
        logger.info(f"   - ì²­í¬ í—¤ë”: {audio_chunk[:4] if len(audio_chunk) >= 4 else 'N/A'}")
        
        if self.provider == "google":
            logger.info(f"ğŸ” [STT Service] Google Cloud STTë¡œ ë¼ìš°íŒ…")
            return await self._transcribe_google(audio_chunk, language)
        elif self.provider == "rtzr":
            logger.info(f"ğŸ” [STT Service] RTZR WebSocket STTë¡œ ë¼ìš°íŒ…")
            return await self._transcribe_rtzr(audio_chunk, language, intermediate_callback)
        else:
            logger.info(f"ğŸ” [STT Service] OpenAI Whisperë¡œ ë¼ìš°íŒ…")
            return await self._transcribe_openai(audio_chunk, language)
    
    async def _transcribe_google(self, audio_chunk: bytes, language: str = "ko"):
        """Google Cloud STTë¡œ ë³€í™˜"""
        try:
            start_time = time.time()
            logger.info(f"ğŸ” [Google STT ë””ë²„ê·¸] ì‹œì‘ - ì²­í¬ í¬ê¸°: {len(audio_chunk)} bytes")
            
            # ì²­í¬ í¬ê¸° ê²€ì¦ (0.1ì´ˆë¡œ ì¤„ì„)
            min_size = 8000 * 2 * 0.1  # ìµœì†Œ 0.1ì´ˆ = 1,600 bytes
            logger.info(f"ğŸ” [Google STT ë””ë²„ê·¸] ìµœì†Œ ê¸¸ì´ ê²€ì¦: {len(audio_chunk)} bytes (ìµœì†Œ: {min_size})")
            
            if len(audio_chunk) < min_size:
                logger.warning(f"âš ï¸  [Google STT ë””ë²„ê·¸] ì²­í¬ê°€ ë„ˆë¬´ ì‘ì•„ ê±´ë„ˆëœ€: {len(audio_chunk)} bytes (ìµœì†Œ: {min_size})")
                return "", 0
            
            # WAV í—¤ë” ì œê±° (Googleì€ raw PCMë§Œ í•„ìš”)
            logger.info(f"ğŸ” [Google STT ë””ë²„ê·¸] WAV í—¤ë” í™•ì¸: {audio_chunk[:4]}")
            if audio_chunk[:4] == b'RIFF':
                logger.info("ğŸ” [Google STT ë””ë²„ê·¸] WAV í—¤ë” ì œê±° ì¤‘...")
                try:
                    import wave
                    wav_io = io.BytesIO(audio_chunk)
                    with wave.open(wav_io, 'rb') as wav_file:
                        # WAV íŒŒì¼ ì •ë³´ í™•ì¸
                        channels = wav_file.getnchannels()
                        sample_width = wav_file.getsampwidth()
                        framerate = wav_file.getframerate()
                        n_frames = wav_file.getnframes()
                        
                        logger.info(f"   - WAV ì •ë³´: {channels}ch, {sample_width*8}bit, {framerate}Hz, {n_frames} frames")
                        
                        # PCM ë°ì´í„° ì¶”ì¶œ
                        audio_data = wav_file.readframes(n_frames)
                        logger.info(f"âœ… [Google STT ë””ë²„ê·¸] WAV í—¤ë” ì œê±° ì™„ë£Œ: {len(audio_data)} bytes")
                        
                        # Google Cloud STT ì„¤ì •ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                        if sample_width != 2:
                            logger.warning(f"âš ï¸  [Google STT ë””ë²„ê·¸] ìƒ˜í”Œ í­ ë¶ˆì¼ì¹˜: {sample_width*8}bit (ì˜ˆìƒ: 16bit)")
                        if framerate != 8000:
                            logger.warning(f"âš ï¸  [Google STT ë””ë²„ê·¸] ìƒ˜í”Œë ˆì´íŠ¸ ë¶ˆì¼ì¹˜: {framerate}Hz (ì˜ˆìƒ: 8000Hz)")
                        if channels != 1:
                            logger.warning(f"âš ï¸  [Google STT ë””ë²„ê·¸] ì±„ë„ ìˆ˜ ë¶ˆì¼ì¹˜: {channels}ch (ì˜ˆìƒ: 1ch)")
                            
                except Exception as wav_error:
                    logger.error(f"âŒ [Google STT ë””ë²„ê·¸] WAV íŒŒì‹± ì‹¤íŒ¨: {wav_error}")
                    logger.info("ğŸ” [Google STT ë””ë²„ê·¸] ì›ë³¸ ë°ì´í„° ì‚¬ìš©")
                    audio_data = audio_chunk
            else:
                logger.info("ğŸ” [Google STT ë””ë²„ê·¸] WAV í—¤ë” ì—†ìŒ, ì›ë³¸ ì‚¬ìš©")
                audio_data = audio_chunk
            
            # Google Cloud Speech API í˜¸ì¶œ
            logger.info(f"ğŸŒ [Google STT ë””ë²„ê·¸] Google Cloud API í˜¸ì¶œ ì¤‘... (ë°ì´í„°: {len(audio_data)} bytes)")
            audio = speech.RecognitionAudio(content=audio_data)
            
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self.google_client.recognize(
                    config=self.google_config,
                    audio=audio,
                    retry=retry.Retry(deadline=10.0)
                )
            )
            
            elapsed_time = time.time() - start_time
            logger.info(f"âœ… [Google STT ë””ë²„ê·¸] API ì‘ë‹µ ë°›ìŒ ({elapsed_time:.2f}ì´ˆ)")
            
            # ì‘ë‹µ êµ¬ì¡° ìƒì„¸ ë¶„ì„
            logger.info(f"ğŸ” [Google STT ë””ë²„ê·¸] ì‘ë‹µ ë¶„ì„:")
            logger.info(f"   - response íƒ€ì…: {type(response)}")
            logger.info(f"   - response.results ì¡´ì¬: {hasattr(response, 'results')}")
            
            if not response.results:
                logger.info("â­ï¸  STT ê²°ê³¼ ì—†ìŒ")
                return "", elapsed_time
            
            logger.info(f"   - results ê°œìˆ˜: {len(response.results)}")
            
            if len(response.results) == 0:
                logger.warning("âš ï¸  [Google STT ë””ë²„ê·¸] results ë°°ì—´ì´ ë¹„ì–´ìˆìŒ")
                return "", elapsed_time
            
            try:
                # ì²« ë²ˆì§¸ ê²°ê³¼ ìƒì„¸ ë¶„ì„
                first_result = response.results[0]
                logger.info(f"   - ì²« ë²ˆì§¸ ê²°ê³¼ íƒ€ì…: {type(first_result)}")
                logger.info(f"   - alternatives ì¡´ì¬: {hasattr(first_result, 'alternatives')}")
                
                if not hasattr(first_result, 'alternatives') or not first_result.alternatives:
                    logger.error(f"âŒ [Google STT ë””ë²„ê·¸] alternativesê°€ ì—†ìŒ")
                    return "", elapsed_time
                
                logger.info(f"   - alternatives ê°œìˆ˜: {len(first_result.alternatives)}")
                
                # ì²« ë²ˆì§¸ alternative ìƒì„¸ ë¶„ì„
                first_alternative = first_result.alternatives[0]
                logger.info(f"   - ì²« ë²ˆì§¸ alternative íƒ€ì…: {type(first_alternative)}")
                logger.info(f"   - transcript ì†ì„± ì¡´ì¬: {hasattr(first_alternative, 'transcript')}")
                logger.info(f"   - confidence ì†ì„± ì¡´ì¬: {hasattr(first_alternative, 'confidence')}")
                
                if not hasattr(first_alternative, 'transcript'):
                    logger.error(f"âŒ [Google STT ë””ë²„ê·¸] transcript ì†ì„±ì´ ì—†ìŒ")
                    return "", elapsed_time
                
                transcript = first_alternative.transcript
                confidence = getattr(first_alternative, 'confidence', 0.0)
                
                logger.info(f"   - transcript ê°’: '{transcript}'")
                logger.info(f"   - transcript íƒ€ì…: {type(transcript)}")
                logger.info(f"   - transcript ê¸¸ì´: {len(transcript) if transcript else 0}")
                logger.info(f"   - confidence ê°’: {confidence}")
                
                if transcript and transcript.strip():
                    logger.info(f"ğŸ¤ [Google STT] {transcript[:80]}... "
                               f"(ì‹ ë¢°ë„: {confidence:.2f}, {elapsed_time:.2f}ì´ˆ)")
                else:
                    logger.info(f"ğŸ” [Google STT ë””ë²„ê·¸] ë¹ˆ ê²°ê³¼ ë°˜í™˜")
                    
            except Exception as detail_error:
                logger.error(f"âŒ [Google STT ë””ë²„ê·¸] ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {detail_error}")
                logger.error(f"   - ì˜¤ë¥˜ íƒ€ì…: {type(detail_error)}")
                import traceback
                logger.error(f"   - ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                return "", elapsed_time
            
            return transcript, elapsed_time
            
        except Exception as e:
            logger.error(f"âŒ Google STT ë³€í™˜ ì‹¤íŒ¨: {e}")
            logger.error(f"   - ì²­í¬ í¬ê¸°: {len(audio_chunk)}")
            logger.error(f"   - ì²­í¬ íƒ€ì…: {type(audio_chunk)}")
            import traceback
            logger.error(f"   - ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return "", 0
    
    async def _transcribe_openai(self, audio_chunk: bytes, language: str = "ko"):
        """OpenAI Whisperë¡œ ë³€í™˜"""
        try:
            start_time = time.time()
            logger.info(f"ğŸ” [OpenAI STT ë””ë²„ê·¸] ì‹œì‘ - ì²­í¬ í¬ê¸°: {len(audio_chunk)} bytes")
            
            # ì²­í¬ í¬ê¸° ê²€ì¦
            if len(audio_chunk) < self.min_chunk_size:
                logger.debug(f"â­ï¸  ì²­í¬ê°€ ë„ˆë¬´ ì‘ì•„ ê±´ë„ˆëœ€: {len(audio_chunk)} bytes (ìµœì†Œ: {self.min_chunk_size})")
                return "", 0
            
            # ì„ì‹œ íŒŒì¼ ìƒì„±
            logger.info(f"ğŸ” [OpenAI STT ë””ë²„ê·¸] ì„ì‹œ íŒŒì¼ ìƒì„± ì¤‘...")
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_path = temp_file.name
                temp_file.write(audio_chunk)
            logger.info(f"âœ… [OpenAI STT ë””ë²„ê·¸] ì„ì‹œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {temp_path}")
            
            try:
                logger.info(f"ğŸŒ [OpenAI STT ë””ë²„ê·¸] OpenAI Whisper API í˜¸ì¶œ ì¤‘...")
                loop = asyncio.get_event_loop()
                transcript = await loop.run_in_executor(
                    None,
                    self._transcribe_file_sync,
                    temp_path,
                    language
                )
                
                elapsed_time = time.time() - start_time
                logger.info(f"âœ… [OpenAI STT ë””ë²„ê·¸] API ì‘ë‹µ ë°›ìŒ ({elapsed_time:.2f}ì´ˆ)")
                
                if transcript and transcript.strip():
                    logger.info(f"ğŸ¤ [OpenAI STT] {transcript[:80]}... ({elapsed_time:.2f}ì´ˆ)")
                else:
                    logger.info(f"ğŸ” [OpenAI STT ë””ë²„ê·¸] ë¹ˆ ê²°ê³¼ ë°˜í™˜")
                
                return transcript, elapsed_time
                
            finally:
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                    logger.info(f"ğŸ—‘ï¸  [OpenAI STT ë””ë²„ê·¸] ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_path}")
                    
        except Exception as e:
            logger.error(f"âŒ OpenAI STT ë³€í™˜ ì‹¤íŒ¨: {e}")
            logger.error(f"   - ì²­í¬ í¬ê¸°: {len(audio_chunk)}")
            logger.error(f"   - ì²­í¬ íƒ€ì…: {type(audio_chunk)}")
            import traceback
            logger.error(f"   - ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return "", 0
    
    def _transcribe_file_sync(self, file_path: str, language: str) -> str:
        """
        ë™ê¸° ë°©ì‹ íŒŒì¼ ë³€í™˜ (executorì—ì„œ ì‹¤í–‰ìš©)
        
        ì´ ë©”ì„œë“œëŠ” ì§ì ‘ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”.
        transcribe_audio_chunk()ì—ì„œ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        
        Args:
            file_path: ë³€í™˜í•  ìŒì„± íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ
        
        Returns:
            str: ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        try:
            logger.info(f"ğŸ” [OpenAI STT Sync ë””ë²„ê·¸] íŒŒì¼ ë³€í™˜ ì‹œì‘: {file_path}")
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(file_path)
            logger.info(f"ğŸ” [OpenAI STT Sync ë””ë²„ê·¸] íŒŒì¼ í¬ê¸°: {file_size} bytes")
            
            with open(file_path, "rb") as audio_file:
                logger.info(f"ğŸŒ [OpenAI STT Sync ë””ë²„ê·¸] OpenAI API í˜¸ì¶œ ì¤‘... (ëª¨ë¸: {self.model})")
                transcript = self.client.audio.transcriptions.create(
                    model=self.model,
                    file=audio_file,
                    language=language,
                    response_format="text",
                    temperature=0.0,  # ëœë¤ì„± ìµœì†Œí™”
                    prompt="ì´ ì…ë ¥ì€ ì „í™” ëŒ€í™”ì˜ í•œ ë¶€ë¶„ì…ë‹ˆë‹¤. ë§ì´ ì—†ìœ¼ë©´ ì•„ë¬´ê²ƒë„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”."
                )
            
            logger.info(f"âœ… [OpenAI STT Sync ë””ë²„ê·¸] API ì‘ë‹µ ë°›ìŒ: '{transcript[:50]}...'")
            return transcript
            
        except Exception as e:
            logger.error(f"âŒ [OpenAI STT Sync ë””ë²„ê·¸] íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
            logger.error(f"   - íŒŒì¼ ê²½ë¡œ: {file_path}")
            logger.error(f"   - íŒŒì¼ í¬ê¸°: {os.path.getsize(file_path) if os.path.exists(file_path) else 'N/A'}")
            import traceback
            logger.error(f"   - ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return ""
    
    def transcribe_audio_with_timestamps(self, audio_file_path: str):
        """
        íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ë³€í™˜
        
        Args:
            audio_file_path: ìŒì„± íŒŒì¼ ê²½ë¡œ
        
        Returns:
            dict: segmentsì™€ íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´
        """
        try:
            with open(audio_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model=self.model,
                    file=audio_file,
                    response_format="verbose_json",
                    timestamp_granularities=["segment"],
                    temperature=0.0
                )
            return transcript
        except Exception as e:
            logger.error(f"Failed to transcribe with timestamps: {e}")
            raise
    
    async def _get_rtzr_token(self):
        """RTZR í† í° ê°€ì ¸ì˜¤ê¸° (ìºì‹±)"""
        # ìºì‹œëœ í† í° ìœ íš¨ì„± ê²€ì‚¬
        if self._cached_token and self._token_expires_at > time.time():
            logger.debug("â™»ï¸ ìºì‹œëœ í† í° ì¬ì‚¬ìš©")
            return self._cached_token
        
        # ìƒˆ í† í° ë°œê¸‰
        logger.info("ğŸ” [RTZR] ìƒˆ í† í° ë°œê¸‰ ì¤‘...")
        auth_response = requests.post(
            f"{self.rtzr_api_base}/v1/authenticate",
            data={
                "client_id": self.rtzr_client_id,
                "client_secret": self.rtzr_client_secret
            }
        )
        
        if auth_response.status_code != 200:
            raise Exception(f"RTZR ì¸ì¦ ì‹¤íŒ¨: {auth_response.status_code}")
        
        token = auth_response.json()["access_token"]
        
        # ìºì‹œ (1ì‹œê°„ ìœ íš¨)
        self._cached_token = token
        self._token_expires_at = time.time() + 3600
        
        logger.info("âœ… [RTZR] í† í° ë°œê¸‰ ë° ìºì‹œ ì™„ë£Œ")
        return token
    
    async def _get_rtzr_websocket(self, token: str):
        """WebSocket ì—°ê²° ê°€ì ¸ì˜¤ê¸° - RTZRì€ ë°œí™”ë§ˆë‹¤ ìƒˆ ì—°ê²° í•„ìš”"""
        async with self._rtzr_ws_lock:
            # RTZR íŠ¹ì„±ìƒ EOS ì „ì†¡ ì‹œ ì—°ê²°ì´ ì¢…ë£Œë˜ë¯€ë¡œ ë§¤ë²ˆ ìƒˆë¡œ ì—°ê²°
            if self._rtzr_ws:
                try:
                    await self._rtzr_ws.close()
                except:
                    pass
                self._rtzr_ws = None
            
            # ìƒˆë¡œ ì—°ê²°
            logger.info("ğŸŒ [RTZR] ìƒˆ WebSocket ì—°ê²° ì¤‘...")
            import websockets
            
            ws_url = "wss://openapi.vito.ai/v1/transcribe:streaming"
            params = {
                "sample_rate": "8000",
                "encoding": "LINEAR16",
                "use_itn": str(settings.RTZR_USE_ITN).lower(),
                "use_disfluency_filter": str(settings.RTZR_USE_DISFLUENCY_FILTER).lower(),
                "use_profanity_filter": str(settings.RTZR_USE_PROFANITY_FILTER).lower()
            }
            query_string = "&".join([f"{k}={v}" for k, v in params.items()])
            
            headers = {"Authorization": f"Bearer {token}"}
            
            self._rtzr_ws = await websockets.connect(
                f"{ws_url}?{query_string}",
                additional_headers=headers,
                ping_interval=None
            )
            
            logger.info("âœ… [RTZR] WebSocket ì—°ê²° ì™„ë£Œ (ì¬ì‚¬ìš© ê°€ëŠ¥)")
            return self._rtzr_ws
    
    async def close_rtzr_websocket(self):
        """í†µí™” ì¢…ë£Œ ì‹œ WebSocket ì—°ê²° ë‹«ê¸°"""
        async with self._rtzr_ws_lock:
            if self._rtzr_ws:
                try:
                    await self._rtzr_ws.close()
                    logger.info("ğŸ”„ [RTZR] WebSocket ì—°ê²° ì¢…ë£Œ")
                except:
                    pass
                self._rtzr_ws = None
    
    async def _transcribe_rtzr(self, audio_chunk: bytes, language: str = "ko", intermediate_callback=None):
        """
        RTZR WebSocket STTë¡œ ë³€í™˜ (í† í° ìºì‹± + ì—°ê²° ì¬ì‚¬ìš© + ì¤‘ê°„ ê²°ê³¼ í™œìš©)
        
        Args:
            audio_chunk: ì˜¤ë””ì˜¤ ë°ì´í„°
            language: ì–¸ì–´ ì½”ë“œ
            intermediate_callback: ì¤‘ê°„ ê²°ê³¼ ì½œë°± í•¨ìˆ˜ (optional)
        """
        try:
            start_time = time.time()
            logger.info(f"ğŸ” [RTZR STT] ì‹œì‘ - ì²­í¬ í¬ê¸°: {len(audio_chunk)} bytes")
            
            # WAV í—¤ë” ì œê±° ë° PCM ì¶”ì¶œ
            import wave
            pcm_data = audio_chunk
            
            if audio_chunk[:4] == b'RIFF':
                logger.info("ğŸ” [RTZR STT] WAV í—¤ë” ì œê±° ì¤‘...")
                wav_io = io.BytesIO(audio_chunk)
                with wave.open(wav_io, 'rb') as wav_file:
                    pcm_data = wav_file.readframes(wav_file.getnframes())
                    logger.info(f"âœ… WAV í—¤ë” ì œê±°: {len(pcm_data)} bytes")
            
            # â­ í† í° ê°€ì ¸ì˜¤ê¸° (ìºì‹œ)
            token = await self._get_rtzr_token()
            
            # â­ WebSocket ê°€ì ¸ì˜¤ê¸° (ì¬ì‚¬ìš©)
            ws = await self._get_rtzr_websocket(token)
            
            # ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡
            logger.info(f"ğŸ“¤ [RTZR STT] ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡ ì¤‘... ({len(pcm_data)} bytes)")
            
            # ì²­í¬ ë‹¨ìœ„ë¡œ ì „ì†¡
            chunk_size = 16000  # 1ì´ˆ ë¶„ëŸ‰
            for i in range(0, len(pcm_data), chunk_size):
                chunk = pcm_data[i:i + chunk_size]
                await ws.send(chunk)
                await asyncio.sleep(0.01)
            
            # ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
            await ws.send("EOS")
            logger.info("ğŸ“¤ [RTZR STT] EOS ì „ì†¡ ì™„ë£Œ")
            
            # ê²°ê³¼ ìˆ˜ì‹ 
            result_text = ""
            results_received = []
            intermediate_text = ""
            final_received = False
            
            try:
                # â­ ì—¬ëŸ¬ ì‘ë‹µ ìˆ˜ì‹  (ìµœì¢… ê²°ê³¼ê¹Œì§€)
                max_attempts = 3  # ìµœëŒ€ 3ë²ˆê¹Œì§€ ì‘ë‹µ ë°›ê¸°
                for attempt in range(max_attempts):
                    try:
                        response = await asyncio.wait_for(ws.recv(), timeout=2.0)
                        if isinstance(response, bytes):
                            continue
                        
                        result = json.loads(response)
                        results_received.append(result)
                        logger.info(f"ğŸ“¥ [RTZR STT] ì‘ë‹µ ìˆ˜ì‹  [{attempt+1}]: {json.dumps(result, ensure_ascii=False)}")
                        
                        # alternativesì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        if "alternatives" in result and len(result["alternatives"]) > 0:
                            text = result["alternatives"][0].get("text", "")
                            is_final = result.get("final", False)
                            
                            if is_final:
                                result_text = text
                                final_received = True
                                logger.info(f"âœ… [RTZR STT] ìµœì¢… ê²°ê³¼: '{text}'")
                                break  # ìµœì¢… ê²°ê³¼ ë°›ì•˜ìœ¼ë¯€ë¡œ ì¢…ë£Œ
                            else:
                                # â­ ì¤‘ê°„ ê²°ê³¼ í™œìš©
                                intermediate_text = text
                                logger.info(f"ğŸ”„ [RTZR STT] ì¤‘ê°„ ê²°ê³¼: '{text}'")
                                
                                # â­ ì½œë°±ì´ ìˆìœ¼ë©´ ì¤‘ê°„ ê²°ê³¼ë¥¼ ì¦‰ì‹œ ì „ë‹¬ (ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥)
                                if intermediate_callback and text and text.strip():
                                    try:
                                        await intermediate_callback(text)
                                        logger.info(f"ğŸ“¤ [RTZR STT] ì¤‘ê°„ ê²°ê³¼ ì½œë°± ì‹¤í–‰: '{text}'")
                                    except Exception as callback_error:
                                        logger.error(f"âŒ ì¤‘ê°„ ê²°ê³¼ ì½œë°± ì˜¤ë¥˜: {callback_error}")
                            
                            # ì¤‘ê°„ ê²°ê³¼ë¡œë„ ìµœì¢… ê²°ê³¼ ì„¤ì • (finalì´ ì—†ì„ ìˆ˜ ìˆìŒ)
                            if not final_received and text:
                                result_text = text
                                
                    except asyncio.TimeoutError:
                        logger.debug(f"ğŸ”„ [RTZR STT] ì‘ë‹µ íƒ€ì„ì•„ì›ƒ [{attempt+1}]")
                        if result_text:  # ì´ë¯¸ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¢…ë£Œ
                            break
                        continue
                            
            except Exception as close_error:
                logger.debug(f"WebSocket ì¢…ë£Œ: {close_error}")
                if results_received:
                    for r in reversed(results_received):
                        if "alternatives" in r and len(r["alternatives"]) > 0:
                            result_text = r["alternatives"][0].get("text", "")
                            if r.get("final", False):
                                break
            
            # â­ WebSocket ì¢…ë£Œí•˜ì§€ ì•ŠìŒ! (ë‹¤ìŒ ë°œí™”ë¥¼ ìœ„í•´ ì¬ì‚¬ìš©)
            elapsed_time = time.time() - start_time
            logger.info(f"âœ… [RTZR STT] ì™„ë£Œ ({elapsed_time:.2f}ì´ˆ): '{result_text}'")
            
            return result_text, elapsed_time
            
        except Exception as e:
            logger.error(f"âŒ RTZR STT ë³€í™˜ ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ë°œìƒ ì‹œ ì—°ê²° ì´ˆê¸°í™”
            async with self._rtzr_ws_lock:
                if self._rtzr_ws:
                    try:
                        await self._rtzr_ws.close()
                    except:
                        pass
                    self._rtzr_ws = None
            import traceback
            logger.error(traceback.format_exc())
            return "", 0

