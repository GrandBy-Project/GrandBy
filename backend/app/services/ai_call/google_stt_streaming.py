"""
Google Cloud Speech-to-Text ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤
ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ì„ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë° API êµ¬í˜„
"""

from google.cloud import speech
from google.api_core import retry
from app.config import settings
import logging
import asyncio
import queue
import threading
from typing import Optional, AsyncGenerator
import time

logger = logging.getLogger(__name__)


class GoogleSTTStreaming:
    """
    Google Cloud STT ìŠ¤íŠ¸ë¦¬ë° í´ë¼ì´ì–¸íŠ¸
    
    Twilioì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ì˜¤ë””ì˜¤ë¥¼ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬
    ì‚¬ìš©ìžê°€ ë§í•˜ëŠ” ë™ì•ˆ ê³„ì† í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self.client = speech.SpeechClient()
        self.is_streaming = False
        self.audio_queue = queue.Queue()
        self.config = self._create_streaming_config()
        logger.info("ðŸŽ¤ Google STT ìŠ¤íŠ¸ë¦¬ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _create_streaming_config(self) -> speech.StreamingRecognitionConfig:
        """ìŠ¤íŠ¸ë¦¬ë° ì¸ì‹ ì„¤ì • ìƒì„±"""
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=8000,  # Twilio 8kHz
            language_code="ko-KR",
            model="phone_call",  # ì „í™” í†µí™” ìµœì í™”
            enable_automatic_punctuation=True,
            use_enhanced=True,
            audio_channel_count=1,
        )
        
        streaming_config = speech.StreamingRecognitionConfig(
            config=config,
            interim_results=True,  # ì¤‘ê°„ ê²°ê³¼ ë°˜í™˜
            single_utterance=False,  # ì—°ì† ì¸ì‹
        )
        
        return streaming_config
    
    def add_audio_chunk(self, audio_data: bytes):
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ íì— ì¶”ê°€
        
        Args:
            audio_data: mulaw í¬ë§· ì˜¤ë””ì˜¤ (Twilioì—ì„œ ì „ì†¡)
        """
        if self.is_streaming:
            self.audio_queue.put(audio_data)
    
    def _request_generator(self):
        """
        ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ìƒì„±ê¸°
        íì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ êº¼ë‚´ì„œ APIì— ì „ì†¡
        """
        # ì²« ìš”ì²­: ì„¤ì • ì •ë³´
        yield speech.StreamingRecognizeRequest(streaming_config=self.config)
        
        # ì´í›„ ìš”ì²­: ì˜¤ë””ì˜¤ ë°ì´í„°
        while self.is_streaming:
            try:
                # íƒ€ìž„ì•„ì›ƒ ì„¤ì • (0.1ì´ˆë§ˆë‹¤ ì²´í¬)
                audio_data = self.audio_queue.get(timeout=0.1)
                
                # mulawë¥¼ LINEAR16ìœ¼ë¡œ ë³€í™˜
                import audioop
                pcm_data = audioop.ulaw2lin(audio_data, 2)
                
                yield speech.StreamingRecognizeRequest(audio_content=pcm_data)
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                break
    
    async def start_streaming(self) -> AsyncGenerator[str, None]:
        """
        ìŠ¤íŠ¸ë¦¬ë° ì‹œìž‘ ë° ê²°ê³¼ ë°˜í™˜
        
        Yields:
            str: ì¸ì‹ëœ í…ìŠ¤íŠ¸ (ì¤‘ê°„ ê²°ê³¼ ë° ìµœì¢… ê²°ê³¼)
        """
        self.is_streaming = True
        self.audio_queue = queue.Queue()  # í ì´ˆê¸°í™”
        
        try:
            logger.info("ðŸŽ™ï¸ Google STT ìŠ¤íŠ¸ë¦¬ë° ì‹œìž‘")
            
            # ìŠ¤íŠ¸ë¦¬ë° ì¸ì‹ ì‹¤í–‰ (ë™ê¸° â†’ ë¹„ë™ê¸° ëž˜í•‘)
            loop = asyncio.get_event_loop()
            
            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            responses = await loop.run_in_executor(
                None,
                lambda: self.client.streaming_recognize(
                    self.config,
                    self._request_generator()
                )
            )
            
            # ê²°ê³¼ ì²˜ë¦¬
            for response in responses:
                if not response.results:
                    continue
                
                result = response.results[0]
                if not result.alternatives:
                    continue
                
                transcript = result.alternatives[0].transcript
                is_final = result.is_final
                
                # ì¤‘ê°„ ê²°ê³¼ ë¡œê¹…
                if not is_final:
                    logger.debug(f"[ì¤‘ê°„] {transcript}")
                else:
                    logger.info(f"âœ… [ìµœì¢…] {transcript}")
                    yield transcript
                    
        except Exception as e:
            logger.error(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(traceback.format_exc())
        finally:
            self.is_streaming = False
            logger.info("ðŸ›‘ Google STT ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ")
    
    def stop_streaming(self):
        """ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€"""
        self.is_streaming = False
        logger.info("ðŸ›‘ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ ìš”ì²­")


class GoogleSTTStreamingSession:
    """
    ë‹¨ì¼ í†µí™” ì„¸ì…˜ì„ ìœ„í•œ STT ìŠ¤íŠ¸ë¦¬ë° ê´€ë¦¬ìž
    
    ê° Twilio í†µí™”ë§ˆë‹¤ ë…ë¦½ì ì¸ ì„¸ì…˜ì„ ìƒì„±í•˜ì—¬
    ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, call_sid: str):
        self.call_sid = call_sid
        self.streaming_client: Optional[GoogleSTTStreaming] = None
        self.transcript_buffer = []  # ë³€í™˜ëœ í…ìŠ¤íŠ¸ ëˆ„ì 
        self.is_active = False
        
        # ë°œí™” ê°ì§€ ì„¤ì •
        self.last_speech_time = time.time()
        self.silence_threshold = 1.5  # 1.5ì´ˆ ì¹¨ë¬µ í›„ ë°œí™” ì¢…ë£Œë¡œ ê°„ì£¼
        
        logger.info(f"ðŸ“ž STT ì„¸ì…˜ ìƒì„±: {call_sid}")
    
    async def initialize(self):
        """ì„¸ì…˜ ì´ˆê¸°í™”"""
        try:
            self.streaming_client = GoogleSTTStreaming()
            self.is_active = True
            logger.info(f"âœ… STT ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ: {self.call_sid}")
        except Exception as e:
            logger.error(f"âŒ STT ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def add_audio_chunk(self, audio_data: bytes):
        """
        ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€
        
        Args:
            audio_data: mulaw ì˜¤ë””ì˜¤ ë°ì´í„°
        """
        if self.streaming_client and self.is_active:
            self.streaming_client.add_audio_chunk(audio_data)
            self.last_speech_time = time.time()
    
    async def process_streaming(self) -> AsyncGenerator[str, None]:
        """
        ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ë° ë°œí™” ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ ë°˜í™˜
        
        Yields:
            str: ì™„ì„±ëœ ë°œí™” í…ìŠ¤íŠ¸
        """
        if not self.streaming_client:
            return
        
        current_utterance = []
        
        try:
            async for transcript in self.streaming_client.start_streaming():
                current_utterance.append(transcript)
                self.last_speech_time = time.time()
                
                # ì¹¨ë¬µ ì²´í¬ (ë°œí™” ì¢…ë£Œ ê°ì§€)
                await asyncio.sleep(0.1)
                silence_duration = time.time() - self.last_speech_time
                
                if silence_duration >= self.silence_threshold and current_utterance:
                    # ë°œí™” ì™„ë£Œ
                    full_utterance = " ".join(current_utterance)
                    logger.info(f"ðŸŽ¤ [ë°œí™” ì™„ë£Œ] {full_utterance}")
                    
                    self.transcript_buffer.append(full_utterance)
                    yield full_utterance
                    
                    current_utterance = []
                    
        except Exception as e:
            logger.error(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    def get_full_transcript(self) -> str:
        """ì „ì²´ ëŒ€í™” ë‚´ìš© ë°˜í™˜"""
        return " ".join(self.transcript_buffer)
    
    async def close(self):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        if self.streaming_client:
            self.streaming_client.stop_streaming()
        self.is_active = False
        logger.info(f"ðŸ›‘ STT ì„¸ì…˜ ì¢…ë£Œ: {self.call_sid}")

