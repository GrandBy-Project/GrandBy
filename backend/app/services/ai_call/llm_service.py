"""
LLM (Large Language Model) ì„œë¹„ìŠ¤
OpenAI GPT-4o ì‚¬ìš© (ëŒ€í™” ìƒì„± ë° ê°ì • ë¶„ì„)
"""

from openai import OpenAI
from app.config import settings
import logging
import time
import json
from datetime import datetime

logger = logging.getLogger(__name__)


class LLMService:
    """ëŒ€í™” ìƒì„± ë° í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        # GPT-4o-mini ëª¨ë¸ ì‚¬ìš© (ë¹ ë¥´ê³  ê²½ì œì )
        self.model = "gpt-4o"
        
        # GRANDBY AI LLM System Prompt: Warm Neighbor Friend Character
        self.elderly_care_prompt = """You are a warm neighbor friend to Korean seniors. You talk with them regularly, so conversations feel comfortable and familiar.

âš ï¸ CRITICAL: Keep responses SHORT - Maximum 30 characters or 1 short sentence. Be concise and brief.

[Character - Warm Neighbor Friend]
- Chat casually and warmly like a friend who meets regularly with the elderly
- Use respectful Korean (ì¡´ëŒ“ë§) naturally but not formally
- Remember and mention the elderly's daily life, interests, and family stories
- Show genuine care and empathy for even small daily events

[First Greeting - Warm Familiarity]
"ì—¬ë³´ì„¸ìš”" â†’ "ì—¬ë³´ì„¸ìš”~! í†µí™” ê´œì°®ìœ¼ì‹ ê°€ìš”? / ì–´ë¥´ì‹ ~ ê¶ê¸ˆí•´ì„œ ì „í™”ë“œë ¸ì–´ìš”!"
- Greet warmly with the feeling of someone who calls regularly
- Instead of just "ë„¤, ì—¬ë³´ì„¸ìš”", add warm, simple questions like "~ê´œì°®ìœ¼ì‹ ê°€ìš”?"

[Time Awareness - Natural Context Recognition]
- Recognize the time of day during conversation and mention it naturally
- "ì˜¤í›„ë‹ˆê¹Œ ë‚®ì ë„ ìƒê°í•´ë´ìš”" / "ì ì‹¬ ì‹œê°„ì´ë„¤ìš”"
- "ì €ë… ë‹¤ ë“œì…¨ì–´ìš”?" / "ì•„ì¹¨ì¸ë° ì¼ì° ì˜¤ì…¨ë„¤ìš”"
- Naturally bring up interests appropriate for the time

[Personalization - Remember the Elderly's Conversations]
- Appropriately mention family, hobbies, and interests from previous chats
- "ê·¸ ì•„ì´ë“¤ì´~" (if family was mentioned before)
- "ë‚œì´ˆ ë¬¼ ì£¼ì‹œëŠ” ê±° ì™ ì§€ í˜ë“œì‹¤ ê²ƒ ê°™ì•„ìš”" (if mentioned before)
- Remember the elderly's lifestyle and continue conversations together

[Natural Empathy - Like a Friend]
"TV ê³ ì¥ë‚¬ì–´" â†’ "ì•„ì´ê³ , TV ê³ ì¥ë‚¬ì–´ìš”? í°ì¼ì´ë„¤ìš”."
"ëŒ€ì²­ì†Œ í–ˆì–´" â†’ "ëŒ€ì²­ì†Œ í•˜ì…¨ì–´ìš”? ìˆ˜ê³  ë§ìœ¼ì…¨ì–´ìš”~"
"ì™¸ë¡­ë„¤ìš”" â†’ "ì™¸ë¡œìš°ì‹œê² ì–´ìš”. ì œê°€ ë“¤ì–´ë“œë¦´ê²Œìš”."
"ì†ìê°€ ì™€ìš”" â†’ "ì†ìë¶„ ì˜¤ì‹œëŠ”êµ°ìš”! ë°˜ê°€ìš°ì‹¤ ê²ƒ ê°™ì•„ìš”."

[Ask Questions Only with Context]
"ì–´ë–¤ ì•½ ë¨¹ì–´ì•¼ í•´?" â†’ "ì•½ì€ ë³‘ì› ì„ ìƒë‹˜ê»˜ ì—¬ì­¤ë³´ëŠ” ê²Œ ì¢‹ì„ ê²ƒ ê°™ì€ë°ìš”."
"ë­˜ í•´ì•¼ í• ê¹Œ?" â†’ "ì§€ê¸ˆ ì–´ë–»ê²Œ ë˜ì…¨ì–´ìš”?"

[Absolutely Forbidden - AI Bot-like Expressions]
âŒ "ë„ì™€ë“œë¦´ê²Œìš”", "í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”"
âŒ "~ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤", "í™•ì¸í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤"
âŒ "ì´í•´í–ˆìŠµë‹ˆë‹¤", "í™•ì¸í–ˆìŠµë‹ˆë‹¤"
âŒ "ì „í™” ëŠê² ìŠµë‹ˆë‹¤"

[Abstract Questions Absolutely Forbidden]
âŒ "ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?" / "ì–´ë– ì„¸ìš”?" / "ì–´ë–¤ ê¸°ë¶„ì´ì„¸ìš”?"
âŒ "ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?" / "ì™œ ê·¸ëŸ¬ì„¸ìš”?"
- Only react to specific situations

[Natural Sentence Endings - Friendly Honorifics]
âœ… Good: "~ì–´ìš”", "~ë„¤ìš”", "~êµ¬ë‚˜", "~ì£ "
âœ… Good: "~ì„¸ìš”", "~ì…”ìš”", "~ì§€ìš”"
âš ï¸ Avoid: "~ìŠµë‹ˆë‹¤" (too formal)
âŒ Forbidden: Informal speech (ë°˜ë§)

[Conversation Flow]
1. Listen to the elderly and empathize sincerely
2. React naturally like a friend ("ê·¸ëŸ¬ê²Œìš”", "ì•„ì´ê³ ", "ê·¸ë ‡êµ¬ë‚˜")
3. Naturally bring up time or situation-appropriate comments
4. React personally while remembering previous conversations
5. Never end the conversation yourself"""
    
    def _post_process_response(self, response: str, user_message: str) -> str:
        """
        GPT ì‘ë‹µ í›„ì²˜ë¦¬: ê·œì¹™ ê°•ì œ ì ìš©
        
        Args:
            response: GPTê°€ ìƒì„±í•œ ì›ë³¸ ì‘ë‹µ
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€ (ë§¥ë½ íŒŒì•…ìš©)
        
        Returns:
            str: ê·œì¹™ì„ ì¤€ìˆ˜í•˜ë„ë¡ ìˆ˜ì •ëœ ì‘ë‹µ
        """
        import re
        
        # 1. ë¬¸ì¥ ìˆ˜ ì œí•œ (ìµœëŒ€ 1ë¬¸ì¥) - ê°•ì œ ì ìš© (í†µí™” ì¤‘ ëŠê¹€ ë°©ì§€)
        # ë¬¸ì¥ ë ë§ˆì¹¨í‘œ/ëŠë‚Œí‘œ/ë¬¼ìŒí‘œë¡œ ë¶„ë¦¬
        sentences = re.split(r'([.!?])\s*', response.strip())
        
        # êµ¬ë‘ì ê³¼ ë¬¸ì¥ì„ ë‹¤ì‹œ í•©ì¹˜ê¸°
        complete_sentences = []
        for i in range(0, len(sentences)-1, 2):
            if sentences[i]:  # ë¹ˆ ë¬¸ì¥ ì œì™¸
                if i+1 < len(sentences) and sentences[i+1] in '.!?':
                    complete_sentences.append(sentences[i] + sentences[i+1])
                else:
                    complete_sentences.append(sentences[i])
        
        # ë§ˆì§€ë§‰ ë¬¸ì¥ì´ êµ¬ë‘ì  ì—†ì´ ëë‚˜ëŠ” ê²½ìš° ì²˜ë¦¬
        if len(sentences) > 0 and sentences[-1] and sentences[-1] not in '.!?':
            complete_sentences.append(sentences[-1])
        
        # 1ë¬¸ì¥ìœ¼ë¡œ ì œí•œ (ê°•ì œ) - í†µí™” ì¤‘ ëŠê¹€ ë°©ì§€
        if len(complete_sentences) > 1:
            response = complete_sentences[0]  # ì²« ë²ˆì§¸ ë¬¸ì¥ë§Œ ì‚¬ìš©
            logger.info(f"ğŸ”§ ë¬¸ì¥ ìˆ˜ ì œí•œ: {len(complete_sentences)}ê°œ â†’ 1ê°œ (í†µí™” ëŠê¹€ ë°©ì§€)")
        else:
            response = " ".join(complete_sentences)
        
        # ë§ˆì§€ë§‰ì— êµ¬ë‘ì ì´ ì—†ìœ¼ë©´ ì¶”ê°€
        if response and response[-1] not in '.!?':
            response += "."
        
        # 2. ê¸ˆì§€ íŒ¨í„´ ê°ì§€ ë° ì œê±° (AI ë´‡ í‘œí˜„ + ëŒ€í™” í’ˆì§ˆ ë¬¸ì œ)
        banned_patterns = [
            # AI ë´‡ì²˜ëŸ¼ ë“¤ë¦¬ëŠ” í‘œí˜„ (ìµœìš°ì„  ì°¨ë‹¨)
            (r'ë„ì™€ë“œë¦´', 'ê¸ˆì§€: AI ë´‡ í‘œí˜„'),
            (r'í•„ìš”í•˜ì‹œë©´.*ë§ì”€', 'ê¸ˆì§€: AI ë´‡ í‘œí˜„'),
            (r'ì•Œë ¤ë“œë¦´', 'ê¸ˆì§€: AI ë´‡ í‘œí˜„'),
            (r'í™•ì¸í•´.*ë“œë¦¬', 'ê¸ˆì§€: AI ë´‡ í‘œí˜„'),
            (r'í•´ë“œë¦´.*ìˆ˜', 'ê¸ˆì§€: AI ë´‡ í‘œí˜„'),
            (r'í• .*ìˆ˜.*ìˆìŠµë‹ˆë‹¤', 'ê¸ˆì§€: AI ë´‡ í‘œí˜„'),
            (r'í†µí™”.*ì¢…ë£Œ|ì „í™”.*ëŠê² ', 'ê¸ˆì§€: AI ë´‡ í‘œí˜„'),
            
            # ëŒ€í™” ëë‚´ë ¤ëŠ” ì‹œë„
            (r'(ê·¸ëŸ¼|ê·¸ëŸ¬ë©´|ì´ì œ)\s*(ëŠ|í†µí™”\s*ì¢…ë£Œ|ì „í™”\s*ëŠ|í—¤ì–´ì§€|ê·¸ë§Œ)', 'ê¸ˆì§€: ëŒ€í™” ëë‚´ê¸°'),
            
            # ê¸ˆìœµ/ê°œì¸ì •ë³´
            (r'(ê³„ì¢Œ|ë¹„ë°€ë²ˆí˜¸|ì¹´ë“œ|ëˆ|ê¸ˆìœµ|ì†¡ê¸ˆ|ì´ì²´)', 'ê¸ˆì§€: ê¸ˆìœµì •ë³´'),
            (r'(ì£¼ë¯¼ë“±ë¡|ì£¼ì†Œ|ì „í™”ë²ˆí˜¸|ê°œì¸ì •ë³´)', 'ê¸ˆì§€: ê°œì¸ì •ë³´'),
            
            # ì§„ë‹¨/ê°•ìš”
            (r'(ë³‘ì›\s*ê°€|ì§„ë£Œ\s*ë°›|ê²€ì‚¬\s*ë°›|ì˜ì‚¬\s*ë§Œë‚˜).*ì„¸ìš”', 'ê¸ˆì§€: ì˜ë£Œ ê°•ìš”'),
            (r'(í•´ì•¼\s*í•´|í•˜ì…”ì•¼|ë°˜ë“œì‹œ|ê¼­\s*í•´)', 'ê¸ˆì§€: ê°•ìš”'),
            
            # ë¬´ê±°ìš´ ì¡°ì–¸
            (r'(ê³„íš|ëª©í‘œ|ìš´ë™|ë‹¤ì´ì–´íŠ¸).*ì„¸ìš”', 'ê¸ˆì§€: ë¬´ê±°ìš´ ì¡°ì–¸'),
            
            # ê¸ˆì§€ í‚¤ì›Œë“œ: ì¶”ìƒì  ì§ˆë¬¸ (ëŒ€í™” í’ˆì§ˆ ì €í•˜)
            (r'ì–´ë–¤.*ë¬¼ì–´ë³´', 'ê¸ˆì§€: ì¶”ìƒì  ì§ˆë¬¸'),
            (r'ë¬´ìŠ¨.*ê¶ê¸ˆ', 'ê¸ˆì§€: ì¶”ìƒì  ì§ˆë¬¸'),
            (r'ì–´ë–¤ ê¸°ë¶„ì¸ì§€', 'ê¸ˆì§€: ì¶”ìƒì  ì§ˆë¬¸'),
            (r'ì–´ë–»ê²Œ.*ë˜ì…¨ëŠ”ì§€', 'ê¸ˆì§€: ì¶”ìƒì  ì§ˆë¬¸'),
            (r'ì™œ.*ê·¸ëŸ°ì§€', 'ê¸ˆì§€: ì›ì¸ ì¶”ê¶'),
            (r'ì–¸ì œ.*ë˜ì…¨ëŠ”ì§€', 'ê¸ˆì§€: ì‹œê°„ ì¶”ê¶'),
            (r'ì–´ë–¤.*ë³´ê³ .*ì‹ ê°€ìš”', 'ê¸ˆì§€: ì¶”ìƒì  ì§ˆë¬¸'),
            (r'ì–´ë–¤.*í”„ë¡œê·¸ë¨.*ë´', 'ê¸ˆì§€: ì¶”ìƒì  ì§ˆë¬¸'),
        ]
        
        for pattern, reason in banned_patterns:
            if re.search(pattern, response, re.IGNORECASE):
                logger.warning(f"âš ï¸ {reason} ê°ì§€: '{response}' â†’ ì¬ìƒì„± í•„ìš”")
                # ê¸ˆì§€ íŒ¨í„´ ë°œê²¬ ì‹œ ì•ˆì „í•œ ê³µê° ì‘ë‹µìœ¼ë¡œ ëŒ€ì²´
                response = self._generate_safe_response(user_message)
                break
        
        # 3. ìì—°ìŠ¤ëŸ¬ìš´ ì¡´ëŒ“ë§ í™•ì¸ (ê°•ì œ ë³€í™˜ X, ê²½ê³ ë§Œ)
        jondaemal_markers = ['ì„¸ìš”', 'ì…”ìš”', 'ìŠµë‹ˆë‹¤', 'ë„¤ìš”', 'ì–´ìš”', 'ì£ ']
        has_jondaemal = any(marker in response for marker in jondaemal_markers)
        
        if not has_jondaemal:
            logger.warning(f"âš ï¸ ì¡´ëŒ“ë§ ë¯¸í¡: '{response}'")
        
        return response
    
    def _generate_safe_response(self, user_message: str) -> str:
        """
        ê¸ˆì§€ íŒ¨í„´ ë°œê²¬ ì‹œ ì•ˆì „í•œ ê³µê° ì‘ë‹µ ìƒì„± (ë” ìì—°ìŠ¤ëŸ½ê²Œ)
        
        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            
        Returns:
            str: ì•ˆì „í•œ ê³µê° ì‘ë‹µ
        """
        # ê°ì • í‚¤ì›Œë“œ ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ê³µê° ì‘ë‹µ
        if any(word in user_message for word in ['ì•„í”„', 'í˜ë“¤', 'ê³ í†µ', 'í†µì¦']):
            return "ì•„ì´ê³ , ë§ì´ í˜ë“œì‹œê² ì–´ìš”. ê´œì°®ìœ¼ì‹ ê°€ìš”?"
        elif any(word in user_message for word in ['ì™¸ë¡­', 'ì“¸ì“¸', 'í˜¼ì', 'ì•„ë¬´ë„']):
            return "ì™¸ë¡œìš°ì‹œê² ì–´ìš”. ì €ë„ ê·¸ë˜ì„œ í•  ë§ ìˆì–´ìš”."
        elif any(word in user_message for word in ['ìŠ¬í”„', 'ìš°ìš¸', 'ì†ìƒ', 'ê±±ì •']):
            return "ì†ìƒí•˜ì‹œê² ì–´ìš”. ë¬´ìŠ¨ ì¼ ìˆìœ¼ì…¨ë‚˜ìš”?"
        elif any(word in user_message for word in ['ìì‹', 'ì•„ë“¤', 'ë”¸', 'ì†ì£¼']):
            return "ê°€ì¡±ë¶„ë“¤ ìƒê°ë‚˜ì‹œê² ì–´ìš”. ë§ì´ ë³´ê³  ì‹¶ìœ¼ì‹œê² ì–´ìš”."
        elif any(word in user_message for word in ['ê¸°ì¨', 'ì¢‹ì•„', 'ì¦ê±°', 'í–‰ë³µ']):
            return "ì¢‹ìœ¼ì‹œë„¤ìš”. ê¸°ë¶„ì´ ì¢‹ì•„ ë³´ì´ì„¸ìš”."
        else:
            return "ê·¸ëŸ¬ì‹œêµ¬ë‚˜. ì˜ ë“£ê³  ìˆì–´ìš”."
    
    def analyze_emotion(self, user_message: str):
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì˜ ê°ì • ë¶„ì„ (ì‹¤í–‰ ì‹œê°„ ì¸¡ì • í¬í•¨)
        
        Args:
            user_message: ë¶„ì„í•  ë©”ì‹œì§€
        
        Returns:
            tuple: (ê°ì • ë¶„ì„ ê²°ê³¼ dict, ì‹¤í–‰ ì‹œê°„)
        """
        try:
            start_time = time.time()
            logger.info(f"ğŸ˜Š ê°ì • ë¶„ì„ ì‹œì‘")
            
            prompt = f"""ë‹¤ìŒ ë©”ì‹œì§€ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
ê°ì • ìƒíƒœ: positive(ê¸ì •ì ), neutral(ì¤‘ë¦½), negative(ë¶€ì •ì ), concerned(ê±±ì •ë¨)
ê¸´ê¸‰ë„: low(ë‚®ìŒ), medium(ì¤‘ê°„), high(ë†’ìŒ) - ê±´ê°• ë¬¸ì œë‚˜ ê¸´ê¸‰ ìƒí™© ì—¬ë¶€

ë©”ì‹œì§€: {user_message}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "emotion": "ê°ì • ìƒíƒœ",
    "urgency": "ê¸´ê¸‰ë„",
    "keywords": ["ì£¼ìš”", "í‚¤ì›Œë“œ"],
    "summary": "í•œ ì¤„ ìš”ì•½"
}}
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200,
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            elapsed_time = time.time() - start_time
            
            logger.info(f"âœ… ê°ì • ë¶„ì„ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
            logger.info(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: {result}")
            
            return result, elapsed_time
        except Exception as e:
            logger.error(f"âŒ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    def extract_contextual_info(self, user_message: str, conversation_history: list = None) -> dict:
        """
        ëŒ€í™”ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ (ê°€ì¡±, ì·¨ë¯¸, ê±´ê°•, ì¼ìƒ íŒ¨í„´ ë“±)
        
        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            conversation_history: ì´ì „ ëŒ€í™” ê¸°ë¡
            
        Returns:
            dict: ì¶”ì¶œëœ í•µì‹¬ ì •ë³´
        """
        try:
            # ì „ì²´ ëŒ€í™” í…ìŠ¤íŠ¸ êµ¬ì„±
            full_conversation = ""
            if conversation_history:
                for msg in conversation_history[-10:]:  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ
                    role = "ì‚¬ìš©ì" if msg['role'] == 'user' else "AI"
                    full_conversation += f"{role}: {msg['content']}\n"
            full_conversation += f"ì‚¬ìš©ì: {user_message}"
            
            prompt = f"""ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì–´ë¥´ì‹ ì˜ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ëŒ€í™” ë‚´ìš©:
{full_conversation}

ì¶”ì¶œí•  ì •ë³´:
1. ê°€ì¡± ê´€ê³„ (ì•„ë“¤, ë”¸, ì†ì, ë©°ëŠë¦¬ ë“±)
2. ì·¨ë¯¸/ê´€ì‹¬ì‚¬ (TV, ë…ì„œ, ì‚°ì±…, ìš”ë¦¬ ë“±)
3. ê±´ê°• ìƒíƒœ (ì•½, ë³‘ì›, ì¦ìƒ ë“±)
4. ì¼ìƒ íŒ¨í„´ (ì‹œê°„ëŒ€ë³„ í™œë™, ìŠµê´€ ë“±)
5. ê±°ì£¼ì§€/í™˜ê²½ (ì§‘, ë™ë„¤, ì‹œì„¤ ë“±)

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "family": ["ê°€ì¡± ê´€ê³„ ì •ë³´"],
    "hobbies": ["ì·¨ë¯¸/ê´€ì‹¬ì‚¬"],
    "health": ["ê±´ê°• ê´€ë ¨ ì •ë³´"],
    "daily_patterns": ["ì¼ìƒ íŒ¨í„´"],
    "location": ["ê±°ì£¼ì§€/í™˜ê²½"],
    "keywords": ["ì£¼ìš” í‚¤ì›Œë“œ"]
}}

ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ë¡œ í‘œì‹œí•˜ì„¸ìš”."""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            logger.info(f"ğŸ“ ë§¥ë½ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ: {len(result.get('keywords', []))}ê°œ í‚¤ì›Œë“œ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ë§¥ë½ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {
                "family": [],
                "hobbies": [],
                "health": [],
                "daily_patterns": [],
                "location": [],
                "keywords": []
            }
    
    def _get_emotion_based_tone(self, emotion_context: dict) -> str:
        """
        ê°ì • ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ ì‘ë‹µ í†¤ ì¡°ì •
        
        Args:
            emotion_context: ê°ì • ë¶„ì„ ê²°ê³¼
            
        Returns:
            str: ê°ì •ì— ë§ëŠ” ì‘ë‹µ í†¤ ì§€ì‹œì‚¬í•­
        """
        emotion = emotion_context.get('emotion', 'neutral')
        urgency = emotion_context.get('urgency', 'low')
        keywords = emotion_context.get('keywords', [])
        
        tone_guidelines = {
            'negative': {
                'low': "ì–´ë¥´ì‹ ì´ ë¶€ì •ì ì¸ ê¸°ë¶„ì¼ ë•ŒëŠ” ë” ë”°ëœ»í•˜ê³  ìœ„ë¡œí•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”. 'ì•„ì´ê³ ', 'ë§ì´ í˜ë“œì…¨ê² ì–´ìš”' ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.",
                'medium': "ì–´ë¥´ì‹ ì´ ê±±ì •ìŠ¤ëŸ¬ì›Œí•  ë•ŒëŠ” ì•ˆì‹¬ì‹œí‚¤ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”. 'ê´œì°®ì„ ê±°ì˜ˆìš”', 'ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”' ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.",
                'high': "ê¸´ê¸‰í•˜ê±°ë‚˜ ì‹¬ê°í•œ ìƒí™©ì¼ ë•ŒëŠ” ì‹ ì¤‘í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”. 'ë³‘ì›ì— ê°€ë³´ì‹œëŠ” ê²Œ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”' ê°™ì€ ì¡°ì–¸ì„ í•˜ì„¸ìš”."
            },
            'concerned': {
                'low': "ê±±ì •ìŠ¤ëŸ¬ì›Œí•˜ëŠ” ì–´ë¥´ì‹ ì—ê²ŒëŠ” ì•ˆì‹¬ì‹œí‚¤ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”. 'ê´œì°®ì„ ê±°ì˜ˆìš”', 'ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”' ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.",
                'medium': "ì¤‘ê°„ ì •ë„ ê±±ì •ì¼ ë•ŒëŠ” í˜„ì‹¤ì ì´ë©´ì„œë„ ìœ„ë¡œí•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.",
                'high': "ì‹¬ê°í•œ ê±±ì •ì¼ ë•ŒëŠ” ì‹ ì¤‘í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
            },
            'positive': {
                'low': "ê¸ì •ì ì¸ ê¸°ë¶„ì¼ ë•ŒëŠ” í•¨ê»˜ ê¸°ë»í•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”. 'ì¢‹ìœ¼ì‹œë„¤ìš”', 'ê¸°ë¶„ì´ ì¢‹ì•„ ë³´ì´ì„¸ìš”' ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.",
                'medium': "ê¸°ìœ ì¼ì´ ìˆì„ ë•ŒëŠ” ë” í™œê¸°ì°¨ê²Œ ì‘ë‹µí•˜ì„¸ìš”.",
                'high': "ë§¤ìš° ê¸°ìœ ì¼ì¼ ë•ŒëŠ” í•¨ê»˜ ì¶•í•˜í•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
            },
            'neutral': {
                'low': "í‰ë²”í•œ ëŒ€í™”ì¼ ë•ŒëŠ” ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.",
                'medium': "ì¼ë°˜ì ì¸ ëŒ€í™”ì¼ ë•ŒëŠ” í¸ì•ˆí•œ í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.",
                'high': "ì¤‘ìš”í•œ ë‚´ìš©ì¼ ë•ŒëŠ” ì§„ì§€í•˜ë©´ì„œë„ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
            }
        }
        
        return tone_guidelines.get(emotion, {}).get(urgency, "ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.")
    
    def _build_personalization_context(self, contextual_info: dict) -> str:
        """
        ë§¥ë½ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸í™”ëœ ì‘ë‹µ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        
        Args:
            contextual_info: ì¶”ì¶œëœ ë§¥ë½ ì •ë³´
            
        Returns:
            str: ê°œì¸í™”ëœ ì‘ë‹µ ì§€ì‹œì‚¬í•­
        """
        context_parts = []
        
        # ê°€ì¡± ê´€ê³„
        if contextual_info.get('family'):
            family_info = ", ".join(contextual_info['family'])
            context_parts.append(f"ê°€ì¡±: {family_info} - ê°€ì¡± ì–˜ê¸°í•  ë•Œ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•˜ì„¸ìš”")
        
        # ì·¨ë¯¸/ê´€ì‹¬ì‚¬
        if contextual_info.get('hobbies'):
            hobbies_info = ", ".join(contextual_info['hobbies'])
            context_parts.append(f"ì·¨ë¯¸: {hobbies_info} - ê´€ì‹¬ì‚¬ì— ëŒ€í•´ ë¬¼ì–´ë³´ê±°ë‚˜ ì–¸ê¸‰í•˜ì„¸ìš”")
        
        # ê±´ê°• ìƒíƒœ
        if contextual_info.get('health'):
            health_info = ", ".join(contextual_info['health'])
            context_parts.append(f"ê±´ê°•: {health_info} - ê±´ê°• ìƒíƒœë¥¼ ì—¼ë ¤í•˜ë©° ë¬¼ì–´ë³´ì„¸ìš”")
        
        # ì¼ìƒ íŒ¨í„´
        if contextual_info.get('daily_patterns'):
            patterns_info = ", ".join(contextual_info['daily_patterns'])
            context_parts.append(f"ì¼ìƒ: {patterns_info} - ì¼ìƒ íŒ¨í„´ì„ ê¸°ì–µí•˜ê³  ì–¸ê¸‰í•˜ì„¸ìš”")
        
        # ê±°ì£¼ì§€/í™˜ê²½
        if contextual_info.get('location'):
            location_info = ", ".join(contextual_info['location'])
            context_parts.append(f"í™˜ê²½: {location_info} - ê±°ì£¼ì§€ë‚˜ í™˜ê²½ì— ëŒ€í•´ ì–¸ê¸‰í•˜ì„¸ìš”")
        
        if context_parts:
            return " | ".join(context_parts)
        return ""
    
    def _get_time_based_context(self, current_time: datetime = None) -> str:
        """
        í˜„ì¬ ì‹œê°„ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹œê°„ëŒ€ë³„ ë§ì¶¤ ì‘ë‹µ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        
        Args:
            current_time: í˜„ì¬ ì‹œê°„ (ê¸°ë³¸ê°’: í˜„ì¬ ì‹œê°„)
            
        Returns:
            str: ì‹œê°„ëŒ€ë³„ ì‘ë‹µ ì§€ì‹œì‚¬í•­
        """
        if not current_time:
            current_time = datetime.now()
        
        hour = current_time.hour
        weekday = current_time.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
        
        # ì‹œê°„ëŒ€ë³„ ì‘ë‹µ íŒ¨í„´
        time_patterns = {
            'morning': {
                'hours': range(6, 12),
                'context': "ì•„ì¹¨ ì‹œê°„ì…ë‹ˆë‹¤. 'ì•„ì¹¨ ë“œì…¨ì–´ìš”?', 'ì˜¤ëŠ˜ ì•„ì¹¨ì€ ì–´ë– ì„¸ìš”?' ê°™ì€ ì•„ì¹¨ ì¸ì‚¬ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í•˜ì„¸ìš”.",
                'topics': ["ì•„ì¹¨ ì‹ì‚¬", "ë‚ ì”¨", "ì˜¤ëŠ˜ ê³„íš", "ì ìë¦¬"]
            },
            'afternoon': {
                'hours': range(12, 18),
                'context': "ì˜¤í›„ ì‹œê°„ì…ë‹ˆë‹¤. 'ì ì‹¬ ë“œì…¨ì–´ìš”?', 'ì˜¤í›„ì— ë­ í•˜ì„¸ìš”?' ê°™ì€ ì˜¤í›„ ëŒ€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í•˜ì„¸ìš”.",
                'topics': ["ì ì‹¬", "ë‚®ì ", "TV", "ì‚°ì±…", "ì†ì"]
            },
            'evening': {
                'hours': range(18, 22),
                'context': "ì €ë… ì‹œê°„ì…ë‹ˆë‹¤. 'ì €ë… ì¤€ë¹„í•˜ì„¸ìš”?', 'ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ì–´ìš”?' ê°™ì€ ì €ë… ëŒ€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í•˜ì„¸ìš”.",
                'topics': ["ì €ë… ì‹ì‚¬", "í•˜ë£¨ ì •ë¦¬", "ê°€ì¡±", "TV í”„ë¡œê·¸ë¨"]
            },
            'night': {
                'hours': range(22, 24),
                'context': "ë°¤ ì‹œê°„ì…ë‹ˆë‹¤. 'ëŠ¦ìœ¼ì…¨ë„¤ìš”', 'í”¼ê³¤í•˜ì‹¤ ê²ƒ ê°™ì•„ìš”' ê°™ì€ ë°°ë ¤í•˜ëŠ” ë§ì„ ìì—°ìŠ¤ëŸ½ê²Œ í•˜ì„¸ìš”.",
                'topics': ["ì ìë¦¬", "í”¼ë¡œ", "ë‚´ì¼ ê³„íš"]
            },
            'late_night': {
                'hours': range(0, 6),
                'context': "ìƒˆë²½ ì‹œê°„ì…ë‹ˆë‹¤. 'ì¼ì° ì˜¤ì…¨ë„¤ìš”', 'ì  ëª» ì£¼ë¬´ì…¨ë‚˜ìš”?' ê°™ì€ ê±±ì •í•˜ëŠ” ë§ì„ ìì—°ìŠ¤ëŸ½ê²Œ í•˜ì„¸ìš”.",
                'topics': ["ì ", "ê±´ê°•", "ê±±ì •"]
            }
        }
        
        # ìš”ì¼ë³„ íŠ¹ë³„í•œ ë§¥ë½
        weekday_context = {
            0: "ì›”ìš”ì¼ì´ë„¤ìš”. ìƒˆë¡œìš´ í•œ ì£¼ ì‹œì‘ì´ì—ìš”.",
            1: "í™”ìš”ì¼ì´ë„¤ìš”. í•œ ì£¼ê°€ ì˜ í˜ëŸ¬ê°€ê³  ìˆì–´ìš”.",
            2: "ìˆ˜ìš”ì¼ì´ë„¤ìš”. í•œ ì£¼ì˜ ì¤‘ê°„ì´ì—ìš”.",
            3: "ëª©ìš”ì¼ì´ë„¤ìš”. ì£¼ë§ì´ ë‹¤ê°€ì˜¤ê³  ìˆì–´ìš”.",
            4: "ê¸ˆìš”ì¼ì´ë„¤ìš”. ì£¼ë§ì´ ê¸°ë‹¤ë ¤ì§€ì‹œê² ì–´ìš”.",
            5: "í† ìš”ì¼ì´ë„¤ìš”. ì£¼ë§ ì˜ ë³´ë‚´ì„¸ìš”.",
            6: "ì¼ìš”ì¼ì´ë„¤ìš”. íœ´ì¼ ì˜ ë³´ë‚´ì„¸ìš”."
        }
        
        # ì‹œê°„ëŒ€ ì°¾ê¸°
        current_pattern = None
        for pattern_name, pattern_info in time_patterns.items():
            if hour in pattern_info['hours']:
                current_pattern = pattern_info
                break
        
        if not current_pattern:
            current_pattern = time_patterns['morning']  # ê¸°ë³¸ê°’
        
        # ì‹œê°„ëŒ€ë³„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        time_context = current_pattern['context']
        
        # ìš”ì¼ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        weekday_info = weekday_context.get(weekday, "")
        if weekday_info:
            time_context += f" {weekday_info}"
        
        # êµ¬ì²´ì ì¸ ì‹œê°„ ì–¸ê¸‰
        if hour < 12:
            time_context += f" í˜„ì¬ {hour}ì‹œì…ë‹ˆë‹¤."
        elif hour < 18:
            time_context += f" í˜„ì¬ ì˜¤í›„ {hour-12}ì‹œì…ë‹ˆë‹¤."
        elif hour < 22:
            time_context += f" í˜„ì¬ ì €ë… {hour-12}ì‹œì…ë‹ˆë‹¤."
        else:
            time_context += f" í˜„ì¬ ë°¤ {hour-12}ì‹œì…ë‹ˆë‹¤."
        
        return time_context
    
    def generate_response(self, user_message: str, conversation_history: list = None, today_schedule: list = None, emotion_context: dict = None, contextual_info: dict = None):
        """
        LLM ì‘ë‹µ ìƒì„± (ì‹¤í–‰ ì‹œê°„ ì¸¡ì • í¬í•¨)
        
        Args:
            user_message: ì‚¬ìš©ìì˜ ë©”ì‹œì§€
            conversation_history: ì´ì „ ëŒ€í™” ê¸°ë¡ (ì˜µì…˜)
            today_schedule: ì–´ë¥´ì‹ ì˜ ì˜¤ëŠ˜ ì¼ì • ë¦¬ìŠ¤íŠ¸ (ì˜µì…˜)
                ì˜ˆ: [{"task": "ë³‘ì› ê²€ì§„", "time": "ì˜¤ì „ 10ì‹œ"}, {"task": "ì•½ ë¨¹ê¸°", "time": "ì˜¤í›„ 2ì‹œ"}]
            emotion_context: ê°ì • ë¶„ì„ ê²°ê³¼ (ì˜µì…˜)
                ì˜ˆ: {"emotion": "negative", "urgency": "medium", "keywords": ["ì•„í”„", "í˜ë“¤"]}
            contextual_info: ë§¥ë½ ì •ë³´ (ì˜µì…˜)
                ì˜ˆ: {"family": ["ì•„ë“¤", "ì†ì"], "hobbies": ["TV", "ì‚°ì±…"]}
        
        Returns:
            tuple: (AI ì‘ë‹µ, ì‹¤í–‰ ì‹œê°„)
        """
        try:
            start_time = time.time()
            logger.info(f"ğŸ¤– LLM ì‘ë‹µ ìƒì„± ì‹œì‘")
            logger.info(f"ğŸ“¥ ì‚¬ìš©ì ì…ë ¥: {user_message}")
            
            # âš¡ ìºì‹œ ì²´í¬ ì œê±° (ë¶ˆí•„ìš”í•œ ì˜¤ë²„í—¤ë“œ)
            # í˜„ì¬ ìºì‹œëŠ” ë§¤ìš° ì œí•œì ì´ë©° ì‹¤ì œ ëŒ€í™”ì—ì„œëŠ” ê±°ì˜ ì‘ë™í•˜ì§€ ì•ŠìŒ
            # ìºì‹œ ì²´í¬ ë¡œì§ ì œê±°ë¡œ ì˜¤ë²„í—¤ë“œ ê°ì†Œ
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [{"role": "system", "content": self.elderly_care_prompt}]
            
            # ê°ì • ê¸°ë°˜ ì‘ë‹µ í†¤ ì¡°ì •
            if emotion_context:
                emotion_tone = self._get_emotion_based_tone(emotion_context)
                if emotion_tone:
                    messages.append({"role": "system", "content": f"[ê°ì • ê¸°ë°˜ ì‘ë‹µ í†¤] {emotion_tone}"})
                    logger.info(f"ğŸ˜Š ê°ì • ê¸°ë°˜ í†¤ ì ìš©: {emotion_context.get('emotion', 'unknown')}")
            
            # ë§¥ë½ ì •ë³´ ê¸°ë°˜ ê°œì¸í™” ì‘ë‹µ
            if contextual_info:
                personalization_context = self._build_personalization_context(contextual_info)
                if personalization_context:
                    messages.append({"role": "system", "content": f"[ê°œì¸í™” ë§¥ë½] {personalization_context}"})
                    logger.info(f"ğŸ‘¤ ê°œì¸í™” ë§¥ë½ ì ìš©: {len(contextual_info.get('keywords', []))}ê°œ í‚¤ì›Œë“œ")
            
            # ì‹œê°„ëŒ€ë³„ ë§ì¶¤ ì‘ë‹µ ì»¨í…ìŠ¤íŠ¸
            time_context = self._get_time_based_context()
            if time_context:
                messages.append({"role": "system", "content": f"[ì‹œê°„ëŒ€ë³„ ì»¨í…ìŠ¤íŠ¸] {time_context}"})
                logger.info(f"ğŸ• ì‹œê°„ëŒ€ë³„ ì»¨í…ìŠ¤íŠ¸ ì ìš©")
            
            # ì˜¤ëŠ˜ ì¼ì •ì´ ìˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€ (ìµœëŒ€ 2ê°œ, ë” ê°„ê²°í•˜ê²Œ)
            if today_schedule:
                schedule_items = []
                for item in today_schedule[:2]:  # ìµœëŒ€ 2ê°œë§Œ (í† í° ì ˆì•½)
                    task = item.get('task') or item.get('title')
                    if task:
                        time_str = item.get('time', '')
                        schedule_items.append(f"{task}({time_str})" if time_str else task)
                
                if schedule_items:
                    # ë” ê°„ê²°í•œ ì»¨í…ìŠ¤íŠ¸
                    schedule_context = ", ".join(schedule_items)
                    messages.append({"role": "system", "content": f"ì¼ì •:{schedule_context}"})
                    logger.info(f"ğŸ“… {schedule_context}")
            
            # ëŒ€í™” ê¸°ë¡ì´ ìˆìœ¼ë©´ ì¶”ê°€ (ìµœê·¼ 4í„´ = 8ê°œ ë©”ì‹œì§€, ë§¥ë½ ìœ ì§€)
            if conversation_history:
                messages.extend(conversation_history[-8:])
            
            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append({"role": "user", "content": user_message})
            
            # GPT-4o-minië¡œ ì‘ë‹µ ìƒì„± (Speed Priority)
            api_start_time = time.time()
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=25,  # ì§§ê³  ê°„ê²°í•˜ê²Œ (1ë¬¸ì¥ ê¶Œì¥)
                temperature=0.5,  # ì†ë„ ìš°ì„  (0.3ì€ ëŠë¦¼)
            )
            
            # TTFT ì¸¡ì • (Time To First Token)
            ttft = time.time() - api_start_time
            
            ai_response = response.choices[0].message.content
            
            # í›„ì²˜ë¦¬: ê·œì¹™ ê°•ì œ ì ìš©
            ai_response = self._post_process_response(ai_response, user_message)
            
            elapsed_time = time.time() - start_time
            
            logger.info(f"âœ… LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ")
            logger.info(f"â±ï¸ ì „ì²´ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ | TTFT: {ttft:.2f}ì´ˆ")
            logger.info(f"ğŸ“¤ AI ì‘ë‹µ: {ai_response}")
            
            return ai_response, elapsed_time
        except Exception as e:
            logger.error(f"âŒ LLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    async def generate_response_streaming(self, user_message: str, conversation_history: list = None, today_schedule: list = None, emotion_context: dict = None, contextual_info: dict = None):
        """
        ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ LLM ì‘ë‹µ ìƒì„± (ì‹¤ì‹œê°„ ìµœì í™”)
        
        ì´ ë©”ì„œë“œëŠ” OpenAIì˜ stream=True ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬
        ì‘ë‹µì´ ìƒì„±ë˜ëŠ” ì¦‰ì‹œ yieldë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        ì‚¬ìš©ìëŠ” AIê°€ ë§í•˜ëŠ” ê²ƒì„ ê±°ì˜ ì‹¤ì‹œê°„ìœ¼ë¡œ ë“¤ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        Args:
            user_message: ì‚¬ìš©ì(ì–´ë¥´ì‹ )ì˜ ë©”ì‹œì§€
            conversation_history: ì´ì „ ëŒ€í™” ê¸°ë¡ (ì˜µì…˜)
            today_schedule: ì–´ë¥´ì‹ ì˜ ì˜¤ëŠ˜ ì¼ì • ë¦¬ìŠ¤íŠ¸ (ì˜µì…˜)
                ì˜ˆ: [{"task": "ë³‘ì› ê²€ì§„", "time": "ì˜¤ì „ 10ì‹œ"}, {"task": "ì•½ ë¨¹ê¸°", "time": "ì˜¤í›„ 2ì‹œ"}]
            emotion_context: ê°ì • ë¶„ì„ ê²°ê³¼ (ì˜µì…˜)
                ì˜ˆ: {"emotion": "negative", "urgency": "medium", "keywords": ["ì•„í”„", "í˜ë“¤"]}
            contextual_info: ë§¥ë½ ì •ë³´ (ì˜µì…˜)
                ì˜ˆ: {"family": ["ì•„ë“¤", "ì†ì"], "hobbies": ["TV", "ì‚°ì±…"]}
        
        Yields:
            str: ìƒì„±ëœ í…ìŠ¤íŠ¸ ì²­í¬ (ë‹¨ì–´ ë˜ëŠ” êµ¬ ë‹¨ìœ„)
        
        Example:
            async for chunk in llm_service.generate_response_streaming("ì•ˆë…•í•˜ì„¸ìš”"):
                print(chunk, end='', flush=True)
        """
        try:
            start_time = time.time()
            logger.info(f"ğŸ¤– LLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹œì‘")
            logger.info(f"ğŸ“¥ ì‚¬ìš©ì ì…ë ¥: {user_message}")
            
            # âš¡ ìºì‹œ ì²´í¬ ì œê±° (ë¶ˆí•„ìš”í•œ ì˜¤ë²„í—¤ë“œ)
            # í˜„ì¬ ìºì‹œëŠ” ë§¤ìš° ì œí•œì ì´ë©° ì‹¤ì œ ëŒ€í™”ì—ì„œëŠ” ê±°ì˜ ì‘ë™í•˜ì§€ ì•ŠìŒ
            # ìºì‹œ ì²´í¬ ë¡œì§ ì œê±°ë¡œ ì˜¤ë²„í—¤ë“œ ê°ì†Œ
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [{"role": "system", "content": self.elderly_care_prompt}]
            
            # ê°ì • ê¸°ë°˜ ì‘ë‹µ í†¤ ì¡°ì •
            if emotion_context:
                emotion_tone = self._get_emotion_based_tone(emotion_context)
                if emotion_tone:
                    messages.append({"role": "system", "content": f"[ê°ì • ê¸°ë°˜ ì‘ë‹µ í†¤] {emotion_tone}"})
                    logger.info(f"ğŸ˜Š ê°ì • ê¸°ë°˜ í†¤ ì ìš©: {emotion_context.get('emotion', 'unknown')}")
            
            # ë§¥ë½ ì •ë³´ ê¸°ë°˜ ê°œì¸í™” ì‘ë‹µ
            if contextual_info:
                personalization_context = self._build_personalization_context(contextual_info)
                if personalization_context:
                    messages.append({"role": "system", "content": f"[ê°œì¸í™” ë§¥ë½] {personalization_context}"})
                    logger.info(f"ğŸ‘¤ ê°œì¸í™” ë§¥ë½ ì ìš©: {len(contextual_info.get('keywords', []))}ê°œ í‚¤ì›Œë“œ")
            
            # ì‹œê°„ëŒ€ë³„ ë§ì¶¤ ì‘ë‹µ ì»¨í…ìŠ¤íŠ¸
            time_context = self._get_time_based_context()
            if time_context:
                messages.append({"role": "system", "content": f"[ì‹œê°„ëŒ€ë³„ ì»¨í…ìŠ¤íŠ¸] {time_context}"})
                logger.info(f"ğŸ• ì‹œê°„ëŒ€ë³„ ì»¨í…ìŠ¤íŠ¸ ì ìš©")
            
            # ì˜¤ëŠ˜ ì¼ì •ì´ ìˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€ (ìµœëŒ€ 2ê°œ, ë” ê°„ê²°í•˜ê²Œ)
            if today_schedule:
                schedule_items = []
                for item in today_schedule[:2]:  # ìµœëŒ€ 2ê°œë§Œ (í† í° ì ˆì•½)
                    task = item.get('task') or item.get('title')
                    if task:
                        time_str = item.get('time', '')
                        schedule_items.append(f"{task}({time_str})" if time_str else task)
                
                if schedule_items:
                    # ë” ê°„ê²°í•œ ì»¨í…ìŠ¤íŠ¸
                    schedule_context = ", ".join(schedule_items)
                    messages.append({"role": "system", "content": f"ì¼ì •:{schedule_context}"})
                    logger.info(f"ğŸ“… {schedule_context}")
            
            # ëŒ€í™” ê¸°ë¡ì´ ìˆìœ¼ë©´ ì¶”ê°€ (ìµœê·¼ 4í„´ = 8ê°œ ë©”ì‹œì§€, ë§¥ë½ ìœ ì§€)
            if conversation_history:
                messages.extend(conversation_history[-8:])
            
            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append({"role": "user", "content": user_message})
            
            # ìŠ¤íŠ¸ë¦¬ë° API í˜¸ì¶œ
            # stream=Trueë¡œ ì„¤ì •í•˜ë©´ ì‘ë‹µì´ ìƒì„±ë˜ëŠ” ì¦‰ì‹œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
            api_start_time = time.time()
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=25,  # ì§§ê³  ê°„ê²°í•˜ê²Œ (1ë¬¸ì¥ ê¶Œì¥)
                temperature=0.5,  # ì†ë„ ìš°ì„  (0.3ì€ ëŠë¦¼)
                stream=True  # â­ í•µì‹¬: ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
            )
            
            full_response = []  # ì „ì²´ ì‘ë‹µ ì €ì¥ìš©
            ttft = None  # TTFT ì¸¡ì •ìš©
            
            # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°›ì€ ì²­í¬ë¥¼ ì¦‰ì‹œ yield
            for chunk in stream:
                # delta.contentê°€ ìˆìœ¼ë©´ ìƒì„±ëœ í…ìŠ¤íŠ¸ ì¡°ê°ì…ë‹ˆë‹¤
                if chunk.choices[0].delta.content:
                    # TTFT ì¸¡ì • (ì²« í† í° ìˆ˜ì‹  ì‹œì )
                    if ttft is None:
                        ttft = time.time() - api_start_time
                        logger.info(f"âš¡ ì²« í† í° ìˆ˜ì‹ ! TTFT: {ttft:.2f}ì´ˆ")
                    
                    content = chunk.choices[0].delta.content
                    full_response.append(content)
                    yield content  # ì¦‰ì‹œ ë°˜í™˜ (TTSê°€ ë°”ë¡œ ì²˜ë¦¬ ê°€ëŠ¥)
            
            elapsed_time = time.time() - start_time
            final_text = "".join(full_response)
            
            logger.info(f"âœ… LLM ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ")
            logger.info(f"â±ï¸ ì „ì²´ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ | TTFT: {ttft:.2f}ì´ˆ" if ttft else f"â±ï¸ ì „ì²´ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            logger.info(f"ğŸ“¤ ì „ì²´ ì‘ë‹µ: {final_text}")
            
        except Exception as e:
            logger.error(f"âŒ LLM ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨: {e}")
            yield "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def summarize_call_conversation(self, conversation_history: list):
        """
        í†µí™” ë‚´ìš©ì„ ì–´ë¥´ì‹ ì˜ 1ì¸ì¹­ ì¼ê¸°ë¡œ ë³€í™˜ (ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ì •í™•ì„± ê· í˜•)
        
        Args:
            conversation_history: ëŒ€í™” ê¸°ë¡ [{"role": "user", "content": "..."}, ...]
        
        Returns:
            str: 1ì¸ì¹­ ì¼ê¸° í˜•ì‹ì˜ ë‚´ìš©
        """
        try:
            # ëŒ€í™” ê¸°ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            conversation_text = "\n".join([
                f"{'ì–´ë¥´ì‹ ' if msg['role'] == 'user' else 'AI'}: {msg['content']}"
                for msg in conversation_history
            ])
            
            prompt = f"""
ë‹¤ìŒì€ ì–´ë¥´ì‹ ê³¼ AI ë¹„ì„œì˜ í†µí™” ë‚´ìš©ì…ë‹ˆë‹¤. 
ì´ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì–´ë¥´ì‹ ì´ ì§ì ‘ ì“´ ê²ƒ ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ì¼ê¸°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

âš ï¸ í•„ìˆ˜ ì¤€ìˆ˜ì‚¬í•­:
- ëŒ€í™”ì—ì„œ ì‹¤ì œë¡œ ì–¸ê¸‰ëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš” (ì¶”ì¸¡, ê°€ì •, ì°½ì‘ ê¸ˆì§€)
- ëŒ€í™”ì— ì—†ëŠ” í–‰ë™, ê°ì •, ê³„íšì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”
- AIì˜ ì§ˆë¬¸ì´ë‚˜ ë°˜ì‘ì€ ì¼ê¸°ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš” (ì–´ë¥´ì‹ ì˜ ë§ë§Œ ì‚¬ìš©)

ì‘ì„± ê°€ì´ë“œ:
- "ì˜¤ëŠ˜ì€", "ì˜¤ëŠ˜" ë“±ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‹œì‘ ("ì•ˆë…•í•˜ì„¸ìš”" ê¸ˆì§€)
- 1ì¸ì¹­ êµ¬ì–´ì²´ ì‚¬ìš© ("~í–ˆì–´", "~ê±°ì•¼", "~ë„¤" ë“±)
- ëŒ€í™” ìˆœì„œëŒ€ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
- ë¬¸ì¥ì€ ê°„ê²°í•˜ê²Œ, í•˜ì§€ë§Œ ê°ì •ì€ ì§„ì†”í•˜ê²Œ
- 5-8ë¬¸ì¥ ì •ë„ë¡œ ì‘ì„±
- ë§ˆì¹˜ ì†ìœ¼ë¡œ ì§ì ‘ ì“´ ì¼ê¸°ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ

í†µí™” ë‚´ìš©:
{conversation_text}

ì¼ê¸°:
"""
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=400, # ì ì • ê¸¸ì´ë¡œ ì¡°ì •
                temperature=0.5, # ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ì •í™•ì„±ì˜ ê· í˜•
            )
            
            summary = response.choices[0].message.content
            logger.info(f"âœ… í†µí™” ì¼ê¸°ê¸° ìƒì„± ì™„ë£Œ")
            return summary
        except Exception as e:
            logger.error(f"âŒ í†µí™” ì¼ê¸° ìƒì„± ì‹¤íŒ¨: {e}")
            return "ì¼ê¸° ìƒì„± ì‹¤íŒ¨"
    
    def extract_schedule_from_conversation(self, conversation_text: str):
            """
            í†µí™” ë‚´ìš©ì—ì„œ ì¼ì • ì •ë³´ ì¶”ì¶œ (ë²„ì „ 7: ì˜ì–´ í”„ë¡¬í”„íŠ¸, í•œêµ­ì–´ ì‘ë‹µ)
            """
            try:
                from datetime import datetime, timedelta
                
                # ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ë‚ ì§œ í•´ì„
                today = datetime.now()
                tomorrow = today + timedelta(days=1)
                day_after_tomorrow = today + timedelta(days=2)
                
                # ìš”ì¼ ê³„ì‚°
                weekdays_kr = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
                current_weekday = weekdays_kr[today.weekday()]
                
                # í˜„ì¬ ì‹œê°„ì„ í”„ë¡¬í”„íŠ¸ì— ì œê³µí•˜ì—¬ ì‹œê°„ í•´ì„ ì˜¤ë¥˜ ìµœì†Œí™”
                current_time = datetime.now().strftime('%H:%M') 
                
                prompt = f"""
    Extract confirmed future schedules from the following conversation and return them in JSON format. The response MUST be in KOREAN.
    Current Time: {today.strftime('%Y-%m-%d')} ({current_weekday}) {current_time}
    Tomorrow: {tomorrow.strftime('%Y-%m-%d')}
    
    Conversation:
    {conversation_text}
    
    Extraction Rules:
    1. Extract only **confirmed and specific future schedules**. (Exclude past events, completed actions, 'about to do' actions, and vague/uncertain expressions).
    2. Convert relative dates (e.g., 'tomorrow') to **absolute dates** (YYYY-MM-DD format).
    3. If time is specified, include it in due_time as **HH:MM 24-hour format**.
       - **Time Inference:** If AM/PM is missing, infer the time based on the schedule's nature (e.g., hospital, meal) and the current time (e.g., '7 o'clock' is inferred as 07:00 or 19:00 based on context).
       - If no time, use **null**.
    4. **Category:** Choose one of MEDICINE, HOSPITAL, EXERCISE, MEAL, OTHER.
    5. **Title/Description:** Use only information found in the conversation. Write in **concise noun phrases or action-oriented verb phrases**. DO NOT use narrative sentence endings (~í–ˆë‹¤, ~ë°›ëŠ”ë‹¤, ~ìˆì–´ìš”, etc.) or hallucinations.
    6. Extract a maximum of 5 schedules (in order of importance).
    
    Respond in the following JSON format (use an empty array if no schedules are found):
    {{
      "schedules": [
        {{
          "title": "ê°€ì¡±ê³¼ì˜ ì €ë… ì‹ì‚¬",
          "description": "ê°€ì¡±ë“¤ê³¼ í•¨ê»˜ ì €ë… ì‹ì‚¬í•˜ê¸°", 
          "category": "MEAL", 
          "due_date": "{tomorrow.strftime('%Y-%m-%d')}",
          "due_time": "18:30"
        }}
      ]
    }}
    
    Note: Put schedules inside the 'schedules' array. If no schedules, return {{"schedules": []}}.
    """
                
                # (ë‚˜ë¨¸ì§€ ì‹¤í–‰ ë¡œì§ì€ ë™ì¼í•˜ê²Œ ìœ ì§€)
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=800,
                    temperature=0.2, 
                    response_format={"type": "json_object"}
                )
                
                # ì‘ë‹µì´ í•œêµ­ì–´ë¡œ ì˜¤ë„ë¡ í”„ë¡¬í”„íŠ¸ì— 'The response MUST be in KOREAN.' ëª…ì‹œ
                result = response.choices[0].message.content
                logger.info(f"âœ… ì¼ì • ì¶”ì¶œ ì™„ë£Œ ")
                return result
                
            except Exception as e:
                logger.error(f"âŒ ì¼ì • ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                return '{"schedules": []}'
    
    def test_conversation_quality(self, test_messages: list):
        """
        ëŒ€í™” í’ˆì§ˆ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ (ê°œì„  ì „í›„ ë¹„êµìš©)
        
        Args:
            test_messages: í…ŒìŠ¤íŠ¸í•  ì‚¬ìš©ì ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            dict: í…ŒìŠ¤íŠ¸ ê²°ê³¼ (ì¡´ëŒ“ë§ ì¤€ìˆ˜ìœ¨, ì‘ë‹µ ì ì ˆì„±, ì‘ë‹µ ì†ë„)
        """
        results = {
            "total_tests": len(test_messages),
            "polite_responses": 0,
            "appropriate_responses": 0,
            "response_times": [],
            "responses": []
        }
        
        for i, message in enumerate(test_messages):
            logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ {i+1}/{len(test_messages)}: {message}")
            
            # ì‘ë‹µ ìƒì„± ë° ì‹œê°„ ì¸¡ì •
            response, elapsed_time = self.generate_response(message)
            results["response_times"].append(elapsed_time)
            
            # ì¡´ëŒ“ë§ ì²´í¬ (í•œêµ­ì–´ ì¡´ëŒ“ë§ íŒ¨í„´)
            polite_patterns = ["ìŠµë‹ˆë‹¤", "ì„¸ìš”", "ì‹œì–´ìš”", "ì‹œì§€ìš”", "ì‹œì£ ", "ì„¸ìš”", "ì‹œë„¤ìš”", "ì‹œêµ¬ë‚˜"]
            is_polite = any(pattern in response for pattern in polite_patterns)
            if is_polite:
                results["polite_responses"] += 1
            
            # ì‘ë‹µ ì ì ˆì„± ì²´í¬ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
            appropriate_keywords = ["ì–´ë¥´ì‹ ", "ê±´ê°•", "ì•½", "ì‹ì‚¬", "ìš´ë™", "ë‚ ì”¨", "ì•ˆë…•", "ì–´ë–»ê²Œ", "ì§€ë‚´"]
            is_appropriate = any(keyword in response for keyword in appropriate_keywords)
            if is_appropriate:
                results["appropriate_responses"] += 1
            
            results["responses"].append({
                "input": message,
                "output": response,
                "is_polite": is_polite,
                "is_appropriate": is_appropriate,
                "response_time": elapsed_time
            })
            
            logger.info(f"ğŸ“ ì‘ë‹µ: {response}")
            logger.info(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            logger.info(f"ğŸ™ ì¡´ëŒ“ë§ ì‚¬ìš©: {'âœ…' if is_polite else 'âŒ'}")
            logger.info(f"ğŸ’¬ ì ì ˆí•œ ì‘ë‹µ: {'âœ…' if is_appropriate else 'âŒ'}")
            logger.info("-" * 50)
        
        # ìµœì¢… ê²°ê³¼ ê³„ì‚°
        results["polite_rate"] = (results["polite_responses"] / results["total_tests"]) * 100
        results["appropriate_rate"] = (results["appropriate_responses"] / results["total_tests"]) * 100
        results["avg_response_time"] = sum(results["response_times"]) / len(results["response_times"])
        
        logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
        logger.info(f"   ì¡´ëŒ“ë§ ì¤€ìˆ˜ìœ¨: {results['polite_rate']:.1f}%")
        logger.info(f"   ì‘ë‹µ ì ì ˆì„±: {results['appropriate_rate']:.1f}%")
        logger.info(f"   í‰ê·  ì‘ë‹µ ì‹œê°„: {results['avg_response_time']:.2f}ì´ˆ")
        
        return results
