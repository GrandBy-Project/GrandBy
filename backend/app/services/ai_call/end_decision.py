import time
import re
from dataclasses import dataclass

# ì§§ì€ ê¸ì • ì‘ë‹µ íŒ¨í„´ (ëŒ€í™” ì˜ì§€ ë¶€ì¡± ê°ì§€ìš©)
SHORT_ACKS = [r"^(ì‘|ì–´|ìŒ|ë„¤|ì˜ˆ|ì‘ì‘|ë„¤ë„¤)[.!?]?$"]

def match_any(text: str, patterns: list[str]) -> bool:
    """ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)"""
    t = (text or "").strip()
    for p in patterns:
        if re.search(p, t, flags=re.IGNORECASE):
            return True
    return False

@dataclass
class EndDecisionSignals:
    # í•„ìˆ˜ ë¹„-ë””í´íŠ¸ í•„ë“œëŠ” ë¨¼ì € ì„ ì–¸
    call_start_time: float
    # ì„ íƒ í•„ë“œë“¤
    last_user_speech_time: float | None = None
    last_ai_closing_time: float | None = None
    last_utterance_time: float | None = None  # ë§ˆì§€ë§‰ ë°œí™”ê°€ ì–¸ì œ ë°œìƒí–ˆëŠ”ì§€ (í‚¤ì›Œë“œ ì‹œíš¨ íŒë‹¨ìš©)
    short_ack_count: int = 0
    task_completed: bool = False
    last_user_utterance: str = ""
    max_call_seconds: int = 300  # 5ë¶„ ìƒí•œ
    max_time_warning_sent: bool = False  # ìµœëŒ€ ì‹œê°„ ê²½ê³  ì „ì†¡ ì—¬ë¶€
    warning_before_end_seconds: int = 10  # ì¢…ë£Œ ì „ ê²½ê³  ì‹œê°„ (ì´ˆ)

class EndDecisionEngine:
    def __init__(self, soft_threshold=70, use_llm=True):
        self.soft_threshold = soft_threshold
        self.use_llm = use_llm  # LLM ì‚¬ìš© ì—¬ë¶€
        self.llm_service = None  # ë‚˜ì¤‘ì— ì£¼ì…

    def set_llm_service(self, llm_service):
        """LLM ì„œë¹„ìŠ¤ ì£¼ì…"""
        self.llm_service = llm_service

    def score(self, s: EndDecisionSignals) -> tuple[int, dict]:
        """
        í´ë°±ìš© ì¢…ë£Œ íŒë‹¨ ì ìˆ˜ ê³„ì‚° (LLM ë¯¸ì‚¬ìš© ì‹œì—ë§Œ ì‚¬ìš©)
        ìµœì†Œí•œì˜ ë¡œì§ë§Œ ìœ ì§€
        
        Returns:
            tuple[int, dict]: (ì´ì , ìƒì„¸ ë‚´ì—­)
        """
        now = time.time()
        score = 0
        breakdown = {}

        # â±ï¸ 1. ìµœëŒ€ í†µí™” ì‹œê°„ ì´ˆê³¼ (ì¦‰ì‹œ í•˜ë“œ ì¢…ë£Œ)
        call_duration = now - s.call_start_time
        if call_duration >= s.max_call_seconds:
            breakdown["max_time_exceeded"] = 100
            breakdown["call_duration_sec"] = int(call_duration)
            return 100, breakdown
        
        breakdown["call_duration_sec"] = int(call_duration)

        # ğŸ”„ 2. ì§§ì€ ì‘ë‹µ ë°˜ë³µ
        if s.short_ack_count >= 3:
            score += 20
            breakdown["short_ack_repeat"] = f"+20 (count:{s.short_ack_count})"

        # ğŸ”‡ 3. ì‚¬ìš©ì ì¹¨ë¬µ ì‹œê°„ ê¸°ë°˜
        if s.last_user_speech_time is not None:
            silence = now - s.last_user_speech_time
            if silence >= 20:
                score = 70
                breakdown["silence_20s+"] = f"70 (ì†Œí”„íŠ¸) - {int(silence)}ì´ˆ ì¹¨ë¬µ"
                breakdown["total_score"] = 70
                return 70, breakdown
            elif silence >= 15:
                score += 40
                breakdown["silence_15s+"] = f"+40 ({int(silence)}s)"
            elif silence >= 10:
                score += 25
                breakdown["silence_10s+"] = f"+25 ({int(silence)}s)"

        # ğŸ• 4. AI í´ë¡œì§• ì´í›„ ë¬´ì‘ë‹µ
        if s.last_ai_closing_time:
            closing_elapsed = now - s.last_ai_closing_time
            user_responded_after_closing = (
                s.last_user_speech_time is not None and 
                s.last_user_speech_time > s.last_ai_closing_time
            )
            
            if not user_responded_after_closing:
                if closing_elapsed >= 10:
                    score = 100
                    breakdown["soft_closing_hard_timeout"] = f"100 (í•˜ë“œ) - {int(closing_elapsed)}ì´ˆ ë¬´ì‘ë‹µ"
                    breakdown["total_score"] = 100
                    return 100, breakdown
                elif closing_elapsed >= 5:
                    score += 30
                    breakdown["soft_closing_timeout"] = f"+30 ({int(closing_elapsed)}s)"
        
        final_score = max(0, min(score, 100))
        breakdown["total_score"] = final_score
        
        return final_score, breakdown

    def score_with_llm(self, s: EndDecisionSignals, conversation_history: list = None) -> tuple[int, dict]:
        """
        LLM ê¸°ë°˜ ì¢…ë£Œ íŒë‹¨ ì ìˆ˜ ê³„ì‚°
        
        Args:
            s: ì¢…ë£Œ íŒë‹¨ ì‹ í˜¸
            conversation_history: ëŒ€í™” ê¸°ë¡
            
        Returns:
            tuple[int, dict]: (ì´ì , ìƒì„¸ ë‚´ì—­)
        """
        now = time.time()
        score = 0
        breakdown = {}
        
        # ê¸°ì¡´ ì ìˆ˜ ê³„ì‚° ë¡œì§
        call_duration = now - s.call_start_time
        breakdown["call_duration_sec"] = int(call_duration)
        
        # â±ï¸ 1. ìµœëŒ€ í†µí™” ì‹œê°„ ì´ˆê³¼ (ì¦‰ì‹œ í•˜ë“œ ì¢…ë£Œ)
        if call_duration >= s.max_call_seconds:
            breakdown["max_time_exceeded"] = 100
            return 100, breakdown
        
        # âš ï¸ 1-1. ìµœëŒ€ í†µí™” ì‹œê°„ ì„ë°• ê°ì§€ (ì¢…ë£Œ ì•ˆë‚´ ë©˜íŠ¸)
        time_until_end = s.max_call_seconds - call_duration
        if not s.max_time_warning_sent and time_until_end <= s.warning_before_end_seconds:
            # ê²½ê³  ì „ì†¡ í”Œë˜ê·¸ ì„¤ì •
            s.max_time_warning_sent = True
            breakdown["max_time_warning"] = f"ê²½ê³  ì „ì†¡ (ë‚¨ì€ ì‹œê°„: {int(time_until_end)}ì´ˆ)"
            breakdown["total_score"] = -1  # íŠ¹ë³„ ê°’: ê²½ê³  ì „ì†¡ í•„ìš”
            return -1, breakdown
        
        # ğŸ¤– 2. LLM ê¸°ë°˜ ì¢…ë£Œ ì˜ë„ ë¶„ì„ (ìµœìš°ì„ )
        if self.use_llm and self.llm_service and s.last_user_utterance:
            try:
                llm_analysis = self.llm_service.analyze_call_ending_context(
                    s.last_user_utterance,
                    conversation_history
                )
                
                end_intent = llm_analysis.get("end_intent", "none")
                confidence = llm_analysis.get("confidence", 0.0)
                reason = llm_analysis.get("reason", "")
                
                breakdown["llm_analysis"] = {
                    "intent": end_intent,
                    "confidence": confidence,
                    "reason": reason
                }
                
                # LLM ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ ì ìˆ˜ ë¶€ì—¬
                if end_intent == "explicit" and confidence >= 0.85:
                    # ëª…ì‹œì  ì¢…ë£Œ ì˜ë„ â†’ ì¦‰ì‹œ í•˜ë“œ ì¢…ë£Œ
                    score = 100
                    breakdown["llm_explicit_end"] = f"100 (í•˜ë“œ ì¢…ë£Œ) - {reason}"
                    breakdown["total_score"] = 100
                    return 100, breakdown
                    
                # elif end_intent == "soft" and confidence >= 0.6:
                #     # ë¶€ë“œëŸ¬ìš´ ì¢…ë£Œ ì‹ í˜¸ â†’ ì†Œí”„íŠ¸ í´ë¡œì§•
                #     score = 70
                #     breakdown["llm_soft_end"] = f"70 (ì†Œí”„íŠ¸ í´ë¡œì§•) - {reason}"
                #     breakdown["total_score"] = 70
                #     return 70, breakdown
                    
                elif end_intent == "none":
                    # ì¢…ë£Œ ì˜ë„ ì—†ìŒ â†’ ê¸°ì¡´ ì ìˆ˜ ê³„ì‚° ë¡œì§ ê³„ì†
                    breakdown["llm_no_end"] = f"ê³„ì† ëŒ€í™” - {reason}"
                
            except Exception as e:
                breakdown["llm_error"] = f"LLM ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        
        # ğŸ”„ 3. ì‹œê°„ ê¸°ë°˜ ë¡œì§ (LLM ë³´ì¡°)
        # ì§§ì€ ì‘ë‹µ ë°˜ë³µ (LLMì´ ë†“ì¹  ìˆ˜ ìˆëŠ” íŒ¨í„´)
        if s.short_ack_count >= 3:
            score += 20
            breakdown["short_ack_repeat"] = f"+20 (count:{s.short_ack_count})"

        # ğŸ”‡ 4. ì‚¬ìš©ì ì¹¨ë¬µ ì‹œê°„ (ì‹œê°„ ê¸°ë°˜ íŒë‹¨) - ìˆ˜ì • í•„ìš”í•  ìˆ˜ ìˆìŒ
        if s.last_user_speech_time is not None:
            silence = now - s.last_user_speech_time
            if silence >= 20:
                score = 70
                breakdown["silence_20s+"] = f"70 (ì†Œí”„íŠ¸) - {int(silence)}ì´ˆ ì¹¨ë¬µ"
                breakdown["total_score"] = 70
                return 70, breakdown
            elif silence >= 15:
                score += 40
                breakdown["silence_15s+"] = f"+40 ({int(silence)}s)"
            elif silence >= 10:
                score += 25
                breakdown["silence_10s+"] = f"+25 ({int(silence)}s)"

        # ğŸ• 5. AI í´ë¡œì§• ì´í›„ ë¬´ì‘ë‹µ (ì‹œê°„ ê¸°ë°˜ íŒë‹¨) - ìˆ˜ì • í•„ìš”í•  ìˆ˜ ìˆìŒ
        if s.last_ai_closing_time:
            closing_elapsed = now - s.last_ai_closing_time
            user_responded_after_closing = (
                s.last_user_speech_time is not None and 
                s.last_user_speech_time > s.last_ai_closing_time
            )
            
            if not user_responded_after_closing:
                if closing_elapsed >= 10:
                    score = 100
                    breakdown["soft_closing_hard_timeout"] = f"100 (í•˜ë“œ) - {int(closing_elapsed)}ì´ˆ ë¬´ì‘ë‹µ"
                    breakdown["total_score"] = 100
                    return 100, breakdown
                elif closing_elapsed >= 5:
                    score += 30
                    breakdown["soft_closing_timeout"] = f"+30 ({int(closing_elapsed)}s)"
        
        final_score = max(0, min(score, 100))
        breakdown["total_score"] = final_score
        
        return final_score, breakdown

    def decide(self, s: EndDecisionSignals) -> tuple[str, int, dict]:
        """
        ì¢…ë£Œ íŒë‹¨ ë° ì ìˆ˜/ìƒì„¸ ë‚´ì—­ ë°˜í™˜ (ê¸°ì¡´ ë°©ì‹ - í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
        
        Returns:
            tuple[str, int, dict]: (íŒë‹¨ ê²°ê³¼, ì´ì , ìƒì„¸ ë‚´ì—­)
        """
        sc, breakdown = self.score(s)
        if sc >= 100:
            decision = "hard_end"
        elif sc >= self.soft_threshold:
            decision = "soft_close"
        else:
            decision = "keep"
        
        return decision, sc, breakdown
    
    def should_analyze_with_llm(self, s: EndDecisionSignals) -> bool:
        """
        LLM ë¶„ì„ì´ í•„ìš”í•œ ìƒí™©ì¸ì§€ íŒë‹¨
        
        Args:
            s: ì¢…ë£Œ íŒë‹¨ ì‹ í˜¸
            
        Returns:
            bool: LLM ë¶„ì„ì´ í•„ìš”í•˜ë©´ True
        """
        # ìµœê·¼ 5ì´ˆ ì´ë‚´ ì‚¬ìš©ì ë°œí™”ê°€ ìˆì—ˆì„ ë•Œë§Œ LLM ì‚¬ìš©
        if s.last_utterance_time:
            elapsed = time.time() - s.last_utterance_time
            return elapsed < 5.0
        return False
    
    def decide_smart(self, s: EndDecisionSignals, conversation_history: list = None) -> tuple[str, int, dict]:
        """
        ğŸš€ ìŠ¤ë§ˆíŠ¸ ì¢…ë£Œ íŒë‹¨ (í•„ìš”í•  ë•Œë§Œ LLM ì‚¬ìš© - ì„±ëŠ¥ ìµœì í™”)
        
        ì‚¬ìš©ìê°€ ë°©ê¸ˆ ë°œí™”í–ˆì„ ë•Œë§Œ LLMìœ¼ë¡œ ë§¥ë½ ë¶„ì„í•˜ê³ ,
        ê·¸ ì™¸ì—ëŠ” ë¹ ë¥¸ ì‹œê°„ ê¸°ë°˜ ë¡œì§ë§Œ ì‚¬ìš©
        
        Args:
            s: ì¢…ë£Œ íŒë‹¨ ì‹ í˜¸
            conversation_history: ëŒ€í™” ê¸°ë¡
            
        Returns:
            tuple[str, int, dict]: (íŒë‹¨ ê²°ê³¼, ì´ì , ìƒì„¸ ë‚´ì—­)
        """
        # ì‚¬ìš©ìê°€ ë°©ê¸ˆ(5ì´ˆ ì´ë‚´) ë°œí™”í–ˆìœ¼ë©´ LLM ì‚¬ìš©
        if self.should_analyze_with_llm(s):
            sc, breakdown = self.score_with_llm(s, conversation_history)
            breakdown["analysis_mode"] = "LLM (recent utterance)"
        else:
            # ì‹œê°„ ê¸°ë°˜ë§Œ (ë¹ ë¦„)
            sc, breakdown = self.score(s)
            breakdown["analysis_mode"] = "Time-based (fast)"
        
        if sc >= 100:
            decision = "hard_end"
        elif sc >= self.soft_threshold:
            decision = "soft_close"
        else:
            decision = "keep"
        
        return decision, sc, breakdown

def is_short_ack(text: str) -> bool:
    return match_any(text or "", SHORT_ACKS)