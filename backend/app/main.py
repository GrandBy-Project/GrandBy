"""
Grandby FastAPI Application
ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
"""

from fastapi import FastAPI, Request, WebSocket, WebSocketDisconnect, Form, HTTPException, Depends, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, PlainTextResponse
from fastapi.exceptions import RequestValidationError
from pydantic import ValidationError
from pydantic import BaseModel
from contextlib import asynccontextmanager
import logging
import json
import base64
import asyncio
import os
import tempfile
from typing import Dict, Optional
import audioop
from datetime import datetime
from sqlalchemy.orm import Session
import time

from twilio.twiml.voice_response import VoiceResponse, Connect, Stream

from app.routers import auth, users, calls, diaries, todos, notifications, dashboard
from app.config import settings, is_development
from app.database import test_db_connection, get_db
from app.services.ai_call.stt_service import STTService
from app.services.ai_call.tts_service import TTSService
from app.services.ai_call.llm_service import LLMService
from app.services.ai_call.twilio_service import TwilioService

# ë¡œê±° ì„¤ì • (ì‹œê°„ í¬í•¨)
logging.basicConfig(
    level=settings.LOG_LEVEL,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ë° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
stt_service = STTService()
tts_service = TTSService()
llm_service = LLMService()

# WebSocket ì—°ê²° ë° ëŒ€í™” ì„¸ì…˜ ê´€ë¦¬
active_connections: Dict[str, WebSocket] = {}
conversation_sessions: Dict[str, list] = {}


# ==================== AudioProcessor ====================

class AudioProcessor:
    """
    ì˜¤ë””ì˜¤ ì²˜ë¦¬ í´ë˜ìŠ¤ - ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë²„í¼ë§ ë° ì¹¨ë¬µ ê°ì§€
    
    Twilioì—ì„œ ìˆ˜ì‹ í•œ mulaw ì˜¤ë””ì˜¤ë¥¼ ë²„í¼ë§í•˜ê³ ,
    ì¹¨ë¬µì„ ê°ì§€í•˜ì—¬ STT ì²˜ë¦¬ ì‹œì ì„ ê²°ì •í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, call_sid: str):
        self.call_sid = call_sid
        self.audio_buffer = []  # ì˜¤ë””ì˜¤ ì²­í¬ ë²„í¼
        self.transcript_buffer = []  # ì‹¤ì‹œê°„ STT ê²°ê³¼ ë²„í¼
        self.is_speaking = False  # ì‚¬ìš©ìê°€ ë§í•˜ê³  ìˆëŠ”ì§€ ì—¬ë¶€
        # mulaw RMS ë²”ìœ„ì— ë§ê²Œ ì„ê³„ê°’ ì¡°ì • (0~127)
        self.silence_threshold = 20  # ì¹¨ë¬µ ê°ì§€ ì„ê³„ê°’ (RMS)
        self.silence_duration = 0  # í˜„ì¬ ì¹¨ë¬µ ì§€ì† ì‹œê°„
        self.max_silence = 1.0  # â­ 1ì´ˆ ì¹¨ë¬µ í›„ STT ì²˜ë¦¬ (ì‘ë‹µ ì†ë„ ìµœì í™”)

        # ì´ˆê¸° ë…¸ì´ì¦ˆ í•„í„°ë§
        self.warmup_chunks = 0  # ë°›ì€ ì²­í¬ ìˆ˜
        self.warmup_threshold = 25  # ì²˜ìŒ 0.5ì´ˆ ë¬´ì‹œ
        
        # ì—°ì† ìŒì„± ê°ì§€
        self.voice_chunks = 0  # ì—°ì† ìŒì„± ê°ì§€ ì¹´ìš´í„°
        self.voice_threshold = 3  # ìµœì†Œ 3ë²ˆ ì—°ì† ê°ì§€
        
        # TTS ì¬ìƒ ìƒíƒœ (ì—ì½” ë°©ì§€)
        self.is_bot_speaking = False
        self.bot_silence_delay = 0
        
    # def add_audio_chunk(self, audio_data: bytes):
    #     """ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€"""
    #     self.audio_buffer.append(audio_data)
        
    #     # ìŒì„± í™œë™ ê°ì§€ (RMS - Root Mean Square)
    #     rms = audioop.rms(audio_data, 2)  # 16-bit audio
        
    #     if rms > self.silence_threshold:
    #         self.is_speaking = True
    #         self.silence_duration = 0
    #     else:
    #         if self.is_speaking:
    #             self.silence_duration += 0.02  # 20ms per chunk

    def add_audio_chunk(self, audio_data: bytes):
        """ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€ ë° ìŒì„± í™œë™ ê°ì§€"""
        self.audio_buffer.append(audio_data)
        
        # ì›Œë°ì—…: ì´ˆê¸° ì²­í¬ ë¬´ì‹œ (ì—°ê²° ë…¸ì´ì¦ˆ ë°©ì§€)
        self.warmup_chunks += 1
        if self.warmup_chunks <= self.warmup_threshold:
            if self.warmup_chunks == 1:
                logger.info("â³ ì˜¤ë””ì˜¤ ì´ˆê¸°í™” ì¤‘...")
            return
        
        # AIê°€ ë§í•˜ëŠ” ë™ì•ˆ + ì¢…ë£Œ í›„ 1ì´ˆê°„ ì‚¬ìš©ì ì…ë ¥ ë¬´ì‹œ (ì—ì½” ë°©ì§€)
        if self.is_bot_speaking or self.bot_silence_delay > 0:
            if self.bot_silence_delay > 0:
                self.bot_silence_delay -= 1
                if self.bot_silence_delay == 0:
                    logger.info("âœ… AI ì‘ë‹µ ì¢…ë£Œ í›„ ëŒ€ê¸° ì™„ë£Œ, ì‚¬ìš©ì ì…ë ¥ ì¬ê°œ")
            return
        
        # RMS ê³„ì‚° (ìŒëŸ‰ ì¸¡ì •)
        rms = audioop.rms(audio_data, 1)
        
        # ë¹„ì •ìƒì ìœ¼ë¡œ í° RMS ê°’ í•„í„°ë§ (ì—°ê²°ìŒ, ì—ëŸ¬ ë“±)
        if rms > 100:
            logger.warning(f"âš ï¸  ë¹„ì •ìƒì ì¸ RMS ë¬´ì‹œ: {rms}")
            self.voice_chunks = 0
            return
        
        # ìŒì„± í™œë™ ê°ì§€
        if rms > self.silence_threshold:
            self.voice_chunks += 1
            
            # ì—°ì†ìœ¼ë¡œ ì—¬ëŸ¬ ë²ˆ ê°ì§€ë˜ì–´ì•¼ ìŒì„±ìœ¼ë¡œ ì¸ì •
            if self.voice_chunks >= self.voice_threshold:
                if not self.is_speaking:
                    logger.info(f"ğŸ¤ [ìŒì„± ê°ì§€] ë§í•˜ê¸° ì‹œì‘ (RMS: {rms})")
                self.is_speaking = True
                self.silence_duration = 0
        else:
            # ì¡°ìš©í•˜ë©´ ìŒì„± ì¹´ìš´í„° ë¦¬ì…‹
            self.voice_chunks = 0
            
            # ì´ì „ì— ë§í•˜ê³  ìˆì—ˆë‹¤ë©´ ì¹¨ë¬µ ì¹´ìš´í„° ì¦ê°€
            if self.is_speaking:
                if self.silence_duration == 0:
                    logger.info(f"ğŸ”‡ [ì¹¨ë¬µ ê°ì§€] ë§ì„ ë©ˆì¶¤")
                
                self.silence_duration += 0.02  # 20ms per chunk
                
                # ì¹¨ë¬µ ì§„í–‰ ìƒí™© (0.5ì´ˆë§ˆë‹¤)
                if int(self.silence_duration * 10) % 5 == 0:
                    logger.debug(f"â±ï¸  ì¹¨ë¬µ: {self.silence_duration:.1f}ì´ˆ / {self.max_silence}ì´ˆ")
                
    def should_process(self) -> bool:
        """ì˜¤ë””ì˜¤ ì²˜ë¦¬ê°€ í•„ìš”í•œì§€ í™•ì¸ (ì‚¬ìš©ìê°€ ë§ì„ ë©ˆì·„ëŠ”ì§€)"""
        return (self.is_speaking and
                self.silence_duration >= self.max_silence and 
                len(self.audio_buffer) > 0)
    
    def get_audio(self) -> bytes:
        """
        ë²„í¼ë§ëœ ì˜¤ë””ì˜¤ ê°€ì ¸ì˜¤ê¸° ë° ì´ˆê¸°í™”
        
        Returns:
            bytes: ë³‘í•©ëœ ì˜¤ë””ì˜¤ ë°ì´í„° (mulaw í¬ë§·)
        """
        audio = b''.join(self.audio_buffer)
        self.audio_buffer = []
        self.is_speaking = False
        self.silence_duration = 0
        return audio
    
    def add_transcript(self, text: str):
        """
        ì‹¤ì‹œê°„ ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ ë²„í¼ì— ì¶”ê°€
        
        Args:
            text: ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        if text and text.strip():
            self.transcript_buffer.append(text)
            logger.debug(f"ğŸ“ í…ìŠ¤íŠ¸ ë²„í¼ ì¶”ê°€: {len(self.transcript_buffer)}ê°œ ë¬¸ì¥")
    
    def get_full_transcript(self) -> str:
        """
        ì „ì²´ ëŒ€í™” ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        
        Returns:
            str: ê³µë°±ìœ¼ë¡œ ê²°í•©ëœ ì „ì²´ ëŒ€í™” í…ìŠ¤íŠ¸
        """
        return " ".join(self.transcript_buffer)
    
    def start_bot_speaking(self):
        """AI ì‘ë‹µ ì‹œì‘ - ì‚¬ìš©ì ì…ë ¥ ì°¨ë‹¨ (ì—ì½” ë°©ì§€)"""
        logger.info("ğŸ¤– [ì—ì½” ë°©ì§€] AI ì‘ë‹µ ì¤‘ - ì‚¬ìš©ì ì…ë ¥ ì°¨ë‹¨")
        self.is_bot_speaking = True
        # ê¸°ì¡´ ìƒíƒœ ì´ˆê¸°í™”
        self.is_speaking = False
        self.voice_chunks = 0
        self.silence_duration = 0
    
    def stop_bot_speaking(self):
        """AI ì‘ë‹µ ì¢…ë£Œ - 1ì´ˆ ëŒ€ê¸° í›„ ì‚¬ìš©ì ì…ë ¥ ì¬ê°œ"""
        self.is_bot_speaking = False
        self.bot_silence_delay = 50  # 50ê°œ ì²­í¬ = 1ì´ˆ ëŒ€ê¸°
        logger.info("ğŸ¤– [ì—ì½” ë°©ì§€] AI ì‘ë‹µ ì¢…ë£Œ - 1ì´ˆ í›„ ì‚¬ìš©ì ì…ë ¥ ì¬ê°œ")


# ==================== Helper Functions ====================

async def transcribe_audio_realtime(audio_data: bytes) -> tuple[str, float]:
    """
    ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì‹¤ì‹œê°„ ì²­í¬ ê¸°ë°˜ STT)
    
    Twilio mulaw í¬ë§·ì„ WAVë¡œ ë³€í™˜ í›„ ì‹¤ì‹œê°„ STT ì²˜ë¦¬í•©ë‹ˆë‹¤.
    ìƒˆë¡œìš´ transcribe_audio_chunk() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        audio_data: Twilioì—ì„œ ë°›ì€ mulaw ì˜¤ë””ì˜¤ ë°ì´í„°
    
    Returns:
        tuple: (ë³€í™˜ëœ í…ìŠ¤íŠ¸, ì‹¤í–‰ ì‹œê°„)
    """
    try:
        import wave
        import io
        
        # mulawë¥¼ 16-bit PCMìœ¼ë¡œ ë³€í™˜
        try:
            pcm_data = audioop.ulaw2lin(audio_data, 2)
        except Exception as conv_error:
            logger.error(f"âŒ mulaw ë³€í™˜ ì˜¤ë¥˜: {conv_error}")
            return "", 0
        
        # PCM ë°ì´í„°ë¥¼ WAV í¬ë§·ìœ¼ë¡œ ë³€í™˜ (ë©”ëª¨ë¦¬ ë‚´)
        wav_io = io.BytesIO()
        with wave.open(wav_io, 'wb') as wav_file:
            wav_file.setnchannels(1)      # Mono
            wav_file.setsampwidth(2)      # 16-bit (2 bytes)
            wav_file.setframerate(8000)   # 8kHz (Twilio ìƒ˜í”Œë ˆì´íŠ¸)
            wav_file.writeframes(pcm_data)
        
        wav_data = wav_io.getvalue()
        logger.debug(f"ğŸ“ WAV ë³€í™˜ ì™„ë£Œ: {len(wav_data)} bytes")
        
        # ì‹¤ì‹œê°„ STT ë³€í™˜ (ë¹„ë™ê¸° ì²˜ë¦¬)
        transcript, stt_time = await stt_service.transcribe_audio_chunk(
            wav_data,
            language="ko"
        )
        
        return transcript, stt_time
        
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return "", 0


async def convert_and_send_audio(websocket: WebSocket, stream_sid: str, text: str):
    """
    ë‹¨ì¼ ë¬¸ì¥ì„ TTS ë³€í™˜í•˜ê³  Twilioë¡œ ì¦‰ì‹œ ì „ì†¡ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
    
    ì´ í•¨ìˆ˜ëŠ” LLM ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ë¬¸ì¥ì´ ì™„ì„±ë  ë•Œë§ˆë‹¤ í˜¸ì¶œë©ë‹ˆë‹¤.
    ì‚¬ìš©ìëŠ” AIê°€ ë§í•˜ëŠ” ê²ƒì„ ê±°ì˜ ì‹¤ì‹œê°„ìœ¼ë¡œ ë“¤ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ì²˜ë¦¬ í”Œë¡œìš°:
    1. ë¬¸ì¥ TTS ë³€í™˜ (ë¹„ë™ê¸°)
    2. WAV â†’ mulaw ë³€í™˜
    3. Base64 ì¸ì½”ë”©
    4. Twilio WebSocketìœ¼ë¡œ ì „ì†¡
    
    Args:
        websocket: Twilio WebSocket ì—°ê²°
        stream_sid: Twilio Stream SID
        text: ë³€í™˜í•  ë¬¸ì¥
    """
    try:
        import wave
        import io
        
        # 1. TTS ë³€í™˜ (ë¬¸ì¥ ë‹¨ìœ„, ë¹„ë™ê¸°)
        audio_data, tts_time = await tts_service.text_to_speech_sentence(text)
        
        if not audio_data:
            logger.warning(f"âš ï¸ TTS ë³€í™˜ ì‹¤íŒ¨, ê±´ë„ˆëœ€: {text[:30]}...")
            return
        
        # 2. WAV â†’ mulaw ë³€í™˜ (Twilio í˜¸í™˜)
        wav_io = io.BytesIO(audio_data)
        with wave.open(wav_io, 'rb') as wav_file:
            channels = wav_file.getnchannels()
            sample_width = wav_file.getsampwidth()
            framerate = wav_file.getframerate()
            pcm_data = wav_file.readframes(wav_file.getnframes())
        
        # Stereo â†’ Mono ë³€í™˜ (í•„ìš” ì‹œ)
        if channels == 2:
            pcm_data = audioop.tomono(pcm_data, sample_width, 1, 1)
        
        # ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜: TwilioëŠ” 8kHz ìš”êµ¬
        if framerate != 8000:
            pcm_data, _ = audioop.ratecv(pcm_data, sample_width, 1, framerate, 8000, None)
        
        # PCM â†’ mulaw ë³€í™˜
        mulaw_data = audioop.lin2ulaw(pcm_data, 2)
        
        # 3. Base64 ì¸ì½”ë”©
        audio_base64 = base64.b64encode(mulaw_data).decode('utf-8')
        
        # 4. Twilioë¡œ ì²­í¬ ë‹¨ìœ„ ì „ì†¡
        chunk_size = 8000  # 8KB ì²­í¬
        for i in range(0, len(audio_base64), chunk_size):
            chunk = audio_base64[i:i + chunk_size]
            
            message = {
                "event": "media",
                "streamSid": stream_sid,
                "media": {
                    "payload": chunk
                }
            }
            
            await websocket.send_text(json.dumps(message))
            await asyncio.sleep(0.02)  # ë¶€ë“œëŸ¬ìš´ ì¬ìƒì„ ìœ„í•œ ì‘ì€ ì§€ì—°
        
        logger.info(f"âœ… ë¬¸ì¥ ì „ì†¡ ì™„ë£Œ ({tts_time:.2f}ì´ˆ): {text[:30]}...")
        
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë””ì˜¤ ë³€í™˜/ì „ì†¡ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())


async def process_streaming_response(
    websocket: WebSocket,
    stream_sid: str,
    user_text: str,
    conversation_history: list,
    audio_processor=None
) -> str:
    """
    ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ LLM â†’ TTS â†’ Twilio ì „ì†¡ì„ ë³‘ë ¬ ì²˜ë¦¬
    
    ì´ê²ƒì´ í•µì‹¬ ìµœì í™” í•¨ìˆ˜ì…ë‹ˆë‹¤!
    
    ë™ì‘ ë°©ì‹:
    1. LLMì´ ë‹¨ì–´/êµ¬ë¥¼ ìƒì„±í•˜ë©´ ì¦‰ì‹œ ë°›ê¸° ì‹œì‘
    2. ë¬¸ì¥ì´ ì™„ì„±ë˜ë©´ (. ! ? ê°ì§€) ì¦‰ì‹œ TTS ë³€í™˜
    3. TTS ë³€í™˜ê³¼ ë™ì‹œì— ë‹¤ìŒ ë¬¸ì¥ LLM ìƒì„± ì§„í–‰
    4. ë³€í™˜ëœ ìŒì„±ì„ ë°”ë¡œ Twilioë¡œ ì „ì†¡
    
    ê²°ê³¼: ì‚¬ìš©ìëŠ” AIê°€ ìƒê°í•˜ëŠ” ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ëŠë‚Œ
    
    Args:
        websocket: Twilio WebSocket ì—°ê²°
        stream_sid: Twilio Stream SID  
        user_text: ì‚¬ìš©ì ë°œí™” ì „ì²´ í…ìŠ¤íŠ¸
        conversation_history: ëŒ€í™” ê¸°ë¡
    
    Returns:
        str: ìƒì„±ëœ ì „ì²´ AI ì‘ë‹µ
    """
    import re
    
    # TTS ì‹œì‘ ì•Œë¦¼ (ì—ì½” ë°©ì§€)
    if audio_processor:
        audio_processor.start_bot_speaking()
    
    try:
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸš€ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        logger.info(f"{'='*60}")
        
        pipeline_start = time.time()
        
        # ë¬¸ì¥ ë²„í¼ ë° ì „ì²´ ì‘ë‹µ ì €ì¥
        sentence_buffer = ""
        full_response = []
        sentence_tasks = []  # ë³‘ë ¬ TTS íƒœìŠ¤í¬ ì¶”ì 
        
        # LLM ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ (ë¹„ë™ê¸° ìƒì„±ê¸°)
        async for chunk in llm_service.generate_response_streaming(
            user_text,
            conversation_history
        ):
            sentence_buffer += chunk
            full_response.append(chunk)
            
            # ë¬¸ì¥ ì¢…ë£Œ ê°ì§€: ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ
            if re.search(r'[.!?\n]', chunk):
                # ì™„ì„±ëœ ë¬¸ì¥ ì¶”ì¶œ
                sentences = re.split(r'([.!?\n]+)', sentence_buffer)
                
                # ë¬¸ì¥ê³¼ êµ¬ë‘ì ì„ ìŒìœ¼ë¡œ ì²˜ë¦¬
                for i in range(0, len(sentences)-1, 2):
                    sentence = sentences[i] + (sentences[i+1] if i+1 < len(sentences) else "")
                    sentence = sentence.strip()
                    
                    if sentence:
                        logger.info(f"ğŸ“ ë¬¸ì¥ ì™„ì„±: {sentence}")
                        
                        # ì¦‰ì‹œ TTS ë³€í™˜ ë° ì „ì†¡ (ë¹„ë™ê¸° íƒœìŠ¤í¬ë¡œ ì‹¤í–‰)
                        # ì—¬ëŸ¬ ë¬¸ì¥ì´ ë™ì‹œì— ì²˜ë¦¬ë  ìˆ˜ ìˆìŒ (ë³‘ë ¬ ì²˜ë¦¬)
                        task = asyncio.create_task(
                            convert_and_send_audio(websocket, stream_sid, sentence)
                        )
                        sentence_tasks.append(task)
                
                # ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ë¬¸ì¥ì€ ë²„í¼ì— ìœ ì§€
                sentence_buffer = sentences[-1] if len(sentences) % 2 == 1 else ""
        
        # ë‚¨ì€ ë²„í¼ ì²˜ë¦¬ (ë§ˆì§€ë§‰ ë¬¸ì¥)
        if sentence_buffer.strip():
            logger.info(f"ğŸ“ ë§ˆì§€ë§‰ ë¬¸ì¥: {sentence_buffer}")
            task = asyncio.create_task(
                convert_and_send_audio(websocket, stream_sid, sentence_buffer)
            )
            sentence_tasks.append(task)
        
        # ëª¨ë“  TTS ë³€í™˜/ì „ì†¡ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        if sentence_tasks:
            await asyncio.gather(*sentence_tasks, return_exceptions=True)
        
        pipeline_time = time.time() - pipeline_start
        final_text = "".join(full_response)
        
        logger.info(f"\n{'='*60}")
        logger.info(f"âœ… ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
        logger.info(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {pipeline_time:.2f}ì´ˆ")
        logger.info(f"ğŸ“¤ ì „ì²´ ì‘ë‹µ: {final_text}")
        logger.info(f"{'='*60}\n")
        
        return final_text
        
    except Exception as e:
        logger.error(f"âŒ ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return ""
    finally:
        # TTS ì¢…ë£Œ ì•Œë¦¼ (ì—ì½” ë°©ì§€)
        if audio_processor:
            audio_processor.stop_bot_speaking()


async def send_audio_to_twilio_with_tts(websocket: WebSocket, stream_sid: str, text: str, audio_processor=None):
    """
    TTS Serviceë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ í›„ Twilio WebSocketìœ¼ë¡œ ì „ì†¡
    WAV â†’ mulaw ë³€í™˜ í¬í•¨
    
    Args:
        websocket: Twilio WebSocket ì—°ê²°
        stream_sid: Twilio Stream SID
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        audio_processor: AudioProcessor ì¸ìŠ¤í„´ìŠ¤ (ì—ì½” ë°©ì§€ìš©)
    """
    # TTS ì‹œì‘ ì•Œë¦¼ (ì—ì½” ë°©ì§€)
    if audio_processor:
        audio_processor.start_bot_speaking()
    
    try:
        import wave
        import io
        
        # TTS Serviceë¡œ ìŒì„± ìƒì„± (WAV íŒŒì¼ë¡œ ì €ì¥ë¨)
        audio_file_path, tts_time = tts_service.text_to_speech(text)
        
        # TTS ì‹¤íŒ¨ ì²´í¬
        if not audio_file_path or tts_time == 0:
            logger.error("âŒ TTS ë³€í™˜ ì‹¤íŒ¨ - ì‘ë‹µì´ Noneì´ê±°ë‚˜ ì‹œê°„ì´ 0ì´ˆ")
            return
        
        logger.info(f"âœ… TTS ì™„ë£Œ ({tts_time:.2f}ì´ˆ): {audio_file_path}")
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(audio_file_path):
            logger.error(f"âŒ TTS íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {audio_file_path}")
            return
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(audio_file_path)
        logger.info(f"ğŸ“ ìƒì„±ëœ íŒŒì¼ í¬ê¸°: {file_size} bytes")
        
        if file_size == 0:
            logger.error("âŒ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤! TTS API ë¬¸ì œ ê°€ëŠ¥ì„±")
            return
        
        try:
            # íŒŒì¼ í—¤ë” í™•ì¸
            with open(audio_file_path, 'rb') as f:
                header = f.read(12)
                logger.info(f"ğŸ“„ íŒŒì¼ í—¤ë”: {header.hex() if header else 'EMPTY'}")
                
                if len(header) == 0:
                    logger.error("âŒ í—¤ë”ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                    return
                
                # WAV íŒŒì¼ ê²€ì¦
                if header[:4] == b'RIFF' and header[8:12] == b'WAVE':
                    logger.info("âœ… ì •ìƒ WAV íŒŒì¼ í™•ì¸")
                elif header[:3] == b'ID3' or header[:2] == b'\xff\xfb':
                    logger.error("âŒ MP3 íŒŒì¼ì…ë‹ˆë‹¤! response_formatì´ wavë¡œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    return
                else:
                    logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ í˜•ì‹: {header[:4]}")
                    return

            # WAV íŒŒì¼ ì½ê¸° (wave ëª¨ë“ˆë§Œ ì‚¬ìš©)
            with wave.open(audio_file_path, 'rb') as wav_file:
                channels = wav_file.getnchannels()
                sample_width = wav_file.getsampwidth()
                framerate = wav_file.getframerate()
                n_frames = wav_file.getnframes()
                
                logger.info(f"ğŸµ TTS WAV ì •ë³´:")
                logger.info(f"  - ì±„ë„: {channels}ch")
                logger.info(f"  - ë¹„íŠ¸: {sample_width*8}bit")
                logger.info(f"  - ìƒ˜í”Œë ˆì´íŠ¸: {framerate}Hz")
                logger.info(f"  - í”„ë ˆì„ ìˆ˜: {n_frames}")
                
                pcm_data = wav_file.readframes(n_frames)
                logger.info(f"  - PCM ë°ì´í„°: {len(pcm_data)} bytes")

            # Stereo â†’ Mono ë³€í™˜ (í•„ìš”ì‹œ)
            if channels == 2:
                logger.info("ğŸ”„ Stereo â†’ Mono ë³€í™˜ ì¤‘...")
                pcm_data = audioop.tomono(pcm_data, sample_width, 1, 1)
                logger.info(f"âœ… Mono ë³€í™˜ ì™„ë£Œ: {len(pcm_data)} bytes")

            # ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜ (TwilioëŠ” 8kHz ìš”êµ¬)
            if framerate != 8000:
                logger.info(f"ğŸ”„ ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜: {framerate}Hz â†’ 8000Hz")
                pcm_data, _ = audioop.ratecv(pcm_data, sample_width, 1, framerate, 8000, None)
                logger.info(f"âœ… ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜ ì™„ë£Œ: {len(pcm_data)} bytes")

            # PCM â†’ mulaw ë³€í™˜
            logger.info("ğŸ”„ PCM â†’ mulaw ë³€í™˜ ì¤‘...")
            mulaw_data = audioop.lin2ulaw(pcm_data, 2)
            logger.info(f"âœ… mulaw ë³€í™˜ ì™„ë£Œ: {len(mulaw_data)} bytes")
            
        except wave.Error as wave_err:
            logger.error(f"âŒ WAV íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {wave_err}")
            import traceback
            logger.error(traceback.format_exc())
            return
        except Exception as conv_error:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ë³€í™˜ ì˜¤ë¥˜: {type(conv_error).__name__}: {conv_error}")
            import traceback
            logger.error(traceback.format_exc())
            return
        finally:
            # TTSë¡œ ìƒì„±ëœ ì„ì‹œ MP3 íŒŒì¼ ì‚­ì œ
            if os.path.exists(audio_file_path):
                os.unlink(audio_file_path)
        
        # mulaw ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©
        audio_base64 = base64.b64encode(mulaw_data).decode('utf-8')
        
        logger.info(f"ğŸ“¤ ì˜¤ë””ì˜¤ ì „ì†¡ ì‹œì‘: {len(mulaw_data)} bytes (mulaw 8kHz)")
        
        # ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì „ì†¡ (Twilio ì œí•œ ê³ ë ¤)
        chunk_size = 8000  # 8KB chunks
        for i in range(0, len(audio_base64), chunk_size):
            chunk = audio_base64[i:i + chunk_size]
            
            message = {
                "event": "media",
                "streamSid": stream_sid,
                "media": {
                    "payload": chunk
                }
            }
            
            await websocket.send_text(json.dumps(message))
            await asyncio.sleep(0.02)  # ì‘ì€ ì§€ì—°ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ì¬ìƒ
        
        logger.info("âœ… ìŒì„± ì „ì†¡ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ ìŒì„± ì „ì†¡ ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        # TTS ì¢…ë£Œ ì•Œë¦¼ (ì—ì½” ë°©ì§€)
        if audio_processor:
            audio_processor.stop_bot_speaking()


# Lifespan ì´ë²¤íŠ¸ (startup/shutdown)
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸"""
    # Startup
    logger.info("ğŸš€ Starting Grandby API Server...")
    logger.info(f"Environment: {settings.ENVIRONMENT}")
    logger.info(f"Debug Mode: {settings.DEBUG}")
    
    # DB ì—°ê²° í…ŒìŠ¤íŠ¸
    if test_db_connection():
        logger.info("âœ… Database connection successful")
    else:
        logger.error("âŒ Database connection failed")
    
    # Sentry ì´ˆê¸°í™” (í”„ë¡œë•ì…˜ í™˜ê²½)
    if settings.SENTRY_DSN and not is_development():
        import sentry_sdk
        sentry_sdk.init(
            dsn=settings.SENTRY_DSN,
            environment=settings.ENVIRONMENT,
            traces_sample_rate=0.1,
        )
        logger.info("âœ… Sentry initialized")
    
    yield
    
    # Shutdown
    logger.info("ğŸ‘‹ Shutting down Grandby API Server...")


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title=settings.APP_NAME,
    description="AI ê¸°ë°˜ ì–´ë¥´ì‹  ì¼€ì–´ í”Œë«í¼ Backend API",
    version=settings.APP_VERSION,
    docs_url="/docs" if is_development() else None,  # í”„ë¡œë•ì…˜ì—ì„œëŠ” Swagger ë¹„í™œì„±í™”
    redoc_url="/redoc" if is_development() else None,
    lifespan=lifespan,
)


# ==================== Middleware ====================

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins_list,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ìš”ì²­ ë¡œê¹… Middleware
@app.middleware("http")
async def log_requests(request: Request, call_next):
    """ëª¨ë“  HTTP ìš”ì²­ ë¡œê¹…"""
    logger.info(f"ğŸ“¥ {request.method} {request.url.path}")
    response = await call_next(request)
    logger.info(f"ğŸ“¤ {request.method} {request.url.path} - {response.status_code}")
    return response


# ==================== Exception Handlers ====================

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """422 Validation Error ìƒì„¸ ì •ë³´ ë¡œê¹…"""
    logger.error(f"âŒ 422 Validation Error:")
    logger.error(f"âŒ URL: {request.url}")
    logger.error(f"âŒ Method: {request.method}")
    logger.error(f"âŒ Body: {exc.body}")
    logger.error(f"âŒ Errors: {exc.errors()}")
    
    # ìƒì„¸ ì—ëŸ¬ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜
    return JSONResponse(
        status_code=422,
        content={
            "detail": "Validation Error",
            "errors": exc.errors(),
            "body": exc.body if isinstance(exc.body, dict) else (exc.body.decode() if exc.body else None)
        }
    )

@app.exception_handler(404)
async def not_found_handler(request: Request, exc):
    """404 ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
    return JSONResponse(
        status_code=404,
        content={
            "detail": "ìš”ì²­í•˜ì‹  ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "path": str(request.url.path)
        }
    )


@app.exception_handler(500)
async def internal_error_handler(request: Request, exc):
    """500 ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
    logger.error(f"Internal Server Error: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "detail": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "error": str(exc) if is_development() else "Internal Server Error"
        }
    )


# ==================== Root Endpoints ====================

@app.get("/", tags=["Root"])
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "ğŸ  Welcome to Grandby API",
        "version": settings.APP_VERSION,
        "docs": "/docs" if is_development() else "disabled",
    }


@app.get("/health", tags=["Health"])
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ (Docker, Kubernetesìš©)"""
    db_status = "healthy" if test_db_connection() else "unhealthy"
    
    return {
        "status": "healthy" if db_status == "healthy" else "degraded",
        "version": settings.APP_VERSION,
        "environment": settings.ENVIRONMENT,
        "database": db_status,
    }


# ==================== API Routers ====================
# ê° ë„ë©”ì¸ë³„ ë¼ìš°í„°ë¥¼ ì—¬ê¸°ì— ë“±ë¡

# ==================== AI ì±—ë´‡ ì„œë¹„ìŠ¤ ====================

# ì¸ì¦
app.include_router(
    auth.router,
    prefix="/api/auth",
    tags=["Authentication"]
)

# ì‚¬ìš©ì ê´€ë¦¬
app.include_router(
    users.router,
    prefix="/api/users",
    tags=["Users"]
)

# AI í†µí™”
app.include_router(
    calls.router,
    prefix="/api/calls",
    tags=["AI Calls"]
)

# ë‹¤ì´ì–´ë¦¬
app.include_router(
    diaries.router,
    prefix="/api/diaries",
    tags=["Diaries"]
)

# TODO ê´€ë¦¬
app.include_router(
    todos.router,
    prefix="/api/todos",
    tags=["TODOs"]
)

# ì•Œë¦¼
app.include_router(
    notifications.router,
    prefix="/api/notifications",
    tags=["Notifications"]
)

# ë³´í˜¸ì ëŒ€ì‹œë³´ë“œ
app.include_router(
    dashboard.router,
    prefix="/api/dashboard",
    tags=["Dashboard"]
)

# ==================== AI ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸ ====================

@app.post("/api/chatbot/text", tags=["AI Chatbot"])
async def chat_with_text(
    user_id: str = Form(..., description="ì‚¬ìš©ì ID"),
    message: str = Form(..., description="ì‚¬ìš©ì ë©”ì‹œì§€ (í…ìŠ¤íŠ¸)"),
    analyze_emotion: bool = Form(False, description="ê°ì • ë¶„ì„ ì—¬ë¶€")
):
    """
    í…ìŠ¤íŠ¸ ê¸°ë°˜ ì±—ë´‡ ëŒ€í™”
    
    ìŒì„± ì…ë ¥ì´ ì–´ë ¤ìš¸ ë•Œ í…ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆëŠ” ê°„í¸í•œ ì—”ë“œí¬ì¸íŠ¸
    
    Args:
        user_id: ì‚¬ìš©ì ê³ ìœ  ID (ì„¸ì…˜ ê´€ë¦¬ìš©)
        message: ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ ë©”ì‹œì§€
        analyze_emotion: ê°ì • ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€
    
    Returns:
        ëŒ€í™” ì‘ë‹µ ë° ì‹¤í–‰ ì‹œê°„ ì •ë³´
    """
    cycle_start_time = time.time()  # ì „ì²´ ì‚¬ì´í´ ì‹œì‘ ì‹œê°„
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸ’¬ í…ìŠ¤íŠ¸ ì±—ë´‡ ëŒ€í™” ì‹œì‘ (ì‚¬ìš©ì: {user_id})")
    logger.info(f"{'='*80}")
    
    try:
        # 1. ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
        if user_id not in conversation_sessions:
            conversation_sessions[user_id] = []
        
        conversation_history = conversation_sessions[user_id]
        
        # 2. ê°ì • ë¶„ì„ (ì˜µì…˜)
        emotion_result = None
        emotion_time = 0
        if analyze_emotion:
            emotion_result, emotion_time = llm_service.analyze_emotion(message)
        
        # 3. LLM ì‘ë‹µ ìƒì„±
        ai_response, llm_time = llm_service.generate_response(
            user_message=message,
            conversation_history=conversation_history
        )
        
        # 4. ëŒ€í™” ê¸°ë¡ ì €ì¥ (ìµœê·¼ 10ê°œê¹Œì§€ë§Œ ìœ ì§€)
        conversation_sessions[user_id].append({"role": "user", "content": message})
        conversation_sessions[user_id].append({"role": "assistant", "content": ai_response})
        if len(conversation_sessions[user_id]) > 10:
            conversation_sessions[user_id] = conversation_sessions[user_id][-10:]
        
        # ì „ì²´ ì‚¬ì´í´ ì™„ë£Œ ì‹œê°„
        total_time = time.time() - cycle_start_time
        
        logger.info(f"\n{'='*80}")
        logger.info(f"â±ï¸  ì „ì²´ ëŒ€í™” ì‚¬ì´í´ ì™„ë£Œ!")
        logger.info(f"  - ê°ì • ë¶„ì„: {emotion_time:.2f}ì´ˆ")
        logger.info(f"  - LLM ì‘ë‹µ ìƒì„±: {llm_time:.2f}ì´ˆ")
        logger.info(f"  â­ ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        logger.info(f"{'='*80}\n")
        
        return {
            "success": True,
            "user_message": message,
            "ai_response": ai_response,
            "emotion_analysis": emotion_result,
            "timing": {
                "emotion_analysis_time": emotion_time,
                "llm_time": llm_time,
                "total_time": total_time
            },
            "conversation_count": len(conversation_sessions[user_id]) // 2
        }
        
    except Exception as e:
        logger.error(f"âŒ ì±—ë´‡ ëŒ€í™” ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@app.post("/api/chatbot/voice", tags=["AI Chatbot"])
async def chat_with_voice(
    user_id: str = Form(..., description="ì‚¬ìš©ì ID"),
    audio_file: UploadFile = File(..., description="ìŒì„± íŒŒì¼ (mp3, wav, m4a ë“±)"),
    return_audio: bool = Form(True, description="ìŒì„± ì‘ë‹µ ìƒì„± ì—¬ë¶€")
):
    """
    ìŒì„± ê¸°ë°˜ ì±—ë´‡ ëŒ€í™” (ì „ì²´ íŒŒì´í”„ë¼ì¸)
    
    STT â†’ LLM â†’ TTS ì „ì²´ ê³¼ì •ì„ ìˆ˜í–‰í•˜ëŠ” ì™„ì „í•œ ìŒì„± ì±—ë´‡
    
    Args:
        user_id: ì‚¬ìš©ì ê³ ìœ  ID
        audio_file: ì‚¬ìš©ì ìŒì„± íŒŒì¼
        return_audio: Trueë©´ TTS ìŒì„± íŒŒì¼ ìƒì„±, Falseë©´ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
    
    Returns:
        ëŒ€í™” ì‘ë‹µ, ìŒì„± íŒŒì¼ ê²½ë¡œ, ì‹¤í–‰ ì‹œê°„ ì •ë³´
    """
    cycle_start_time = time.time()  # ì „ì²´ ì‚¬ì´í´ ì‹œì‘ ì‹œê°„
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸ™ï¸  ìŒì„± ì±—ë´‡ ëŒ€í™” ì‹œì‘ (ì‚¬ìš©ì: {user_id})")
    logger.info(f"{'='*80}")
    
    temp_audio_path = None
    tts_audio_path = None
    
    try:
        # 1. ì—…ë¡œë“œëœ ìŒì„± íŒŒì¼ ì„ì‹œ ì €ì¥
        temp_audio_path = f"/tmp/upload_{user_id}_{int(time.time())}.{audio_file.filename.split('.')[-1]}"
        with open(temp_audio_path, "wb") as f:
            content = await audio_file.read()
            f.write(content)
        logger.info(f"ğŸ“ ìŒì„± íŒŒì¼ ì €ì¥: {temp_audio_path}")
        
        # 2. STT: ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜
        user_message, stt_time = stt_service.transcribe_audio(temp_audio_path)
        
        # 3. ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
        if user_id not in conversation_sessions:
            conversation_sessions[user_id] = []
        conversation_history = conversation_sessions[user_id]
        
        # 4. LLM: ëŒ€í™” ì‘ë‹µ ìƒì„±
        ai_response, llm_time = llm_service.generate_response(
            user_message=user_message,
            conversation_history=conversation_history
        )
        
        # 5. TTS: í…ìŠ¤íŠ¸ â†’ ìŒì„± ë³€í™˜ (ì˜µì…˜)
        tts_time = 0
        if return_audio:
            tts_audio_path, tts_time = tts_service.text_to_speech(ai_response)
        
        # 6. ëŒ€í™” ê¸°ë¡ ì €ì¥
        conversation_sessions[user_id].append({"role": "user", "content": user_message})
        conversation_sessions[user_id].append({"role": "assistant", "content": ai_response})
        if len(conversation_sessions[user_id]) > 10:
            conversation_sessions[user_id] = conversation_sessions[user_id][-10:]
        
        # ì „ì²´ ì‚¬ì´í´ ì™„ë£Œ ì‹œê°„
        total_time = time.time() - cycle_start_time
        
        logger.info(f"\n{'='*80}")
        logger.info(f"â±ï¸  ì „ì²´ ìŒì„± ëŒ€í™” ì‚¬ì´í´ ì™„ë£Œ!")
        logger.info(f"  - STT (ìŒì„±â†’í…ìŠ¤íŠ¸): {stt_time:.2f}ì´ˆ")
        logger.info(f"  - LLM (ì‘ë‹µ ìƒì„±): {llm_time:.2f}ì´ˆ")
        logger.info(f"  - TTS (í…ìŠ¤íŠ¸â†’ìŒì„±): {tts_time:.2f}ì´ˆ")
        logger.info(f"  â­ ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        logger.info(f"{'='*80}\n")
        
        return {
            "success": True,
            "user_message": user_message,
            "ai_response": ai_response,
            "audio_file_path": tts_audio_path if return_audio else None,
            "timing": {
                "stt_time": stt_time,
                "llm_time": llm_time,
                "tts_time": tts_time,
                "total_time": total_time
            },
            "conversation_count": len(conversation_sessions[user_id]) // 2
        }
        
    except Exception as e:
        logger.error(f"âŒ ìŒì„± ì±—ë´‡ ëŒ€í™” ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "error": str(e)
        }
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if temp_audio_path and os.path.exists(temp_audio_path):
            os.remove(temp_audio_path)
            logger.info(f"ğŸ—‘ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_audio_path}")


@app.get("/api/chatbot/session/{user_id}", tags=["AI Chatbot"])
async def get_conversation_history(user_id: str):
    """
    ì‚¬ìš©ìì˜ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
    
    Args:
        user_id: ì‚¬ìš©ì ID
    
    Returns:
        ëŒ€í™” ê¸°ë¡ ëª©ë¡
    """
    if user_id not in conversation_sessions:
        return {
            "user_id": user_id,
            "conversation_count": 0,
            "messages": []
        }
    
    return {
        "user_id": user_id,
        "conversation_count": len(conversation_sessions[user_id]) // 2,
        "messages": conversation_sessions[user_id]
    }


@app.delete("/api/chatbot/session/{user_id}", tags=["AI Chatbot"])
async def clear_conversation_history(user_id: str):
    """
    ì‚¬ìš©ìì˜ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
    
    Args:
        user_id: ì‚¬ìš©ì ID
    
    Returns:
        ì´ˆê¸°í™” ê²°ê³¼
    """
    if user_id in conversation_sessions:
        del conversation_sessions[user_id]
        logger.info(f"ğŸ—‘ï¸  ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ì™„ë£Œ: {user_id}")
        return {
            "success": True,
            "message": f"ì‚¬ìš©ì {user_id}ì˜ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    else:
        return {
            "success": False,
            "message": f"ì‚¬ìš©ì {user_id}ì˜ ëŒ€í™” ê¸°ë¡ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        }

# ==================== Twilio WebSocket Endpoints ====================

class RealtimeCallRequest(BaseModel):
    """ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ìš”ì²­"""
    to_number: str  # ì „í™”ë²ˆí˜¸ (+821012345678 í˜•ì‹)
    user_id: str = "test-user"  # ì‚¬ìš©ì ID (ì„ íƒ)


class RealtimeCallResponse(BaseModel):
    """ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ì‘ë‹µ"""
    success: bool
    call_sid: str
    to_number: str
    status: str
    message: str
    voice_url: str
    timestamp: str


@app.post("/api/twilio/call", response_model=RealtimeCallResponse, tags=["Twilio"])
async def initiate_realtime_call(
    request: RealtimeCallRequest,
    db: Session = Depends(get_db)
):
    """
    ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ë°œì‹  (WebSocket ê¸°ë°˜)
    
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì „í™”ë²ˆí˜¸ë¡œ ì „í™”ë¥¼ ê±¸ê³ , WebSocketì„ í†µí•´ ì‹¤ì‹œê°„ AI ëŒ€í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    í”Œë¡œìš°:
    1. ì•±ì—ì„œ ì´ API í˜¸ì¶œ (ì „í™”ë²ˆí˜¸ ì „ë‹¬)
    2. Twilioê°€ ì‚¬ìš©ì ì „í™”ë²ˆí˜¸ë¡œ ì „í™” ë°œì‹ 
    3. ì‚¬ìš©ìê°€ ì „í™” ë°›ìŒ
    4. /api/twilio/voice ì—”ë“œí¬ì¸íŠ¸ì—ì„œ WebSocket ì—°ê²° ì‹œì‘
    5. ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™” (STT â†’ LLM â†’ TTS)
    """
    try:
        # API Base URL í™•ì¸
        if not settings.API_BASE_URL:
            raise HTTPException(
                status_code=400,
                detail="API_BASE_URLì´ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ngrok ë˜ëŠ” ë„ë©”ì¸ í•„ìš”)"
            )
        
        # Twilio ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        twilio_service = TwilioService()
        
        # Callback URL ì„¤ì • (WebSocket ì—°ê²°)
        api_base_url = settings.API_BASE_URL
        voice_url = f"https://{api_base_url}/api/twilio/voice"  # WebSocket ì‹œì‘ ì—”ë“œí¬ì¸íŠ¸
        status_callback_url = f"https://{api_base_url}/api/twilio/call-status"
        
        logger.info(f"ğŸ“ ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ë°œì‹  ì‹œì‘: {request.to_number}")
        logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ID: {request.user_id}")
        logger.info(f"ğŸ”— Voice URL (WebSocket ì‹œì‘): {voice_url}")
        
        # ì „í™” ê±¸ê¸°
        call_sid = twilio_service.make_call(
            to_number=request.to_number,  # ì‚¬ìš©ì ì…ë ¥ ì „í™”ë²ˆí˜¸
            voice_url=voice_url,
            status_callback_url=status_callback_url
        )
        
        # í†µí™” ê¸°ë¡ ì €ì¥ (ì„ íƒì‚¬í•­)
        try:
            from app.models.call import CallLog
            new_call = CallLog(
                call_id=call_sid,
                elderly_id=request.user_id,
                call_status="initiated",
                twilio_call_sid=call_sid,
                created_at=datetime.utcnow()
            )
            db.add(new_call)
            db.commit()
            logger.info(f"âœ… í†µí™” ê¸°ë¡ ì €ì¥: {call_sid}")
        except Exception as e:
            logger.warning(f"âš ï¸ í†µí™” ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {str(e)}")
            db.rollback()
        
        logger.info(f"âœ… ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ë°œì‹  ì„±ê³µ: {call_sid}")
        
        return RealtimeCallResponse(
            success=True,
            call_sid=call_sid,
            to_number=request.to_number,
            status="initiated",
            message=f"ì‹¤ì‹œê°„ AI ëŒ€í™” ì „í™”ê°€ {request.to_number}ë¡œ ë°œì‹ ë˜ì—ˆìŠµë‹ˆë‹¤. ì „í™”ë¥¼ ë°›ìœ¼ì‹œë©´ AIì™€ ëŒ€í™”í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            voice_url=voice_url,
            timestamp=datetime.utcnow().isoformat()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ë°œì‹  ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ë°œì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )


@app.post("/api/twilio/voice", response_class=PlainTextResponse, tags=["Twilio"])
async def voice_handler():
    """
    Twilio ì „í™” ì—°ê²° ì‹œ WebSocket ìŠ¤íŠ¸ë¦¼ ì‹œì‘
    """
    response = VoiceResponse()
    
    # í™˜ì˜ ë©”ì‹œì§€
    # response.say(
    #     "ì•ˆë…•í•˜ì„¸ìš”. AI ì–´ì‹œìŠ¤í„´íŠ¸ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.",
    #     language='ko-KR'
    # )
    
    # WebSocket ìŠ¤íŠ¸ë¦¼ ì—°ê²° ì„¤ì •
    if not settings.API_BASE_URL:
        logger.error("âš ï¸ API_BASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        api_base_url = "your-domain.com"  # fallback (ì‘ë™í•˜ì§€ ì•ŠìŒ)
    else:
        api_base_url = settings.API_BASE_URL
    
    websocket_url = f"wss://{api_base_url}/api/twilio/media-stream"
    
    connect = Connect()
    stream = Stream(url=websocket_url)
    connect.append(stream)
    response.append(connect)
    
    logger.info(f"ğŸ™ï¸ Twilio WebSocket ìŠ¤íŠ¸ë¦¼ ì‹œì‘: {websocket_url}")
    return str(response)


@app.websocket("/api/twilio/media-stream")
async def media_stream_handler(
    websocket: WebSocket,
    db: Session = Depends(get_db)
):
    """
    Twilio Media Streams WebSocket í•¸ë“¤ëŸ¬ (ì‹¤ì‹œê°„ STT ì ìš©)
    
    ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë°ì´í„° ì–‘ë°©í–¥ ì²˜ë¦¬:
    1. ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  ë° ë²„í¼ë§
    2. ì¹¨ë¬µ ê°ì§€ ì‹œ ì‹¤ì‹œê°„ STT ë³€í™˜
    3. ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëˆ„ì 
    4. ê° ë°œí™”ë§ˆë‹¤ ì¦‰ì‹œ AI ì‘ë‹µ ìƒì„± ë° TTS ì¬ìƒ
    5. í†µí™” ì¢…ë£Œ ì‹œ ì „ì²´ ëŒ€í™” ë‚´ìš© ì €ì¥
    
    ì‹¤ì‹œê°„ STT â†’ LLM â†’ TTS íŒŒì´í”„ë¼ì¸
    """
    await websocket.accept()
    logger.info("ğŸ“ Twilio WebSocket ì—°ê²°ë¨")
    
    call_sid = None
    stream_sid = None
    audio_processor = None
    call_log = None  # DBì— ì €ì¥í•  CallLog ê°ì²´
    elderly_id = None  # í†µí™” ëŒ€ìƒ ì–´ë¥´ì‹  ID
    
    try:
        async for message in websocket.iter_text():
            data = json.loads(message)
            event_type = data.get('event')
            
            # ========== 1. ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ==========
            if event_type == 'start':
                call_sid = data['start']['callSid']
                stream_sid = data['start']['streamSid']
                
                # customParametersì—ì„œ elderly_id ì¶”ì¶œ (Twilio í†µí™” ì‹œì‘ ì‹œ ì „ë‹¬)
                custom_params = data['start'].get('customParameters', {})
                elderly_id = custom_params.get('elderly_id', 'unknown')
                
                audio_processor = AudioProcessor(call_sid)
                active_connections[call_sid] = websocket
                
                # ëŒ€í™” ì„¸ì…˜ ì´ˆê¸°í™” (LLM ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬)
                if call_sid not in conversation_sessions:
                    conversation_sessions[call_sid] = []
                
                # DBì— í†µí™” ì‹œì‘ ê¸°ë¡ ì €ì¥
                try:
                    from app.models.call import CallLog, CallStatus
                    db = next(get_db())
                    
                    call_log = CallLog(
                        call_id=call_sid,
                        elderly_id=elderly_id,
                        call_status=CallStatus.ANSWERED,
                        call_start_time=datetime.utcnow(),
                        twilio_call_sid=call_sid
                    )
                    db.add(call_log)
                    db.commit()
                    db.refresh(call_log)
                    db.close()
                    logger.info(f"âœ… DBì— í†µí™” ì‹œì‘ ê¸°ë¡ ì €ì¥: {call_sid}")
                except Exception as e:
                    logger.error(f"âŒ í†µí™” ì‹œì‘ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
                
                logger.info(f"â”Œ{'â”€'*58}â”")
                logger.info(f"â”‚ ğŸ™ï¸  Twilio í†µí™” ì‹œì‘                                   â”‚")
                logger.info(f"â”‚ Call SID: {call_sid:43} â”‚")
                logger.info(f"â”‚ Stream SID: {stream_sid:41} â”‚")
                logger.info(f"â”‚ Elderly ID: {elderly_id:41} â”‚")
                logger.info(f"â””{'â”€'*58}â”˜")
                
                # ì‹œì‘ ì•ˆë‚´ ë©”ì‹œì§€ (TTS ì„œë¹„ìŠ¤ ì‚¬ìš©)
                welcome_text = "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
                await send_audio_to_twilio_with_tts(websocket, stream_sid, welcome_text, audio_processor)
                
            # ========== 2. ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  ë° ì‹¤ì‹œê°„ STT ì²˜ë¦¬ ==========
            elif event_type == 'media':
                if audio_processor:
                    # Base64 ë””ì½”ë”© (TwilioëŠ” mulaw 8kHzë¡œ ì „ì†¡)
                    audio_payload = base64.b64decode(data['media']['payload'])
                    audio_processor.add_audio_chunk(audio_payload)
                    
                    # ì‚¬ìš©ìê°€ ë§ì„ ë©ˆì·„ëŠ”ì§€ í™•ì¸ (ì¹¨ë¬µ ê°ì§€ - 1ì´ˆë¡œ ë‹¨ì¶•!)
                    if audio_processor.should_process():
                        cycle_start = time.time()
                        logger.info(f"{'='*60}")
                        logger.info(f"ğŸ¯ ë°œí™” ì¢…ë£Œ ê°ì§€ â†’ ì¦‰ì‹œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ")
                        logger.info(f"{'='*60}")
                        
                        # 1ï¸âƒ£ STT: ì˜¤ë””ì˜¤ â†’ í…ìŠ¤íŠ¸ ë³€í™˜ (ì‹¤ì‹œê°„ ì²­í¬ ê¸°ë°˜)
                        audio_data = audio_processor.get_audio()
                        user_text, stt_time = await transcribe_audio_realtime(audio_data)
                        
                        if user_text and user_text.strip():
                            logger.info(f"âœ… STT ì™„ë£Œ ({stt_time:.2f}ì´ˆ)")
                            logger.info(f"ğŸ‘¤ [ì‚¬ìš©ì ë°œí™”] {user_text}")
                            
                            # ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ ë²„í¼ì— ì €ì¥ (ì „ì²´ ëŒ€í™” ì¶”ì ìš©)
                            audio_processor.add_transcript(user_text)
                            
                            # ì¢…ë£Œ í‚¤ì›Œë“œ í™•ì¸
                            if any(keyword in user_text.lower() 
                                   for keyword in ['ì¢…ë£Œ', 'ë', 'ê·¸ë§Œ', 'goodbye', 'ëŠì–´', 'ì•ˆë…•']):
                                logger.info(f"ğŸ›‘ ì¢…ë£Œ í‚¤ì›Œë“œ ê°ì§€: '{user_text}'")
                                goodbye_text = "ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”!"
                                await send_audio_to_twilio_with_tts(websocket, stream_sid, goodbye_text, audio_processor)
                                await asyncio.sleep(2)  # ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¬ìƒ ëŒ€ê¸°
                                await websocket.close()
                                break
                            
                            # 2ï¸âƒ£+3ï¸âƒ£ LLM ìŠ¤íŠ¸ë¦¬ë° + TTS ë³‘ë ¬ ì²˜ë¦¬
                            # ì´ê²ƒì´ í•µì‹¬ ìµœì í™”!
                            # LLMì´ ë¬¸ì¥ì„ ìƒì„±í•˜ë©´ ì¦‰ì‹œ TTS ë³€í™˜í•˜ì—¬ ì „ì†¡
                            conversation_history = conversation_sessions.get(call_sid, [])
                            
                            ai_response = await process_streaming_response(
                                websocket,
                                stream_sid,
                                user_text,
                                conversation_history,
                                audio_processor
                            )
                            
                            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ (ìµœê·¼ 10ê°œë§Œ ìœ ì§€)
                            conversation_sessions[call_sid].append({"role": "user", "content": user_text})
                            conversation_sessions[call_sid].append({"role": "assistant", "content": ai_response})
                            if len(conversation_sessions[call_sid]) > 10:
                                conversation_sessions[call_sid] = conversation_sessions[call_sid][-10:]
                            
                            total_cycle_time = time.time() - cycle_start
                            logger.info(f"â±ï¸  ì „ì²´ ì‘ë‹µ ì‚¬ì´í´: {total_cycle_time:.2f}ì´ˆ")
                            logger.info(f"{'='*60}\n\n")
                        else:
                            logger.debug("â­ï¸  STT ê²°ê³¼ ì—†ìŒ (ì¹¨ë¬µ ë˜ëŠ” ì¡ìŒ)")
                        
            # ========== 3. ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ==========
            elif event_type == 'stop':
                logger.info(f"\n{'='*60}")
                logger.info(f"ğŸ“ Twilio í†µí™” ì¢…ë£Œ - Call: {call_sid}")
                logger.info(f"{'='*60}")
                
                # ì „ì²´ ëŒ€í™” ë‚´ìš© í™•ì¸
                if audio_processor:
                    full_transcript = audio_processor.get_full_transcript()
                    if full_transcript:
                        logger.info(f"\nğŸ“‹ ì „ì²´ ëŒ€í™” ë‚´ìš©:")
                        logger.info(f"â”€" * 60)
                        logger.info(f"{full_transcript}")
                        logger.info(f"â”€" * 60)
                
                # ëŒ€í™” ì„¸ì…˜ì„ DBì— ì €ì¥
                if call_sid in conversation_sessions:
                    conversation = conversation_sessions[call_sid]
                    logger.info(f"ğŸ’¾ ëŒ€í™” ê¸°ë¡: {len(conversation)}ê°œ ë©”ì‹œì§€")
                    
                    # DBì— ëŒ€í™” ë‚´ìš© ë° ìš”ì•½ ì €ì¥
                    try:
                        from app.models.call import CallLog, CallTranscript, CallStatus
                        db = next(get_db())
                        
                        # 1. CallLog ì—…ë°ì´íŠ¸ (í†µí™” ì¢…ë£Œ ì‹œê°„, ìš”ì•½)
                        call_log_db = db.query(CallLog).filter(CallLog.call_id == call_sid).first()
                        
                        if call_log_db:
                            call_log_db.call_end_time = datetime.utcnow()
                            call_log_db.call_status = CallStatus.COMPLETED
                            
                            # í†µí™” ì‹œê°„ ê³„ì‚° (ì´ˆ)
                            if call_log_db.call_start_time:
                                duration = (call_log_db.call_end_time - call_log_db.call_start_time).total_seconds()
                                call_log_db.call_duration = int(duration)
                            
                            # LLM ìš”ì•½ ìƒì„± (ëŒ€í™”ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
                            if len(conversation) > 0:
                                logger.info("ğŸ¤– LLMìœ¼ë¡œ í†µí™” ìš”ì•½ ìƒì„± ì¤‘...")
                                summary = llm_service.summarize_call_conversation(conversation)
                                call_log_db.conversation_summary = summary
                                logger.info(f"âœ… ìš”ì•½ ìƒì„± ì™„ë£Œ: {summary[:100]}...")
                            
                            db.commit()
                            logger.info(f"âœ… CallLog ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                        
                        # 2. CallTranscript ì €ì¥ (í™”ìë³„ ëŒ€í™” ë‚´ìš©)
                        for idx, message in enumerate(conversation):
                            speaker = "ELDERLY" if message["role"] == "user" else "AI"
                            
                            transcript = CallTranscript(
                                call_id=call_sid,
                                speaker=speaker,
                                text=message["content"],
                                timestamp=idx * 10.0,  # ëŒ€ëµì ì¸ íƒ€ì„ìŠ¤íƒ¬í”„ (10ì´ˆ ê°„ê²©)
                                created_at=datetime.utcnow()
                            )
                            db.add(transcript)
                        
                        db.commit()
                        logger.info(f"âœ… ëŒ€í™” ë‚´ìš© {len(conversation)}ê°œ ì €ì¥ ì™„ë£Œ")
                        
                        db.close()
                        
                    except Exception as e:
                        logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
                        import traceback
                        logger.error(traceback.format_exc())
                        if 'db' in locals():
                            db.rollback()
                            db.close()
                    
                    # ë©”ëª¨ë¦¬ì—ì„œ ì œê±°
                    del conversation_sessions[call_sid]
                
                if call_sid in active_connections:
                    del active_connections[call_sid]
                
                logger.info(f"â”Œ{'â”€'*58}â”")
                logger.info(f"â”‚ âœ… Twilio í†µí™” ì •ë¦¬ ì™„ë£Œ                               â”‚")
                logger.info(f"â””{'â”€'*58}â”˜\n")
                break
                
    except WebSocketDisconnect:
        logger.info(f"ğŸ“ Twilio WebSocket ì—°ê²° í•´ì œ (Call: {call_sid})")
    except Exception as e:
        logger.error(f"âŒ Twilio WebSocket ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        # ì •ë¦¬ ì‘ì—…
        if call_sid and call_sid in active_connections:
            del active_connections[call_sid]
        if call_sid and call_sid in conversation_sessions:
            del conversation_sessions[call_sid]


@app.post("/api/twilio/call-status", tags=["Twilio"])
async def call_status_handler(
    CallSid: str = Form(None),
    CallStatus: str = Form(None)
):
    """
    Twilio í†µí™” ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°±
    í†µí™” ìƒíƒœ: initiated, ringing, answered, completed
    """
    logger.info(f"ğŸ“ í†µí™” ìƒíƒœ ì—…ë°ì´íŠ¸: {CallSid} - {CallStatus}")
    
    if CallStatus == 'completed':
        # í†µí™” ì¢…ë£Œ ì‹œ ì •ë¦¬
        if CallSid in conversation_sessions:
            del conversation_sessions[CallSid]
        if CallSid in active_connections:
            del active_connections[CallSid]
    
    return {"status": "ok", "call_sid": CallSid, "call_status": CallStatus}


# ==================== Startup Message ====================
if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=is_development(),
        log_level=settings.LOG_LEVEL.lower(),
    )
