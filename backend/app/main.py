"""
Grandby FastAPI Application
ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
"""

from fastapi import FastAPI, Request, WebSocket, WebSocketDisconnect, Form, HTTPException, Depends, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, PlainTextResponse
from fastapi.exceptions import RequestValidationError
from pydantic import ValidationError
from pydantic import BaseModel
from contextlib import asynccontextmanager
import logging
import json
import base64
import asyncio
import os
import tempfile
from typing import Dict, Optional
import audioop
from datetime import datetime
from sqlalchemy.orm import Session
import time

from twilio.twiml.voice_response import VoiceResponse, Connect, Stream

from app.routers import auth, users, calls, diaries, todos, notifications, dashboard
from app.config import settings, is_development
from app.database import test_db_connection, get_db
from app.services.ai_call.stt_service import STTService
from app.services.ai_call.tts_service import TTSService
from app.services.ai_call.cartesia_tts_service import cartesia_tts_service
from app.services.ai_call.llm_service import LLMService
from app.services.ai_call.twilio_service import TwilioService
from app.services.ai_call.rtzr_stt_realtime import RTZRRealtimeSTT, LLMPartialCollector

# ë¡œê±° ì„¤ì • (ì‹œê°„ í¬í•¨)
logging.basicConfig(
    level=settings.LOG_LEVEL,
    format='%(asctime)s.%(msecs)03d - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ë° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
stt_service = STTService()
tts_service = TTSService()
llm_service = LLMService()

# WebSocket ì—°ê²° ë° ëŒ€í™” ì„¸ì…˜ ê´€ë¦¬
active_connections: Dict[str, WebSocket] = {}
conversation_sessions: Dict[str, list] = {}
saved_calls: set = set()  # ì¤‘ë³µ ì €ì¥ ë°©ì§€ìš© í”Œë˜ê·¸


# ==================== í†µí™” ì„¸ì…˜ ê´€ë¦¬ í´ë˜ìŠ¤ ====================

class CallSession:
    """í†µí™” ì„¸ì…˜ ê´€ë¦¬ í´ë˜ìŠ¤ - Cartesia WebSocket ì—°ê²° ì¬ì‚¬ìš©"""
    
    def __init__(self, call_sid: str, stream_sid: str):
        self.call_sid = call_sid
        self.stream_sid = stream_sid
        self.cartesia_ws = None
        self.context_id = None
        self.is_connected = False
        self.connection_task = None
        
    async def initialize_cartesia_connection(self):
        """í†µí™” ì‹œì‘ ì‹œ Cartesia WebSocket ì—°ê²° ìƒì„±"""
        try:
            access_token = await cartesia_tts_service._get_access_token()
            ws_url = f"wss://api.cartesia.ai/tts/websocket?api_key={access_token}&cartesia_version=2025-04-16"
            
            import websockets
            self.cartesia_ws = await websockets.connect(
                ws_url,
                ping_interval=20,
                ping_timeout=10
            )
            self.context_id = f"ctx_{self.stream_sid}_{int(time.time() * 1000)}"
            self.is_connected = True
            
            # ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œì‘
            self.connection_task = asyncio.create_task(self._monitor_connection())
            
            logger.info(f"âœ… Cartesia WebSocket ì—°ê²° ìƒì„± ì™„ë£Œ: {self.call_sid}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Cartesia WebSocket ì—°ê²° ì‹¤íŒ¨: {e}")
            self.is_connected = False
            return False
    
    async def _monitor_connection(self):
        """WebSocket ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§"""
        try:
            while self.is_connected:
                await asyncio.sleep(30)  # 30ì´ˆë§ˆë‹¤ í™•ì¸
                if self.cartesia_ws:
                    await self.cartesia_ws.ping()
        except Exception as e:
            logger.warning(f"âš ï¸ WebSocket ì—°ê²° ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")
            self.is_connected = False
    
    async def close(self):
        """í†µí™” ì¢…ë£Œ ì‹œ ì—°ê²° ì •ë¦¬"""
        self.is_connected = False
        if self.connection_task:
            self.connection_task.cancel()
        if self.cartesia_ws:
            await self.cartesia_ws.close()
        logger.info(f"ğŸ”„ Cartesia WebSocket ì—°ê²° ì¢…ë£Œ: {self.call_sid}")

# ì „ì—­ ì„¸ì…˜ ê´€ë¦¬
call_sessions: Dict[str, CallSession] = {}


# ==================== ëŒ€í™” ë‚´ìš© DB ì €ì¥ í•¨ìˆ˜ ====================

async def save_conversation_to_db(call_sid: str, conversation: list):
    """
    ëŒ€í™” ë‚´ìš©ì„ DBì— ì €ì¥í•˜ëŠ” ê³µí†µ í•¨ìˆ˜
    
    Args:
        call_sid: Twilio Call SID
        conversation: ëŒ€í™” ë‚´ìš© ë¦¬ìŠ¤íŠ¸ [{"role": "user", "content": "..."}, ...]
    """
    # ì´ë¯¸ ì €ì¥ë˜ì—ˆìœ¼ë©´ ìŠ¤í‚µ (ì¤‘ë³µ ë°©ì§€)
    if call_sid in saved_calls:
        logger.info(f"â­ï¸  ì´ë¯¸ ì €ì¥ëœ í†µí™”: {call_sid}")
        return
    
    # ì €ì¥í•  ë‚´ìš©ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
    if not conversation or len(conversation) == 0:
        logger.warning(f"âš ï¸  ì €ì¥í•  ëŒ€í™” ë‚´ìš©ì´ ì—†ìŒ: {call_sid}")
        return
    
    logger.info(f"ğŸ’¾ ëŒ€í™” ê¸°ë¡ ì €ì¥ ì‹œì‘: {len(conversation)}ê°œ ë©”ì‹œì§€")
    
    try:
        from app.models.call import CallLog, CallTranscript, CallStatus
        db = next(get_db())
        
        # 1. CallLog ì—…ë°ì´íŠ¸ (ëŒ€í™” ìš”ì•½)
        call_log_db = db.query(CallLog).filter(CallLog.call_id == call_sid).first()
        
        if call_log_db:
            # LLM ìš”ì•½ ìƒì„± (ëŒ€í™”ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
            if len(conversation) > 0:
                logger.info("ğŸ¤– LLMìœ¼ë¡œ í†µí™” ìš”ì•½ ìƒì„± ì¤‘...")
                summary = llm_service.summarize_call_conversation(conversation)
                call_log_db.conversation_summary = summary
                logger.info(f"âœ… ìš”ì•½ ìƒì„± ì™„ë£Œ: {summary[:100]}...")
            
            db.commit()
            logger.info(f"âœ… CallLog ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        else:
            logger.warning(f"âš ï¸  CallLogë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {call_sid}")
        
        # 2. CallTranscript ì €ì¥ (í™”ìë³„ ëŒ€í™” ë‚´ìš©)
        for idx, message in enumerate(conversation):
            speaker = "ELDERLY" if message["role"] == "user" else "AI"
            
            transcript = CallTranscript(
                call_id=call_sid,
                speaker=speaker,
                text=message["content"],
                timestamp=idx * 10.0,  # ëŒ€ëµì ì¸ íƒ€ì„ìŠ¤íƒ¬í”„ (10ì´ˆ ê°„ê²©)
                created_at=datetime.utcnow()
            )
            db.add(transcript)
        
        db.commit()
        logger.info(f"âœ… ëŒ€í™” ë‚´ìš© {len(conversation)}ê°œ ì €ì¥ ì™„ë£Œ")
        
        # ì €ì¥ ì„±ê³µ í”Œë˜ê·¸ ì„¤ì •
        saved_calls.add(call_sid)
        
        # # âœ… ì¼ê¸° ìë™ ìƒì„± íŠ¸ë¦¬ê±°
        # try:
        #     from app.tasks.diary_generator import generate_diary_from_call
        #     generate_diary_from_call.delay(call_sid)
        #     logger.info(f"ğŸ“ ì¼ê¸° ìë™ ìƒì„± ì‘ì—… ì˜ˆì•½: {call_sid}")
        # except Exception as e:
        #     logger.error(f"âŒ ì¼ê¸° ìƒì„± ì‘ì—… ì˜ˆì•½ ì‹¤íŒ¨: {e}")
        
        db.close()
        
    except Exception as e:
        logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        if 'db' in locals():
            db.rollback()
            db.close()


# ==================== AudioProcessor ====================

class AudioProcessor:
    """
    ì˜¤ë””ì˜¤ ì²˜ë¦¬ í´ë˜ìŠ¤ - ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë²„í¼ë§ ë° ì¹¨ë¬µ ê°ì§€ (ë™ì  ì„ê³„ê°’)
    
    Twilioì—ì„œ ìˆ˜ì‹ í•œ mulaw ì˜¤ë””ì˜¤ë¥¼ ë²„í¼ë§í•˜ê³ ,
    ì¹¨ë¬µì„ ê°ì§€í•˜ì—¬ STT ì²˜ë¦¬ ì‹œì ì„ ê²°ì •í•©ë‹ˆë‹¤.
    
    ë°°ê²½ ì†ŒìŒ ë ˆë²¨ì„ ìë™ìœ¼ë¡œ ì¸¡ì •í•˜ì—¬ ì„ê³„ê°’ì„ ë™ì ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, call_sid: str):
        self.call_sid = call_sid
        self.audio_buffer = []  # ì˜¤ë””ì˜¤ ì²­í¬ ë²„í¼ (ì´ì œ PCM ë°ì´í„° ì €ì¥)
        self.transcript_buffer = []  # ì‹¤ì‹œê°„ STT ê²°ê³¼ ë²„í¼
        self.is_speaking = False  # ì‚¬ìš©ìê°€ ë§í•˜ê³  ìˆëŠ”ì§€ ì—¬ë¶€
        
        # ========== PCM ê¸°ë°˜ ë™ì  ì„ê³„ê°’ ì„¤ì • ==========
        # PCM RMS ê°’ì€ Î¼-lawë³´ë‹¤ í›¨ì”¬ í¼ (16-bit vs 8-bit)
        self.base_silence_threshold = 1000  # ê¸°ë³¸ ì„ê³„ê°’ (PCM 16-bit ê¸°ì¤€)
        self.silence_threshold = 1000  # í˜„ì¬ ì„ê³„ê°’ (ë™ì ìœ¼ë¡œ ë³€ê²½ë¨)
        
        # ë°°ê²½ ì†ŒìŒ ì¸¡ì •
        self.noise_samples = []  # ë°°ê²½ ì†ŒìŒ RMS ìƒ˜í”Œ
        self.noise_calibration_chunks = 50  # ì²˜ìŒ 1ì´ˆ(50*20ms) ë™ì•ˆ ë°°ê²½ ì†ŒìŒ ì¸¡ì •
        self.is_calibrated = False  # ë³´ì • ì™„ë£Œ ì—¬ë¶€
        self.background_noise_level = 0  # ì¸¡ì •ëœ ë°°ê²½ ì†ŒìŒ ë ˆë²¨
        
        # ì ì‘í˜• ì¡°ì • ì„¤ì • (PCM ê°’ì— ë§ê²Œ ì¡°ì •)
        self.noise_margin = 200  # ë°°ê²½ ì†ŒìŒ + ë§ˆì§„ = ì„ê³„ê°’ (PCM ê¸°ì¤€)
        self.min_threshold = 500  # ìµœì†Œ ì„ê³„ê°’ (PCM ê¸°ì¤€)
        self.max_threshold = 5000  # ìµœëŒ€ ì„ê³„ê°’ (PCM ê¸°ì¤€)
        # ======================================
        
        self.silence_duration = 0  # í˜„ì¬ ì¹¨ë¬µ ì§€ì† ì‹œê°„
        self.max_silence = 0.5  # â­ 1.5ì´ˆ ì¹¨ë¬µ í›„ STT ì²˜ë¦¬ (ì¶©ë¶„í•œ ë°œí™” ìˆ˜ì§‘)

        # ì´ˆê¸° ë…¸ì´ì¦ˆ í•„í„°ë§
        self.warmup_chunks = 0  # ë°›ì€ ì²­í¬ ìˆ˜
        self.warmup_threshold = 25  # ì²˜ìŒ 0.5ì´ˆ ë¬´ì‹œ
        
        # ì—°ì† ìŒì„± ê°ì§€
        self.voice_chunks = 0  # ì—°ì† ìŒì„± ê°ì§€ ì¹´ìš´í„°
        self.voice_threshold = 3  # ìµœì†Œ 3ë²ˆ ì—°ì† ê°ì§€
        
        # TTS ì¬ìƒ ìƒíƒœ (ì—ì½” ë°©ì§€)
        self.is_bot_speaking = False
        self.bot_silence_delay = 0
        
        # í†µê³„ ì •ë³´ (ë””ë²„ê¹…ìš©)
        self.rms_history = []  # ìµœê·¼ RMS ê¸°ë¡
        self.max_rms_history = 100  # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
    
    def _calibrate_noise_level(self, rms: float):
        """
        ë°°ê²½ ì†ŒìŒ ë ˆë²¨ ìë™ ë³´ì • (PCM ê¸°ì¤€)
        
        í†µí™” ì‹œì‘ í›„ ì²˜ìŒ 1ì´ˆ ë™ì•ˆ ìˆ˜ì‹ í•œ RMS ê°’ë“¤ì˜ í‰ê· ì„ 
        ë°°ê²½ ì†ŒìŒ ë ˆë²¨ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
        
        Args:
            rms: í˜„ì¬ ì²­í¬ì˜ RMS ê°’ (PCM 16-bit)
        """
        if not self.is_calibrated:
            # ë¹„ì •ìƒì ìœ¼ë¡œ í° ê°’ì€ ì œì™¸ (ì—°ê²°ìŒ ë“±) - PCM ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
            if rms < 10000:  # PCM 16-bit ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
                self.noise_samples.append(rms)
            
            # ì¶©ë¶„í•œ ìƒ˜í”Œì´ ëª¨ì´ë©´ í‰ê·  ê³„ì‚°
            if len(self.noise_samples) >= self.noise_calibration_chunks:
                self.background_noise_level = sum(self.noise_samples) / len(self.noise_samples)
                
                # ë™ì  ì„ê³„ê°’ ì„¤ì •: ë°°ê²½ ì†ŒìŒ + ë§ˆì§„
                calculated_threshold = self.background_noise_level + self.noise_margin
                
                # ìµœì†Œ/ìµœëŒ€ ë²”ìœ„ ë‚´ë¡œ ì œí•œ
                self.silence_threshold = max(
                    self.min_threshold,
                    min(self.max_threshold, calculated_threshold)
                )
                
                self.is_calibrated = True
                
                logger.info(f"ğŸšï¸  [ë°°ê²½ ì†ŒìŒ ë³´ì • ì™„ë£Œ]")
                logger.info(f"   ğŸ“Š ë°°ê²½ ì†ŒìŒ ë ˆë²¨: {self.background_noise_level:.1f}")
                logger.info(f"   ğŸ¯ ì¡°ì •ëœ ì„ê³„ê°’: {self.silence_threshold:.1f} (ê¸°ë³¸: {self.base_silence_threshold})")
                logger.info(f"   ğŸ“ˆ ìƒ˜í”Œ ìˆ˜: {len(self.noise_samples)}ê°œ")
    
    def _update_threshold_adaptive(self, rms: float):
        """
        ì‹¤ì‹œê°„ ì ì‘í˜• ì„ê³„ê°’ ì¡°ì • (PCM ê¸°ì¤€)
        
        ëŒ€í™” ì¤‘ì—ë„ RMS í†µê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ê³„ê°’ì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.
        ë°°ê²½ ì†ŒìŒì´ ë³€í™”í•˜ëŠ” í™˜ê²½(ì˜ˆ: ì´ë™ ì¤‘ í†µí™”)ì— ìœ ìš©í•©ë‹ˆë‹¤.
        
        Args:
            rms: í˜„ì¬ ì²­í¬ì˜ RMS ê°’ (PCM 16-bit)
        """
        # RMS ê¸°ë¡ ì €ì¥
        self.rms_history.append(rms)
        if len(self.rms_history) > self.max_rms_history:
            self.rms_history.pop(0)
        
        # 100ê°œ ìƒ˜í”Œë§ˆë‹¤ ì¬ì¡°ì • (ì•½ 2ì´ˆë§ˆë‹¤)
        if len(self.rms_history) >= self.max_rms_history and len(self.rms_history) % 50 == 0:
            # í•˜ìœ„ 30% ê°’ë“¤ì˜ í‰ê·  (ë°°ê²½ ì†ŒìŒìœ¼ë¡œ ì¶”ì •)
            sorted_rms = sorted(self.rms_history)
            lower_30_percent = sorted_rms[:30]
            estimated_noise = sum(lower_30_percent) / len(lower_30_percent)
            
            # ì„ê³„ê°’ ì¬ì¡°ì • (ì„œì„œíˆ ì ì‘)
            new_threshold = estimated_noise + self.noise_margin
            new_threshold = max(self.min_threshold, min(self.max_threshold, new_threshold))
            
            # í° ë³€í™”ê°€ ìˆì„ ë•Œë§Œ ì—…ë°ì´íŠ¸ (Â±500 ì´ìƒ) - PCM ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
            if abs(new_threshold - self.silence_threshold) > 500:
                old_threshold = self.silence_threshold
                self.silence_threshold = new_threshold
                logger.info(f"ğŸ”„ ì„ê³„ê°’ ì ì‘: {old_threshold:.1f} â†’ {new_threshold:.1f} (ì¶”ì • ì†ŒìŒ: {estimated_noise:.1f})")
    
    def get_calibration_status(self) -> dict:
        """
        ë³´ì • ìƒíƒœ ì •ë³´ ë°˜í™˜ (ë””ë²„ê¹…/ëª¨ë‹ˆí„°ë§ìš©)
        
        Returns:
            dict: ë³´ì • ê´€ë ¨ í†µê³„ ì •ë³´
        """
        return {
            "is_calibrated": self.is_calibrated,
            "background_noise_level": round(self.background_noise_level, 2),
            "current_threshold": round(self.silence_threshold, 2),
            "base_threshold": self.base_silence_threshold,
            "samples_collected": len(self.noise_samples),
            "rms_history_size": len(self.rms_history)
        }

    def add_audio_chunk(self, audio_data: bytes):
        """ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€ ë° ìŒì„± í™œë™ ê°ì§€ (PCM ê¸°ë°˜ ë™ì  ì„ê³„ê°’ ì ìš©)"""
        # Î¼-law â†’ PCM ë³€í™˜ (ì‹¤ì‹œê°„)
        try:
            pcm_data = audioop.ulaw2lin(audio_data, 2)  # 16-bit PCMìœ¼ë¡œ ë³€í™˜
            self.audio_buffer.append(pcm_data)
        except Exception as e:
            logger.error(f"âŒ Î¼-law â†’ PCM ë³€í™˜ ì‹¤íŒ¨: {e}")
            return
        
        # ì›Œë°ì—…: ì´ˆê¸° ì²­í¬ ë¬´ì‹œ (ì—°ê²° ë…¸ì´ì¦ˆ ë°©ì§€)
        self.warmup_chunks += 1
        if self.warmup_chunks <= self.warmup_threshold:
            if self.warmup_chunks == 1:
                logger.info("â³ ì˜¤ë””ì˜¤ ì´ˆê¸°í™” ë° ë°°ê²½ ì†ŒìŒ ì¸¡ì • ì¤‘...")
            return
        
        # AIê°€ ë§í•˜ëŠ” ë™ì•ˆ + ì¢…ë£Œ í›„ 1ì´ˆê°„ ì‚¬ìš©ì ì…ë ¥ ë¬´ì‹œ (ì—ì½” ë°©ì§€)
        if self.is_bot_speaking or self.bot_silence_delay > 0:
            if self.bot_silence_delay > 0:
                self.bot_silence_delay -= 1
                if self.bot_silence_delay == 0:
                    logger.info("âœ… AI ì‘ë‹µ ì¢…ë£Œ í›„ ëŒ€ê¸° ì™„ë£Œ, ì‚¬ìš©ì ì…ë ¥ ì¬ê°œ")
            return
        
        # RMS ê³„ì‚° (PCM 16-bit ê¸°ì¤€)
        rms = audioop.rms(pcm_data, 2)  # 2ë°”ì´íŠ¸ ìƒ˜í”Œ í­
        
        # ========== ë™ì  ì„ê³„ê°’ ê¸°ëŠ¥ ==========
        # 1. ë°°ê²½ ì†ŒìŒ ë³´ì • (ì²˜ìŒ 1ì´ˆ)
        if not self.is_calibrated:
            self._calibrate_noise_level(rms)
            return  # ë³´ì • ì™„ë£Œ ì „ê¹Œì§€ëŠ” ìŒì„± ê°ì§€ ì•ˆí•¨
        
        # 2. ì‹¤ì‹œê°„ ì ì‘í˜• ì¡°ì • (ì„ íƒì , ì£¼ì„ í•´ì œí•˜ì—¬ í™œì„±í™”)
        # self._update_threshold_adaptive(rms)
        # ======================================
        
        # ë¹„ì •ìƒì ìœ¼ë¡œ í° RMS ê°’ í•„í„°ë§ (PCM ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •)
        if rms > 20000:  # PCM 16-bit ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
            logger.warning(f"âš ï¸  ë¹„ì •ìƒì ì¸ RMS ë¬´ì‹œ: {rms}")
            self.voice_chunks = 0
            return
        
        # ìŒì„± í™œë™ ê°ì§€ (ë™ì  ì„ê³„ê°’ ì‚¬ìš©)
        if rms > self.silence_threshold:
            self.voice_chunks += 1
            
            # ì—°ì†ìœ¼ë¡œ ì—¬ëŸ¬ ë²ˆ ê°ì§€ë˜ì–´ì•¼ ìŒì„±ìœ¼ë¡œ ì¸ì •
            if self.voice_chunks >= self.voice_threshold:
                if not self.is_speaking:
                    logger.info(f"ğŸ¤ [ìŒì„± ê°ì§€] ë§í•˜ê¸° ì‹œì‘ (RMS: {rms:.1f}, ì„ê³„ê°’: {self.silence_threshold:.1f})")
                self.is_speaking = True
                self.silence_duration = 0
        else:
            # ì¡°ìš©í•˜ë©´ ìŒì„± ì¹´ìš´í„° ë¦¬ì…‹
            self.voice_chunks = 0
            
            # ì´ì „ì— ë§í•˜ê³  ìˆì—ˆë‹¤ë©´ ì¹¨ë¬µ ì¹´ìš´í„° ì¦ê°€
            if self.is_speaking:
                if self.silence_duration == 0:
                    logger.info(f"ğŸ”‡ [ì¹¨ë¬µ ê°ì§€] ë§ì„ ë©ˆì¶¤ (RMS: {rms:.1f})")
                
                self.silence_duration += 0.02  # 20ms per chunk
                
                # ì¹¨ë¬µ ì§„í–‰ ìƒí™© (0.5ì´ˆë§ˆë‹¤)
                if int(self.silence_duration * 10) % 5 == 0:
                    logger.debug(f"â±ï¸  ì¹¨ë¬µ: {self.silence_duration:.1f}ì´ˆ / {self.max_silence}ì´ˆ")
                
    def should_process(self) -> bool:
        """ì˜¤ë””ì˜¤ ì²˜ë¦¬ê°€ í•„ìš”í•œì§€ í™•ì¸ (ì‚¬ìš©ìê°€ ë§ì„ ë©ˆì·„ëŠ”ì§€)"""
        return (self.is_speaking and
                self.silence_duration >= self.max_silence and 
                len(self.audio_buffer) > 0)
    
    def get_audio(self) -> bytes:
        """
        ë²„í¼ë§ëœ ì˜¤ë””ì˜¤ ê°€ì ¸ì˜¤ê¸° ë° ì´ˆê¸°í™”
        
        Returns:
            bytes: ë³‘í•©ëœ ì˜¤ë””ì˜¤ ë°ì´í„° (PCM í¬ë§·)
        """
        audio = b''.join(self.audio_buffer)
        self.audio_buffer = []
        self.is_speaking = False
        self.silence_duration = 0
        return audio
    
    def add_transcript(self, text: str):
        """
        ì‹¤ì‹œê°„ ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ ë²„í¼ì— ì¶”ê°€
        
        Args:
            text: ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        if text and text.strip():
            self.transcript_buffer.append(text)
            logger.debug(f"ğŸ“ í…ìŠ¤íŠ¸ ë²„í¼ ì¶”ê°€: {len(self.transcript_buffer)}ê°œ ë¬¸ì¥")
    
    def get_full_transcript(self) -> str:
        """
        ì „ì²´ ëŒ€í™” ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        
        Returns:
            str: ê³µë°±ìœ¼ë¡œ ê²°í•©ëœ ì „ì²´ ëŒ€í™” í…ìŠ¤íŠ¸
        """
        return " ".join(self.transcript_buffer)
    
    def start_bot_speaking(self):
        """AI ì‘ë‹µ ì‹œì‘ - ì‚¬ìš©ì ì…ë ¥ ì°¨ë‹¨ (ì—ì½” ë°©ì§€)"""
        logger.info("ğŸ¤– [ì—ì½” ë°©ì§€] AI ì‘ë‹µ ì¤‘ - ì‚¬ìš©ì ì…ë ¥ ì°¨ë‹¨")
        self.is_bot_speaking = True
        # ê¸°ì¡´ ìƒíƒœ ì´ˆê¸°í™”
        self.is_speaking = False
        self.voice_chunks = 0
        self.silence_duration = 0
    
    def stop_bot_speaking(self):
        """AI ì‘ë‹µ ì¢…ë£Œ - 1ì´ˆ ëŒ€ê¸° í›„ ì‚¬ìš©ì ì…ë ¥ ì¬ê°œ"""
        self.bot_silence_delay = 50  # 50ê°œ ì²­í¬ = 1ì´ˆ ëŒ€ê¸°
        self.is_bot_speaking = False
        logger.info("ğŸ¤– [ì—ì½” ë°©ì§€] AI ì‘ë‹µ ì¢…ë£Œ - 1ì´ˆ í›„ ì‚¬ìš©ì ì…ë ¥ ì¬ê°œ")
    
    def remove_silence(self, audio_data: bytes) -> bytes:
        """
        ì˜¤ë””ì˜¤ ë°ì´í„°ì—ì„œ ë¬´ìŒ êµ¬ê°„ ì œê±° (PCM ê¸°ì¤€)
        
        Args:
            audio_data: PCM í¬ë§· ì˜¤ë””ì˜¤ ë°ì´í„°
        
        Returns:
            bytes: ë¬´ìŒì´ ì œê±°ëœ ì˜¤ë””ì˜¤ ë°ì´í„°
        """
        try:
            # ì²­í¬ í¬ê¸° (20ms = 320 bytes at 8kHz PCM 16-bit)
            chunk_size = 320  # 8kHz * 20ms * 2 bytes
            voice_chunks = []
            
            # ë™ì  ì„ê³„ê°’ ì‚¬ìš© (calibration ì™„ë£Œ í›„)
            threshold = self.silence_threshold if self.is_calibrated else self.base_silence_threshold
            
            # ì²­í¬ ë‹¨ìœ„ë¡œ RMS ê³„ì‚°í•˜ì—¬ ìŒì„± êµ¬ê°„ë§Œ ì¶”ì¶œ
            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i + chunk_size]
                
                # ë§ˆì§€ë§‰ ì²­í¬ê°€ ì‘ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²´í¬
                if len(chunk) < chunk_size:
                    break
                
                # RMS ê³„ì‚° (PCM 16-bit)
                try:
                    rms = audioop.rms(chunk, 2)  # 2ë°”ì´íŠ¸ ìƒ˜í”Œ í­
                    
                    # ì„ê³„ê°’ë³´ë‹¤ í° ê²½ìš°ì—ë§Œ í¬í•¨ (ìŒì„± êµ¬ê°„)
                    if rms > threshold:
                        voice_chunks.append(chunk)
                except Exception as e:
                    logger.debug(f"RMS ê³„ì‚° ì˜¤ë¥˜, ì²­í¬ ê±´ë„ˆëœ€: {e}")
                    continue
            
            if not voice_chunks:
                logger.warning("âš ï¸  ë¬´ìŒ ì œê±° í›„ ë‚¨ì€ ì˜¤ë””ì˜¤ ì—†ìŒ")
                return audio_data  # ì›ë³¸ ë°˜í™˜
            
            # ìŒì„± ì²­í¬ë“¤ì„ ê²°í•©
            cleaned_audio = b''.join(voice_chunks)
            
            reduction_percent = (1 - len(cleaned_audio) / len(audio_data)) * 100
            logger.info(f"ğŸšï¸  ë¬´ìŒ ì œê±°: {len(audio_data)} â†’ {len(cleaned_audio)} bytes ({reduction_percent:.1f}% ê°ì†Œ)")
            
            return cleaned_audio
            
        except Exception as e:
            logger.error(f"âŒ ë¬´ìŒ ì œê±° ì¤‘ ì˜¤ë¥˜: {e}")
            return audio_data  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë°˜í™˜


# ==================== Helper Functions ====================

async def transcribe_audio_realtime(audio_data: bytes, audio_processor=None) -> tuple[str, float]:
    """
    ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (PCM ê¸°ë°˜)
    
    ì´ì œ audio_dataëŠ” ì´ë¯¸ PCM í¬ë§·ì´ë¯€ë¡œ ì¶”ê°€ ë³€í™˜ ë¶ˆí•„ìš”
    
    Args:
        audio_data: PCM ì˜¤ë””ì˜¤ ë°ì´í„° (16-bit)
        audio_processor: AudioProcessor ì¸ìŠ¤í„´ìŠ¤ (ë¬´ìŒ ì œê±°ìš©)
    
    Returns:
        tuple: (ë³€í™˜ëœ í…ìŠ¤íŠ¸, ì‹¤í–‰ ì‹œê°„)
    """
    try:
        import wave
        import io
        
        # âœ… ë¬´ìŒ ì œê±° (AudioProcessorê°€ ì œê³µëœ ê²½ìš°)
        if audio_processor:
            # audio_data = audio_processor.remove_silence(audio_data)
            
            # ë¬´ìŒ ì œê±° í›„ ë°ì´í„°ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
            if len(audio_data) < 1600:  # ìµœì†Œ 0.1ì´ˆ (320 bytes * 5)
                logger.debug("â­ï¸  ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë„ˆë¬´ ì§§ìŒ, STT ìŠ¤í‚µ")
                return "", 0
        
        # PCM ë°ì´í„°ë¥¼ WAV í¬ë§·ìœ¼ë¡œ ë³€í™˜ (ë©”ëª¨ë¦¬ ë‚´)
        logger.info(f"ğŸ” [STT ë””ë²„ê·¸] PCM ë°ì´í„° í¬ê¸°: {len(audio_data)} bytes")
        
        try:
            wav_io = io.BytesIO()
            
            with wave.open(wav_io, 'wb') as wav_file:
                wav_file.setnchannels(1)      # Mono
                wav_file.setsampwidth(2)      # 16-bit (2 bytes)
                wav_file.setframerate(8000)   # 8kHz
                wav_file.writeframes(audio_data)  # ì´ë¯¸ PCM ë°ì´í„°
            
            wav_data = wav_io.getvalue()
            logger.info(f"âœ… [STT ë””ë²„ê·¸] WAV ë³€í™˜ ì™„ë£Œ: {len(wav_data)} bytes")
            
        except Exception as wav_error:
            logger.error(f"âŒ [STT ë””ë²„ê·¸] WAV ë³€í™˜ ì‹¤íŒ¨: {wav_error}")
            logger.error(f"   - PCM ë°ì´í„° í¬ê¸°: {len(audio_data)}")
            logger.error(f"   - PCM ë°ì´í„° íƒ€ì…: {type(audio_data)}")
            return "", 0
        
        # ì‹¤ì‹œê°„ STT ë³€í™˜ (ë¹„ë™ê¸° ì²˜ë¦¬)
        logger.info(f"ğŸ¤ [STT ë””ë²„ê·¸] STT ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹œì‘...")
        try:
            transcript, stt_time = await stt_service.transcribe_audio_chunk(
                wav_data,
                language="ko"
            )
            logger.info(f"âœ… [STT ë””ë²„ê·¸] STT ì„œë¹„ìŠ¤ ì‘ë‹µ ì™„ë£Œ: '{transcript[:50]}...' ({stt_time:.2f}ì´ˆ)")
        except Exception as stt_error:
            logger.error(f"âŒ [STT ë””ë²„ê·¸] STT ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹¤íŒ¨: {stt_error}")
            logger.error(f"   - WAV ë°ì´í„° í¬ê¸°: {len(wav_data)}")
            import traceback
            logger.error(f"   - ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return "", 0
        
        return transcript, stt_time
        
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return "", 0


async def convert_and_send_audio(websocket: WebSocket, stream_sid: str, text: str) -> float:
    """
    ë‹¨ì¼ ë¬¸ì¥ì„ TTS ë³€í™˜í•˜ê³  Twilioë¡œ ì¦‰ì‹œ ì „ì†¡ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
    
    ì´ í•¨ìˆ˜ëŠ” LLM ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ë¬¸ì¥ì´ ì™„ì„±ë  ë•Œë§ˆë‹¤ í˜¸ì¶œë©ë‹ˆë‹¤.
    ì‚¬ìš©ìëŠ” AIê°€ ë§í•˜ëŠ” ê²ƒì„ ê±°ì˜ ì‹¤ì‹œê°„ìœ¼ë¡œ ë“¤ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ì²˜ë¦¬ í”Œë¡œìš°:
    1. ë¬¸ì¥ TTS ë³€í™˜ (ë¹„ë™ê¸°)
    2. WAV â†’ mulaw ë³€í™˜
    3. Base64 ì¸ì½”ë”©
    4. Twilio WebSocketìœ¼ë¡œ ì „ì†¡
    
    Args:
        websocket: Twilio WebSocket ì—°ê²°
        stream_sid: Twilio Stream SID
        text: ë³€í™˜í•  ë¬¸ì¥
    
    Returns:
        float: ì´ ë¬¸ì¥ì˜ ì˜ˆìƒ ì¬ìƒ ì‹œê°„ (ì´ˆ)
    """
    try:
        import wave
        import io
        
        # 1. TTS ë³€í™˜ (ë¬¸ì¥ ë‹¨ìœ„, ë¹„ë™ê¸°)
        audio_data, tts_time = await cartesia_tts_service.text_to_speech_sentence(text)
        
        if not audio_data:
            logger.warning(f"âš ï¸ TTS ë³€í™˜ ì‹¤íŒ¨, ê±´ë„ˆëœ€: {text[:30]}...")
            return 0.0
        
        # 2. WAV â†’ mulaw ë³€í™˜ (Twilio í˜¸í™˜)
        wav_io = io.BytesIO(audio_data)
        with wave.open(wav_io, 'rb') as wav_file:
            channels = wav_file.getnchannels()
            sample_width = wav_file.getsampwidth()
            framerate = wav_file.getframerate()
            pcm_data = wav_file.readframes(wav_file.getnframes())
        
        # Stereo â†’ Mono ë³€í™˜ (í•„ìš” ì‹œ)
        if channels == 2:
            pcm_data = audioop.tomono(pcm_data, sample_width, 1, 1)
        
        # ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜: TwilioëŠ” 8kHz ìš”êµ¬
        if framerate != 8000:
            pcm_data, _ = audioop.ratecv(pcm_data, sample_width, 1, framerate, 8000, None)
        
        # PCM â†’ mulaw ë³€í™˜
        mulaw_data = audioop.lin2ulaw(pcm_data, 2)
        
        # â­ ì¬ìƒ ì‹œê°„ ê³„ì‚° (mulaw 8kHz: 1ì´ˆ = 8000 bytes)
        playback_duration = len(mulaw_data) / 8000.0
        
        # 3. Base64 ì¸ì½”ë”©
        audio_base64 = base64.b64encode(mulaw_data).decode('utf-8')
        
        # 4. Twilioë¡œ ì²­í¬ ë‹¨ìœ„ ì „ì†¡
        chunk_size = 8000  # 8KB ì²­í¬
        for i in range(0, len(audio_base64), chunk_size):
            chunk = audio_base64[i:i + chunk_size]
            
            message = {
                "event": "media",
                "streamSid": stream_sid,
                "media": {
                    "payload": chunk
                }
            }
            
            await websocket.send_text(json.dumps(message))
            await asyncio.sleep(0.02)  # ë¶€ë“œëŸ¬ìš´ ì¬ìƒì„ ìœ„í•œ ì‘ì€ ì§€ì—°
        
        logger.info(f"âœ… ë¬¸ì¥ ì „ì†¡ ì™„ë£Œ ({tts_time:.2f}ì´ˆ, ì¬ìƒ: {playback_duration:.2f}ì´ˆ): {text[:30]}...")
        
        return playback_duration  # ì¬ìƒ ì‹œê°„ ë°˜í™˜
        
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë””ì˜¤ ë³€í™˜/ì „ì†¡ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 0.0


async def process_fallback_response(
    websocket: WebSocket,
    stream_sid: str,
    user_text: str,
    audio_processor=None
) -> str:
    """í´ë°± ëª¨ë“œ - ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬"""
    logger.warning("ğŸ”„ í´ë°± ëª¨ë“œ: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬")
    
    try:
        # ê¸°ì¡´ì˜ ë‹¨ìˆœí•œ TTS ë°©ì‹ ì‚¬ìš©
        response_text = await llm_service.generate_response(user_text, [])
        
        if response_text:
            await send_audio_to_twilio_with_tts(websocket, stream_sid, response_text, audio_processor)
            return response_text
        
        return ""
    except Exception as e:
        logger.error(f"âŒ í´ë°± ëª¨ë“œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return ""

async def process_streaming_response(
    websocket: WebSocket,
    stream_sid: str,
    user_text: str,
    conversation_history: list,
    audio_processor=None
) -> str:
    """
    ìµœì í™”ëœ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ - ì‚¬ì „ ì—°ê²°ëœ WebSocket ì‚¬ìš©
    
    í•µì‹¬ ê°œì„ :
    - ì‚¬ì „ ì—°ê²°ëœ Cartesia WebSocket ì¬ì‚¬ìš©
    - LLM ìŠ¤íŠ¸ë¦¼ì„ ë‘ ê°ˆë˜ë¡œ ë¶„ë¦¬ (í…ìŠ¤íŠ¸ ìˆ˜ì§‘ + TTS)
    """
    import audioop
    
    if audio_processor:
        audio_processor.start_bot_speaking()
    
    try:
        pipeline_start = time.time()
        full_response = []
        logger.info("=" * 60)
        logger.info("ğŸš€ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        logger.info("=" * 60)

        # call_sid ì°¾ê¸° (stream_sidë¡œë¶€í„°)
        call_sid = None
        for cid, session in call_sessions.items():
            if session.stream_sid == stream_sid:
                call_sid = cid
                break
        
        if not call_sid or call_sid not in call_sessions:
            logger.error("âŒ í†µí™” ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - í´ë°± ëª¨ë“œ ì‚¬ìš©")
            return await process_fallback_response(websocket, stream_sid, user_text, audio_processor)
        
        session = call_sessions[call_sid]
        
        # WebSocket ì—°ê²° ìƒíƒœ í™•ì¸
        if not session.is_connected or session.cartesia_ws is None:
            logger.warning("âš ï¸ WebSocket ì—°ê²°ì´ ëŠì–´ì§ - ì¬ì—°ê²° ì‹œë„")
            connection_success = await session.initialize_cartesia_connection()
            if not connection_success:
                logger.error("âŒ WebSocket ì¬ì—°ê²° ì‹¤íŒ¨ - í´ë°± ëª¨ë“œ ì‚¬ìš©")
                return await process_fallback_response(websocket, stream_sid, user_text, audio_processor)
        
        logger.info("ğŸš€ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸ ì‹œì‘ (ì‚¬ì „ ì—°ê²°ëœ WebSocket ì‚¬ìš©)")
        
        # ì‚¬ì „ ì—°ê²°ëœ WebSocket ì‚¬ìš©
        cartesia_ws = session.cartesia_ws
        
        # ë³‘ë ¬ íƒœìŠ¤í¬ ìƒì„±
        # 1. LLM í…ìŠ¤íŠ¸ ìƒì„± + Cartesia ì „ì†¡
        # 2. Cartesia ìŒì„± ìˆ˜ì‹  + Twilio ì „ì†¡
        
        send_task = asyncio.create_task(
            llm_to_cartesia_sender(
                cartesia_ws,
                user_text,
                conversation_history,
                session.context_id,
                full_response,
                pipeline_start
            )
        )
        
        receive_task = asyncio.create_task(
            cartesia_to_twilio_forwarder(
                cartesia_ws,
                websocket,
                stream_sid,
                pipeline_start
            )
        )
        
        # ë‘ íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
        send_result = await send_task
        playback_duration = await receive_task
        
        pipeline_time = time.time() - pipeline_start
        
        logger.info("=" * 60)
        logger.info(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {pipeline_time:.2f}ì´ˆ")
        logger.info(f"   ì˜ˆìƒ ì¬ìƒ ì‹œê°„: {playback_duration:.2f}ì´ˆ")
        logger.info("=" * 60)
        
        # ì¬ìƒ ì™„ë£Œ ëŒ€ê¸°
        if playback_duration > 0:
            await asyncio.sleep(playback_duration * 1.1)
        
        return "".join(full_response)
        
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return ""
    finally:
        if audio_processor:
            audio_processor.stop_bot_speaking()

async def llm_to_cartesia_sender(
    cartesia_ws,
    user_text: str,
    conversation_history: list,
    context_id: str,
    full_response: list,
    pipeline_start: float
):
    """
    LLM í…ìŠ¤íŠ¸ ìƒì„± â†’ Cartesia WebSocket ì „ì†¡
    
    í•µì‹¬: ë¬¸ì¥ì´ ì™„ì„±ë˜ëŠ” ì¦‰ì‹œ ì „ì†¡ (ëŒ€ê¸° ì—†ìŒ)
    """
    import re

    llm_service = LLMService()
    
    try:
        sentence_buffer = ""
        chunk_count = 0
        sentence_count = 0
        first_sentence_sent = False
        
        logger.info("ğŸ¤– [LLM] ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘")
        
        async for chunk in llm_service.generate_response_streaming(user_text, conversation_history):
            chunk_count += 1
            sentence_buffer += chunk
            full_response.append(chunk)  # ì „ì²´ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            
            # ë¬¸ì¥ ì¢…ë£Œ ê°ì§€
            should_send = False
            
            # 1. ëª…í™•í•œ ë¬¸ì¥ ì¢…ë£Œ (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ)
            if re.search(r'[.!?\nã€‚ï¼ï¼Ÿ]', chunk):
                should_send = True
            
            # 2. ì‰¼í‘œë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŠê¸° (ê¸´ ë¬¸ì¥ ë°©ì§€)
            elif len(sentence_buffer) > 40 and re.search(r'[,ï¼Œ]', sentence_buffer[-5:]):
                should_send = True
            
            # 3. ë„ˆë¬´ ê¸´ ë¬¸ì¥ ê°•ì œ ë¶„í•  (80ì ì´ìƒ)
            elif len(sentence_buffer) > 80:
                should_send = True
            
            if should_send and sentence_buffer.strip():
                sentence = sentence_buffer.strip()
                sentence_count += 1
                
                elapsed = time.time() - pipeline_start
                
                if not first_sentence_sent:
                    logger.info(f"âš¡ [ì²« ë¬¸ì¥] +{elapsed:.2f}ì´ˆì— ìƒì„± ì™„ë£Œ!")
                    first_sentence_sent = True
                
                logger.info(f"ğŸ“¤ [ë¬¸ì¥ {sentence_count}] ì „ì†¡: {sentence[:40]}...")
                
                # Cartesiaë¡œ ì¦‰ì‹œ ì „ì†¡
                await cartesia_tts_service._send_text_chunk(
                    cartesia_ws,
                    sentence,
                    context_id,
                    continue_=True
                )
                
                sentence_buffer = ""
        
        # ë§ˆì§€ë§‰ ë¬¸ì¥ ì²˜ë¦¬
        if sentence_buffer.strip():
            sentence_count += 1
            logger.info(f"ğŸ“¤ [ë§ˆì§€ë§‰ ë¬¸ì¥ {sentence_count}] ì „ì†¡: {sentence_buffer[:40]}...")
            
            await cartesia_tts_service._send_text_chunk(
                cartesia_ws,
                sentence_buffer.strip(),
                context_id,
                continue_=False  # ë§ˆì§€ë§‰ ì‹ í˜¸
            )
        
        logger.info(f"âœ… [LLM] ì´ {sentence_count}ê°œ ë¬¸ì¥ ì „ì†¡ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ LLM â†’ Cartesia ì „ì†¡ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())

async def cartesia_to_twilio_forwarder(
    cartesia_ws,
    twilio_ws: WebSocket,
    stream_sid: str,
    pipeline_start: float
) -> float:
    """
    Cartesia ìŒì„± ìˆ˜ì‹  â†’ Twilio ì¦‰ì‹œ ì „ì†¡
    
    í•µì‹¬: ì²­í¬ ë°›ëŠ” ì¦‰ì‹œ ì „ì†¡ (ë²„í¼ë§ ì—†ìŒ)
    
    Returns:
        float: ì´ ì¬ìƒ ì‹œê°„
    """
    import audioop
    import base64
    
    try:
        chunk_count = 0
        total_audio_bytes = 0
        first_audio_received = False
        
        logger.info("ğŸ“¡ [ìˆ˜ì‹ ] Cartesia ìŒì„± ì²­í¬ ëŒ€ê¸° ì¤‘...")
        
        async for message in cartesia_ws:
            try:
                data = json.loads(message)
                
                # ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ 
                if "data" in data:
                    chunk_count += 1
                    
                    elapsed = time.time() - pipeline_start
                    
                    if not first_audio_received:
                        logger.info(f"âš¡ [ì²« ìŒì„±] +{elapsed:.2f}ì´ˆì— ìˆ˜ì‹  ì‹œì‘!")
                        first_audio_received = True
                    
                    # Base64 ë””ì½”ë”© (CartesiaëŠ” PCM 24kHz ë°˜í™˜)
                    audio_chunk = base64.b64decode(data["data"])
                    total_audio_bytes += len(audio_chunk)
                    
                    # PCM 24kHz â†’ 8kHz ë³€í™˜ (Twilio ìš”êµ¬ì‚¬í•­)
                    resampled_pcm, _ = audioop.ratecv(
                        audio_chunk, 2, 1, 24000, 8000, None
                    )
                    
                    # PCM â†’ mulaw ë³€í™˜
                    mulaw_data = audioop.lin2ulaw(resampled_pcm, 2)
                    
                    # Base64 ì¸ì½”ë”©
                    audio_base64 = base64.b64encode(mulaw_data).decode('utf-8')
                    
                    # Twilioë¡œ ì¦‰ì‹œ ì „ì†¡
                    message = {
                        "event": "media",
                        "streamSid": stream_sid,
                        "media": {"payload": audio_base64}
                    }
                    
                    await twilio_ws.send_text(json.dumps(message))
                    
                    if chunk_count % 10 == 0:
                        logger.debug(f"ğŸ“¤ [ì²­í¬ {chunk_count}] Twilio ì „ì†¡ ì™„ë£Œ")
                
                # ì™„ë£Œ ì‹ í˜¸
                elif data.get("done"):
                    logger.info(f"âœ… [ìˆ˜ì‹ ] Cartesia ìŒì„± ìƒì„± ì™„ë£Œ ({chunk_count}ê°œ ì²­í¬)")
                    break
                
                # ì—ëŸ¬ ì²˜ë¦¬
                elif "error" in data:
                    logger.error(f"âŒ Cartesia ì˜¤ë¥˜: {data['error']}")
                    break
                    
            except json.JSONDecodeError:
                logger.warning("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ê±´ë„ˆëœ€")
                continue
        
        # ì¬ìƒ ì‹œê°„ ê³„ì‚° (24kHz, 16-bit)
        playback_duration = total_audio_bytes / (24000 * 2)
        
        logger.info(f"âœ… [ì „ì†¡] Twilio ì „ì†¡ ì™„ë£Œ: {chunk_count}ê°œ ì²­í¬, {playback_duration:.2f}ì´ˆ")
        
        return playback_duration
        
    except Exception as e:
        logger.error(f"âŒ Cartesia â†’ Twilio ì „ì†¡ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 0.0


async def process_tts_and_send(
    websocket: WebSocket,
    stream_sid: str,
    index: int,
    sentence: str,
    completed_audio: dict,
    next_send_index: list,
    send_lock: asyncio.Lock,
    pipeline_start: float
) -> float:
    """
    TTS ë³€í™˜ ë° ì „ì†¡ (ì˜¤ë””ì˜¤ ë³€í™˜ ë³‘ë ¬í™”)
    """
    try:
        tts_start = time.time()
        elapsed_start = tts_start - pipeline_start
        logger.info(f"ğŸ”Š [TTS] ë¬¸ì¥[{index}] ë³€í™˜ ì‹œì‘: {sentence[:30]}...")
        logger.info(f"â° [TTS] ë¬¸ì¥[{index}] ì‹¤ì œ TTS í•¨ìˆ˜ ì§„ì… ì‹œê°„: +{elapsed_start:.2f}ì´ˆ")
        
        # TTS ë³€í™˜ (íƒ€ì„ì•„ì›ƒ 10ì´ˆ)
        try:
            audio_data, tts_time = await asyncio.wait_for(
                cartesia_tts_service.text_to_speech_sentence(sentence),
                timeout=10.0
            )
        except asyncio.TimeoutError:
            logger.error(f"ë¬¸ì¥[{index}] TTS íƒ€ì„ì•„ì›ƒ")
            return 0.0
        
        # ğŸ”‘ ì¶”ê°€: audio_data ìœ íš¨ì„± ê²€ì¦ ê°•í™”
        if not audio_data or not isinstance(audio_data, bytes) or len(audio_data) == 0:
            logger.warning(f"âš ï¸ ë¬¸ì¥[{index}] TTS ì‹¤íŒ¨ ë˜ëŠ” ë¹ˆ ì‘ë‹µ")
            logger.warning(f"    - audio_data íƒ€ì…: {type(audio_data)}")
            logger.warning(f"    - audio_data ê¸¸ì´: {len(audio_data) if audio_data else 0}")
            return 0.0
        
        elapsed_tts_done = time.time() - pipeline_start
        logger.info(f"[+{elapsed_tts_done:.2f}ì´ˆ] ë¬¸ì¥[{index}] TTS ì™„ë£Œ ({tts_time:.2f}ì´ˆ)")
        
        # ìµœì í™”: ì˜¤ë””ì˜¤ ë³€í™˜ì„ ë³„ë„ ìŠ¤ë ˆë“œë¡œ ì²˜ë¦¬ (CPU ì§‘ì•½ì  ì‘ì—…)
        if len(audio_data) > 100000:
            loop = asyncio.get_event_loop()
            mulaw_data, playback_duration = await loop.run_in_executor(
                None,  # ê¸°ë³¸ ThreadPoolExecutor ì‚¬ìš©
                convert_to_mulaw_optimized,
                audio_data
            )
        else:
            mulaw_data, playback_duration = convert_to_mulaw_optimized(audio_data)
        
        # ì™„ë£Œëœ ì˜¤ë””ì˜¤ ì €ì¥
        completed_audio[index] = (mulaw_data, playback_duration)
        
        # ìˆœì„œì— ë§ì¶° ì „ì†¡
        await try_send_in_order(
            websocket, stream_sid,
            completed_audio, next_send_index, send_lock,
            pipeline_start
        )
        
        return playback_duration
        
    except Exception as e:
        logger.error(f"ë¬¸ì¥[{index}] ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return 0.0


def convert_to_mulaw_optimized(audio_data: bytes) -> tuple[bytes, float]:
    """
    ì˜¤ë””ì˜¤ ë³€í™˜ ìµœì í™”
    
    ìµœì í™” í¬ì¸íŠ¸:
    1. âœ… ThreadPoolë¡œ ë³‘ë ¬ ì²˜ë¦¬ (ì†ë„ í–¥ìƒ)
    2. âœ… audioop ì‚¬ìš© ìœ ì§€ (ìŒì§ˆ ë³´ì¥)
    """
    import wave
    import io
    import audioop
    
    # WAV íŒŒì¼ ì½ê¸°
    wav_io = io.BytesIO(audio_data)
    with wave.open(wav_io, 'rb') as wav_file:
        channels = wav_file.getnchannels()
        sample_width = wav_file.getsampwidth()
        framerate = wav_file.getframerate()
        n_frames = wav_file.getnframes()
        pcm_data = wav_file.readframes(n_frames)
    
    logger.info(f"ì›ë³¸ ì˜¤ë””ì˜¤: {framerate}Hz, {channels}ch, {sample_width}ë°”ì´íŠ¸, {n_frames}í”„ë ˆì„")
    
    # Stereo â†’ Mono (í‰ê· )
    if channels == 2:
        pcm_data = audioop.tomono(pcm_data, sample_width, 1, 1)
        logger.info(f"Mono ë³€í™˜ ì™„ë£Œ")
    
    if sample_width != 2:
        pcm_data = audioop.lin2lin(pcm_data, sample_width, 2)
        sample_width = 2
        logger.info(f"16-bit ë³€í™˜ ì™„ë£Œ")
    
    if framerate != 8000:
        logger.info(f"ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜: {framerate}Hz â†’ 8000Hz")
        pcm_data, _ = audioop.ratecv(
            pcm_data, sample_width, 1, framerate, 8000, None
        )
        logger.info(f"ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜ ì™„ë£Œ")

    mulaw_data = audioop.lin2ulaw(pcm_data, 2)
    playback_duration = len(mulaw_data) / 8000.0
    
    return mulaw_data, playback_duration


async def try_send_in_order(
    websocket: WebSocket,
    stream_sid: str,
    completed_audio: dict,
    next_send_index: list,
    send_lock: asyncio.Lock,
    pipeline_start: float
):
    """
    ë‹¤ìŒ ìˆœì„œì˜ ì˜¤ë””ì˜¤ê°€ ì¤€ë¹„ë˜ë©´ ì „ì†¡
    
    í•µì‹¬: ìˆœì„œë¥¼ ê±´ë„ˆë›°ì§€ ì•Šê³  ì°¨ë¡€ëŒ€ë¡œë§Œ ì „ì†¡
    ì˜ˆ: 1ë²ˆ ì™„ë£Œ â†’ ì „ì†¡, 3ë²ˆ ì™„ë£Œ â†’ ëŒ€ê¸°, 2ë²ˆ ì™„ë£Œ â†’ 2,3 ì—°ì† ì „ì†¡
    """
    async with send_lock:  # ë™ì‹œ ì „ì†¡ ë°©ì§€
        # ë‹¤ìŒ ìˆœì„œê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ê³„ì† ì „ì†¡
        while next_send_index[0] in completed_audio:
            index = next_send_index[0]
            mulaw_data, playback_duration = completed_audio[index]
            
            send_start = time.time()
            elapsed_send_start = send_start - pipeline_start
            logger.info(f"ğŸ“¤ [AUDIO] ë¬¸ì¥[{index}] ìŒì„± ì „ì†¡ ì‹œì‘")
            
            # Base64 ì¸ì½”ë”© ë° ì²­í¬ ë‹¨ìœ„ ì „ì†¡
            audio_base64 = base64.b64encode(mulaw_data).decode('utf-8')
            
            chunk_size = 8000  # 8KB ì²­í¬
            for i in range(0, len(audio_base64), chunk_size):
                chunk = audio_base64[i:i + chunk_size]
                
                message = {
                    "event": "media",
                    "streamSid": stream_sid,
                    "media": {"payload": chunk}
                }
                
                await websocket.send_text(json.dumps(message))
                await asyncio.sleep(0.02)  # ë¶€ë“œëŸ¬ìš´ ì¬ìƒ
            
            elapsed_send_done = time.time() - pipeline_start
            logger.info(f"âœ… [AUDIO] ë¬¸ì¥[{index}] ìŒì„± ì¶œë ¥ ì¢…ë£Œ (ì¬ìƒ: {playback_duration:.2f}ì´ˆ)")
            
            # ì •ë¦¬ ë° ë‹¤ìŒ ìˆœì„œë¡œ ì´ë™
            del completed_audio[index]
            next_send_index[0] += 1


async def _generate_welcome_audio_async(text: str) -> bytes:
    """í™˜ì˜ ë©”ì‹œì§€ ì˜¤ë””ì˜¤ë¥¼ ë¯¸ë¦¬ ìƒì„±"""
    try:
        start_time = time.time()
        
        # ì´ë¯¸ ì¤€ë¹„ëœ í† í° ì‚¬ìš©
        access_token = await cartesia_tts_service._get_access_token()
        
        # ìµœì í™”ëœ HTTP í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
        client = await cartesia_tts_service._get_http_client()
        
        response = await client.post(
            "https://api.cartesia.ai/tts/bytes",
            headers={
                "Authorization": f"Bearer {access_token}",
                "Content-Type": "application/json",
                "Cartesia-Version": "2025-04-16",
            },
            json={
                "model_id": cartesia_tts_service.model,
                "transcript": text,
                "voice": {
                    "mode": "id",
                    "id": cartesia_tts_service.voice
                },
                "language": "ko",
                "output_format": {
                    "container": "raw",
                    "encoding": "pcm_s16le",
                    "sample_rate": 24000
                }
            }
        )
        
        response.raise_for_status()
        pcm_data = response.content
        
        # ì˜¤ë””ì˜¤ ë³€í™˜ (Î¼-law ë³€í™˜ì€ í•„ìˆ˜ì´ë¯€ë¡œ ìœ ì§€)
        resampled_pcm, _ = audioop.ratecv(
            pcm_data, 2, 1, 24000, 8000, None
        )
        mulaw_data = audioop.lin2ulaw(resampled_pcm, 2)
        
        tts_time = time.time() - start_time
        logger.info(f"âœ… [í™˜ì˜] ì‚¬ì „ ìƒì„± ì™„ë£Œ ({tts_time:.2f}ì´ˆ)")
        
        return mulaw_data
        
    except Exception as e:
        logger.error(f"âŒ í™˜ì˜ ë©”ì‹œì§€ ì‚¬ì „ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

async def _send_prepared_audio_to_twilio(
    websocket: WebSocket, 
    stream_sid: str, 
    mulaw_data: bytes, 
    audio_processor=None
):
    """ì¤€ë¹„ëœ ì˜¤ë””ì˜¤ë¥¼ Twilioë¡œ ì „ì†¡"""
    if not mulaw_data:
        return
    
    try:
        if audio_processor:
            audio_processor.start_bot_speaking()
        
        # Base64 ì¸ì½”ë”© ë° ì „ì†¡
        audio_base64 = base64.b64encode(mulaw_data).decode('utf-8')
        
        logger.info(f"ğŸ“¤ [í™˜ì˜] ì¦‰ì‹œ ì „ì†¡: {len(mulaw_data)} bytes")
        
        # ì²­í¬ ë‹¨ìœ„ ì „ì†¡ (ì§€ì—° ì‹œê°„ ë‹¨ì¶•)
        chunk_size = 8000
        for i in range(0, len(audio_base64), chunk_size):
            chunk = audio_base64[i:i + chunk_size]
            
            message = {
                "event": "media",
                "streamSid": stream_sid,
                "media": {"payload": chunk}
            }
            
            await websocket.send_text(json.dumps(message))
            await asyncio.sleep(0.01)  # 0.02ì´ˆ â†’ 0.01ì´ˆë¡œ ë‹¨ì¶•
        
        logger.info(f"âœ… [í™˜ì˜] ì¦‰ì‹œ ì „ì†¡ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ ì¤€ë¹„ëœ ì˜¤ë””ì˜¤ ì „ì†¡ ì‹¤íŒ¨: {e}")
    finally:
        if audio_processor:
            audio_processor.stop_bot_speaking()


async def send_audio_to_twilio_with_tts(websocket: WebSocket, stream_sid: str, text: str, audio_processor=None):
    """
    TTS Serviceë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ í›„ Twilio WebSocketìœ¼ë¡œ ì „ì†¡
    WAV â†’ mulaw ë³€í™˜ í¬í•¨
    
    Args:
        websocket: Twilio WebSocket ì—°ê²°
        stream_sid: Twilio Stream SID
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        audio_processor: AudioProcessor ì¸ìŠ¤í„´ìŠ¤ (ì—ì½” ë°©ì§€ìš©)
    """
    import httpx
    
    if audio_processor:
        audio_processor.start_bot_speaking()
    
    logger.info(f"ğŸ™ï¸ [í™˜ì˜] ë¹ ë¥¸ ìŒì„± ìƒì„±: {text}")
    
    try:
        start_time = time.time()
        
        # Cartesia HTTP API ì§ì ‘ í˜¸ì¶œ (ìµœì í™”ëœ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©)
        access_token = await cartesia_tts_service._get_access_token()
        client = await cartesia_tts_service._get_http_client()
        
        try:
            response = await client.post(
                "https://api.cartesia.ai/tts/bytes",
                headers={
                    "Authorization": f"Bearer {access_token}",
                    "Content-Type": "application/json",
                    "Cartesia-Version": "2025-04-16",
                },
                json={
                    "model_id": cartesia_tts_service.model,
                    "transcript": text,
                    "voice": {
                        "mode": "id",
                        "id": cartesia_tts_service.voice
                    },
                    "language": "ko",
                    "output_format": {
                        "container": "raw",
                        "encoding": "pcm_s16le",
                        "sample_rate": 24000
                    }
                }
            )
            
            response.raise_for_status()
            pcm_data = response.content
            
            tts_time = time.time() - start_time
            logger.info(f"âœ… [í™˜ì˜] TTS ì™„ë£Œ ({tts_time:.2f}ì´ˆ)")
            
            if not pcm_data or len(pcm_data) == 0:
                logger.error("âŒ ìŒì„± ë°ì´í„° ì—†ìŒ")
                return
            
            # PCM 24kHz â†’ 8kHz mulaw (Twilio)
            resampled_pcm, _ = audioop.ratecv(
                pcm_data, 2, 1, 24000, 8000, None
            )
            mulaw_data = audioop.lin2ulaw(resampled_pcm, 2)
            
            # Base64 ì¸ì½”ë”© ë° ì „ì†¡
            audio_base64 = base64.b64encode(mulaw_data).decode('utf-8')
            
            logger.info(f"ğŸ“¤ [í™˜ì˜] ìŒì„± ì „ì†¡ ì‹œì‘: {len(mulaw_data)} bytes")
            
            # ì²­í¬ ë‹¨ìœ„ ì „ì†¡
            chunk_size = 8000
            for i in range(0, len(audio_base64), chunk_size):
                chunk = audio_base64[i:i + chunk_size]
                
                message = {
                    "event": "media",
                    "streamSid": stream_sid,
                    "media": {"payload": chunk}
                }
                
                await websocket.send_text(json.dumps(message))
                # await asyncio.sleep(0.02)
            
            total_time = time.time() - start_time
            logger.info(f"âœ… [í™˜ì˜] ì „ì†¡ ì™„ë£Œ (ì´ {total_time:.2f}ì´ˆ)")
            
        except httpx.HTTPStatusError as e:
            logger.error(f"âŒ Cartesia API ì˜¤ë¥˜: {e.response.status_code}")
            logger.error(f"ì‘ë‹µ: {e.response.text}")
        except Exception as e:
            logger.error(f"âŒ í™˜ì˜ ë©”ì‹œì§€ ì „ì†¡ ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(traceback.format_exc())
    except Exception as e:
        logger.error(f"âŒ ì „ì²´ í™˜ì˜ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        if audio_processor:
            audio_processor.stop_bot_speaking()

# Lifespan ì´ë²¤íŠ¸ (startup/shutdown)
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸"""
    # Startup
    logger.info("ğŸš€ Starting Grandby API Server...")
    logger.info(f"Environment: {settings.ENVIRONMENT}")
    logger.info(f"Debug Mode: {settings.DEBUG}")
    
    # DB ì—°ê²° í…ŒìŠ¤íŠ¸
    if test_db_connection():
        logger.info("âœ… Database connection successful")
    else:
        logger.error("âŒ Database connection failed")
    
    # Sentry ì´ˆê¸°í™” (í”„ë¡œë•ì…˜ í™˜ê²½)
    if settings.SENTRY_DSN and not is_development():
        import sentry_sdk
        sentry_sdk.init(
            dsn=settings.SENTRY_DSN,
            environment=settings.ENVIRONMENT,
            traces_sample_rate=0.1,
        )
        logger.info("âœ… Sentry initialized")
    
    # Cartesia TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    try:
        await cartesia_tts_service.ensure_token_ready()
        logger.info("ğŸš€ Cartesia TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ Cartesia ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    yield
    
    # Shutdown
    logger.info("ğŸ‘‹ Shutting down Grandby API Server...")
    
    # Cartesia ì„œë¹„ìŠ¤ ì •ë¦¬
    try:
        await cartesia_tts_service.close()
        logger.info("ğŸ”„ Cartesia TTS ì„œë¹„ìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ Cartesia ì„œë¹„ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title=settings.APP_NAME,
    description="AI ê¸°ë°˜ ì–´ë¥´ì‹  ì¼€ì–´ í”Œë«í¼ Backend API",
    version=settings.APP_VERSION,
    docs_url="/docs" if is_development() else None,  # í”„ë¡œë•ì…˜ì—ì„œëŠ” Swagger ë¹„í™œì„±í™”
    redoc_url="/redoc" if is_development() else None,
    lifespan=lifespan,
)


# ==================== Middleware ====================

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins_list,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ìš”ì²­ ë¡œê¹… Middleware
@app.middleware("http")
async def log_requests(request: Request, call_next):
    """ëª¨ë“  HTTP ìš”ì²­ ë¡œê¹…"""
    logger.info(f"ğŸ“¥ {request.method} {request.url.path}")
    response = await call_next(request)
    logger.info(f"ğŸ“¤ {request.method} {request.url.path} - {response.status_code}")
    return response


# ==================== Exception Handlers ====================

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """422 Validation Error ìƒì„¸ ì •ë³´ ë¡œê¹…"""
    logger.error(f"âŒ 422 Validation Error:")
    logger.error(f"âŒ URL: {request.url}")
    logger.error(f"âŒ Method: {request.method}")
    logger.error(f"âŒ Body: {exc.body}")
    logger.error(f"âŒ Errors: {exc.errors()}")
    
    # ìƒì„¸ ì—ëŸ¬ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜
    return JSONResponse(
        status_code=422,
        content={
            "detail": "Validation Error",
            "errors": exc.errors(),
            "body": exc.body if isinstance(exc.body, dict) else (exc.body.decode() if exc.body else None)
        }
    )

@app.exception_handler(404)
async def not_found_handler(request: Request, exc):
    """404 ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
    return JSONResponse(
        status_code=404,
        content={
            "detail": "ìš”ì²­í•˜ì‹  ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "path": str(request.url.path)
        }
    )


@app.exception_handler(500)
async def internal_error_handler(request: Request, exc):
    """500 ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
    logger.error(f"Internal Server Error: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "detail": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "error": str(exc) if is_development() else "Internal Server Error"
        }
    )


# ==================== Root Endpoints ====================

@app.get("/", tags=["Root"])
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "ğŸ  Welcome to Grandby API",
        "version": settings.APP_VERSION,
        "docs": "/docs" if is_development() else "disabled",
    }


@app.get("/health", tags=["Health"])
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ (Docker, Kubernetesìš©)"""
    db_status = "healthy" if test_db_connection() else "unhealthy"
    
    return {
        "status": "healthy" if db_status == "healthy" else "degraded",
        "version": settings.APP_VERSION,
        "environment": settings.ENVIRONMENT,
        "database": db_status,
    }


# ==================== API Routers ====================

# ì¸ì¦
app.include_router(
    auth.router,
    prefix="/api/auth",
    tags=["Authentication"]
)

# ì‚¬ìš©ì ê´€ë¦¬
app.include_router(
    users.router,
    prefix="/api/users",
    tags=["Users"]
)

# AI í†µí™”
app.include_router(
    calls.router,
    prefix="/api/calls",
    tags=["AI Calls"]
)

# ë‹¤ì´ì–´ë¦¬
app.include_router(
    diaries.router,
    prefix="/api/diaries",
    tags=["Diaries"]
)

# TODO ê´€ë¦¬
app.include_router(
    todos.router,
    prefix="/api/todos",
    tags=["TODOs"]
)

# ì•Œë¦¼
app.include_router(
    notifications.router,
    prefix="/api/notifications",
    tags=["Notifications"]
)

# ë³´í˜¸ì ëŒ€ì‹œë³´ë“œ
app.include_router(
    dashboard.router,
    prefix="/api/dashboard",
    tags=["Dashboard"]
)

# ==================== Twilio WebSocket Endpoints ====================

class RealtimeCallRequest(BaseModel):
    """ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ìš”ì²­"""
    to_number: str  # ì „í™”ë²ˆí˜¸ (+821012345678 í˜•ì‹)
    user_id: str = "test-user"  # ì‚¬ìš©ì ID (ì„ íƒ)


class RealtimeCallResponse(BaseModel):
    """ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ì‘ë‹µ"""
    success: bool
    call_sid: str
    to_number: str
    status: str
    message: str
    voice_url: str
    timestamp: str


@app.post("/api/twilio/call", response_model=RealtimeCallResponse, tags=["Twilio"])
async def initiate_realtime_call(
    request: RealtimeCallRequest,
    db: Session = Depends(get_db)
):
    """
    ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ë°œì‹  (WebSocket ê¸°ë°˜)
    
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì „í™”ë²ˆí˜¸ë¡œ ì „í™”ë¥¼ ê±¸ê³ , WebSocketì„ í†µí•´ ì‹¤ì‹œê°„ AI ëŒ€í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    í”Œë¡œìš°:
    1. ì•±ì—ì„œ ì´ API í˜¸ì¶œ (ì „í™”ë²ˆí˜¸ ì „ë‹¬)
    2. Twilioê°€ ì‚¬ìš©ì ì „í™”ë²ˆí˜¸ë¡œ ì „í™” ë°œì‹ 
    3. ì‚¬ìš©ìê°€ ì „í™” ë°›ìŒ
    4. /api/twilio/voice ì—”ë“œí¬ì¸íŠ¸ì—ì„œ WebSocket ì—°ê²° ì‹œì‘
    5. ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™” (STT â†’ LLM â†’ TTS)
    """
    try:
        # API Base URL í™•ì¸
        if not settings.API_BASE_URL:
            raise HTTPException(
                status_code=400,
                detail="API_BASE_URLì´ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ngrok ë˜ëŠ” ë„ë©”ì¸ í•„ìš”)"
            )
        
        # Twilio ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        twilio_service = TwilioService()
        
        # Callback URL ì„¤ì • (WebSocket ì—°ê²°)
        api_base_url = settings.API_BASE_URL
        voice_url = f"https://{api_base_url}/api/twilio/voice"  # WebSocket ì‹œì‘ ì—”ë“œí¬ì¸íŠ¸
        status_callback_url = f"https://{api_base_url}/api/twilio/call-status"
        
        logger.info(f"ğŸ“ ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ë°œì‹  ì‹œì‘: {request.to_number}")
        logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ID: {request.user_id}")
        logger.info(f"ğŸ”— Voice URL (WebSocket ì‹œì‘): {voice_url}")
        
        # ì „í™” ê±¸ê¸°
        call_sid = twilio_service.make_call(
            to_number=request.to_number,  # ì‚¬ìš©ì ì…ë ¥ ì „í™”ë²ˆí˜¸
            voice_url=voice_url,
            status_callback_url=status_callback_url
        )
        
        # í†µí™” ê¸°ë¡ ì €ì¥ (ì„ íƒì‚¬í•­)
        try:
            from app.models.call import CallLog
            new_call = CallLog(
                call_id=call_sid,
                elderly_id=request.user_id,
                call_status="initiated",
                twilio_call_sid=call_sid,
                created_at=datetime.utcnow()
            )
            db.add(new_call)
            db.commit()
            logger.info(f"âœ… í†µí™” ê¸°ë¡ ì €ì¥: {call_sid}")
        except Exception as e:
            logger.warning(f"âš ï¸ í†µí™” ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {str(e)}")
            db.rollback()
        
        logger.info(f"âœ… ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ë°œì‹  ì„±ê³µ: {call_sid}")
        
        return RealtimeCallResponse(
            success=True,
            call_sid=call_sid,
            to_number=request.to_number,
            status="initiated",
            message=f"ì‹¤ì‹œê°„ AI ëŒ€í™” ì „í™”ê°€ {request.to_number}ë¡œ ë°œì‹ ë˜ì—ˆìŠµë‹ˆë‹¤. ì „í™”ë¥¼ ë°›ìœ¼ì‹œë©´ AIì™€ ëŒ€í™”í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            voice_url=voice_url,
            timestamp=datetime.utcnow().isoformat()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ë°œì‹  ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ì‹¤ì‹œê°„ AI ëŒ€í™” í†µí™” ë°œì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )


@app.post("/api/twilio/voice", response_class=PlainTextResponse, tags=["Twilio"])
async def voice_handler():
    """
    Twilio ì „í™” ì—°ê²° ì‹œ WebSocket ìŠ¤íŠ¸ë¦¼ ì‹œì‘
    """
    response = VoiceResponse()
    
    # í™˜ì˜ ë©”ì‹œì§€
    # response.say(
    #     "ì•ˆë…•í•˜ì„¸ìš”. AI ì–´ì‹œìŠ¤í„´íŠ¸ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.",
    #     language='ko-KR'
    # )
    
    # WebSocket ìŠ¤íŠ¸ë¦¼ ì—°ê²° ì„¤ì •
    if not settings.API_BASE_URL:
        logger.error("âš ï¸ API_BASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        api_base_url = "your-domain.com"  # fallback (ì‘ë™í•˜ì§€ ì•ŠìŒ)
    else:
        api_base_url = settings.API_BASE_URL
    
    websocket_url = f"wss://{api_base_url}/api/twilio/media-stream"
    
    connect = Connect()
    stream = Stream(url=websocket_url)
    connect.append(stream)
    response.append(connect)
    
    logger.info(f"ğŸ™ï¸ Twilio WebSocket ìŠ¤íŠ¸ë¦¼ ì‹œì‘: {websocket_url}")
    return str(response)


@app.websocket("/api/twilio/media-stream")
async def media_stream_handler(
    websocket: WebSocket,
    db: Session = Depends(get_db)
):
    """
    Twilio Media Streams WebSocket í•¸ë“¤ëŸ¬ (RTZR ì‹¤ì‹œê°„ STT ì ìš©)
    
    ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë°ì´í„° ì–‘ë°©í–¥ ì²˜ë¦¬ (RTZR ê¸°ë°˜):
    1. RTZR ì‹¤ì‹œê°„ STT ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    2. ë¶€ë¶„ ì¸ì‹ ê²°ê³¼ë¥¼ LLMì— ë°±ê·¸ë¼ìš´ë“œ ì „ì†¡ (ëŒ€ê¸° ìƒíƒœ ìœ ì§€)
    3. ìµœì¢… ì¸ì‹ ê²°ê³¼(is_final: true) ê°ì§€
    4. ì¦‰ì‹œ AI ì‘ë‹µ ìƒì„± ë° TTS ì¬ìƒ
    5. í†µí™” ì¢…ë£Œ ì‹œ ì „ì²´ ëŒ€í™” ë‚´ìš© ì €ì¥
    
    RTZR ì‹¤ì‹œê°„ STT â†’ LLM (ë°±ê·¸ë¼ìš´ë“œ) â†’ ìµœì¢… ë¬¸ì¥ â†’ ì¦‰ì‹œ ì‘ë‹µ
    """
    await websocket.accept()
    logger.info("ğŸ“ Twilio WebSocket ì—°ê²°ë¨")
    
    call_sid = None
    stream_sid = None
    rtzr_stt = None  # RTZR ì‹¤ì‹œê°„ STT
    llm_collector = None  # LLM ë¶€ë¶„ ê²°ê³¼ ìˆ˜ì§‘ê¸°
    call_log = None  # DBì— ì €ì¥í•  CallLog ê°ì²´
    elderly_id = None  # í†µí™” ëŒ€ìƒ ì–´ë¥´ì‹  ID
    partial_response_context = ""  # ë¶€ë¶„ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ (LLM ë©”ëª¨ë¦¬)
    
    try:
        async for message in websocket.iter_text():
            data = json.loads(message)
            event_type = data.get('event')
            
            # ========== 1. ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ==========
            if event_type == 'start':
                call_sid = data['start']['callSid']
                stream_sid = data['start']['streamSid']
                
                # customParametersì—ì„œ elderly_id ì¶”ì¶œ (Twilio í†µí™” ì‹œì‘ ì‹œ ì „ë‹¬)
                custom_params = data['start'].get('customParameters', {})
                elderly_id = custom_params.get('elderly_id', 'unknown')
                
                active_connections[call_sid] = websocket
                
                # ëŒ€í™” ì„¸ì…˜ ì´ˆê¸°í™” (LLM ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬)
                if call_sid not in conversation_sessions:
                    conversation_sessions[call_sid] = []
                
                # RTZR ì‹¤ì‹œê°„ STT ì´ˆê¸°í™”
                rtzr_stt = RTZRRealtimeSTT()
                
                # LLM ë¶€ë¶„ ê²°ê³¼ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” (ë°±ê·¸ë¼ìš´ë“œ ì „ì†¡)
                async def llm_partial_callback(partial_text: str):
                    """ë¶€ë¶„ ì¸ì‹ ê²°ê³¼ë¥¼ LLMì— ë°±ê·¸ë¼ìš´ë“œ ì „ì†¡"""
                    nonlocal partial_response_context, call_sid
                    # LLMì´ ë¯¸ë¦¬ ì¤€ë¹„í•  ìˆ˜ ìˆë„ë¡ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                    partial_response_context = partial_text
                    logger.debug(f"ğŸ’­ [LLM ë°±ê·¸ë¼ìš´ë“œ] ë¶€ë¶„ ê²°ê³¼ ì—…ë°ì´íŠ¸: {partial_text}")
                
                llm_collector = LLMPartialCollector(llm_partial_callback)
                
                # DBì— í†µí™” ì‹œì‘ ê¸°ë¡ ì €ì¥ (status: initiatedë§Œ)
                try:
                    from app.models.call import CallLog, CallStatus
                    db = next(get_db())
                    
                    # ê¸°ì¡´ CallLogê°€ ìˆëŠ”ì§€ í™•ì¸
                    existing_call = db.query(CallLog).filter(CallLog.call_id == call_sid).first()
                    
                    if not existing_call:
                        call_log = CallLog(
                            call_id=call_sid,
                            elderly_id=elderly_id,
                            call_status=CallStatus.INITIATED,
                            twilio_call_sid=call_sid
                        )
                        db.add(call_log)
                        db.commit()
                        db.refresh(call_log)
                        logger.info(f"âœ… DBì— í†µí™” ì‹œì‘ ê¸°ë¡ ì €ì¥: {call_sid}")
                    else:
                        logger.info(f"â­ï¸  ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í†µí™” ê¸°ë¡: {call_sid}")
                    
                    db.close()
                except Exception as e:
                    logger.error(f"âŒ í†µí™” ì‹œì‘ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
                
                logger.info(f"â”Œ{'â”€'*58}â”")
                logger.info(f"â”‚ ğŸ™ï¸  Twilio í†µí™” ì‹œì‘ (RTZR STT)                     â”‚")
                logger.info(f"â”‚ Call SID: {call_sid:43} â”‚")
                logger.info(f"â”‚ Stream SID: {stream_sid:41} â”‚")
                logger.info(f"â”‚ Elderly ID: {elderly_id:41} â”‚")
                logger.info(f"â””{'â”€'*58}â”˜")
                
                # ğŸš€ ê°œì„ : í†µí™” ì„¸ì…˜ ìƒì„± ë° Cartesia WebSocket ì—°ê²°
                call_session = CallSession(call_sid, stream_sid)
                call_sessions[call_sid] = call_session
                
                # Cartesia WebSocket ì—°ê²°ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘
                connection_success = await call_session.initialize_cartesia_connection()
                
                if connection_success:
                    logger.info("ğŸ‰ Cartesia WebSocket ì—°ê²° ì¤€ë¹„ ì™„ë£Œ - ì¦‰ì‹œ ì‘ë‹µ ê°€ëŠ¥!")
                else:
                    logger.warning("âš ï¸ Cartesia WebSocket ì—°ê²° ì‹¤íŒ¨ - í´ë°± ëª¨ë“œ ì‚¬ìš©")
                
                # ğŸš€ ê°œì„ : í† í°ê³¼ í™˜ì˜ ë©”ì‹œì§€ë¥¼ ë³‘ë ¬ë¡œ ì¤€ë¹„
                welcome_text = "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
                
                # í† í° ë¯¸ë¦¬ ì¤€ë¹„ (ë°±ê·¸ë¼ìš´ë“œ)
                token_task = asyncio.create_task(
                    cartesia_tts_service._get_access_token()
                )
                
                # í™˜ì˜ ë©”ì‹œì§€ TTS ë¯¸ë¦¬ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬)
                welcome_audio_task = asyncio.create_task(
                    _generate_welcome_audio_async(welcome_text)
                )
                
                # ëª¨ë“  ì¤€ë¹„ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
                await asyncio.gather(token_task, welcome_audio_task)
                
                # ì¤€ë¹„ëœ ì˜¤ë””ì˜¤ë¡œ ì¦‰ì‹œ ì „ì†¡
                await _send_prepared_audio_to_twilio(
                    websocket, stream_sid, welcome_audio_task.result(), None
                )
                
                # ========== RTZR ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ==========
                logger.info("ğŸ¤ RTZR ì‹¤ì‹œê°„ STT ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘")
                
                # STT ì‘ë‹µ ì†ë„ ì¸¡ì • ë³€ìˆ˜
                last_partial_time = None
                
                async def process_rtzr_results():
                    """RTZR ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬"""
                    nonlocal last_partial_time, call_sid
                    stt_complete_time = None
                    try:
                        async for result in rtzr_stt.start_streaming():
                            # âœ… í†µí™” ì¢…ë£Œ ì²´í¬
                            if call_sid not in conversation_sessions:
                                logger.info("âš ï¸ í†µí™” ì¢…ë£Œë¡œ ì¸í•œ RTZR ì²˜ë¦¬ ì¤‘ë‹¨")
                                break
                            
                            if not result or 'text' not in result:
                                continue
                            
                            text = result.get('text', '')
                            is_final = result.get('is_final', False)
                            partial_only = result.get('partial_only', False)
                            
                            current_time = time.time()
                            
                            # ë¶€ë¶„ ê²°ê³¼ëŠ” ë¬´ì‹œí•˜ë˜ ì‹œê°„ ê¸°ë¡
                            if partial_only and text:
                                logger.debug(f"ğŸ“ [RTZR ë¶€ë¶„ ì¸ì‹] {text}")
                                last_partial_time = current_time
                                continue
                            
                            # ìµœì¢… ê²°ê³¼ ì²˜ë¦¬
                            if is_final and text:
                                # âœ… í†µí™” ì¢…ë£Œ ì²´í¬
                                if call_sid not in conversation_sessions:
                                    logger.info("âš ï¸ í†µí™” ì¢…ë£Œë¡œ ì¸í•œ ìµœì¢… ì²˜ë¦¬ ì¤‘ë‹¨")
                                    break
                                # STT ì‘ë‹µ ì†ë„ ì¸¡ì •
                                # ë§ì´ ëë‚œ ì‹œì ë¶€í„° ìµœì¢… ì¸ì‹ê¹Œì§€ì˜ ì‹œê°„
                                if last_partial_time:
                                    speech_to_final_delay = current_time - last_partial_time
                                    logger.info(f"â±ï¸ [STT ì§€ì—°] ë§ ë â†’ ìµœì¢… ì¸ì‹: {speech_to_final_delay:.2f}ì´ˆ")
                                
                                # ìµœì¢… ë°œí™” ì™„ë£Œ
                                logger.info(f"âœ… [RTZR ìµœì¢…] {text}")
                                
                                # ìµœì¢… ì¸ì‹ ì‹œì  ê¸°ë¡ (LLM ì „ë‹¬ ì „ ì‹œê°„ ì¸¡ì •ìš©)
                                stt_complete_time = current_time
                                
                                # ì¢…ë£Œ í‚¤ì›Œë“œ í™•ì¸
                                if 'ê·¸ëœë¹„ í†µí™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤' in text:
                                    logger.info(f"ğŸ›‘ ì¢…ë£Œ í‚¤ì›Œë“œ ê°ì§€")
                                    
                                    # ëŒ€í™” ì„¸ì…˜ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                                    if call_sid not in conversation_sessions:
                                        conversation_sessions[call_sid] = []
                                    conversation_sessions[call_sid].append({"role": "user", "content": text})
                                    
                                    goodbye_text = "ê·¸ëœë¹„ í†µí™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”!"
                                    conversation_sessions[call_sid].append({"role": "assistant", "content": goodbye_text})
                                    
                                    logger.info("ğŸ”Š [TTS] ì¢…ë£Œ ë©”ì‹œì§€ ì „ì†¡")
                                    await send_audio_to_twilio_with_tts(websocket, stream_sid, goodbye_text, None)
                                    await asyncio.sleep(2)
                                    await websocket.close()
                                    return
                                
                                # ë°œí™” ì²˜ë¦¬ ì‚¬ì´í´
                                cycle_start = time.time()
                                logger.info(f"{'='*60}")
                                logger.info(f"ğŸ¯ ë°œí™” ì™„ë£Œ â†’ ì¦‰ì‹œ ì‘ë‹µ ìƒì„±")
                                logger.info(f"{'='*60}")
                                
                                # ëŒ€í™” ì„¸ì…˜ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                                if call_sid not in conversation_sessions:
                                    conversation_sessions[call_sid] = []
                                conversation_sessions[call_sid].append({"role": "user", "content": text})
                                
                                conversation_history = conversation_sessions[call_sid]
                                
                                # LLM ì „ë‹¬ê¹Œì§€ì˜ ì‹œê°„ ì¸¡ì •
                                llm_delivery_start = time.time()
                                if stt_complete_time:
                                    stt_to_llm_delay = llm_delivery_start - stt_complete_time
                                    logger.info(f"â±ï¸ [ì§€ì—°ì‹œê°„] ìµœì¢… ì¸ì‹ â†’ LLM ì „ë‹¬: {stt_to_llm_delay:.2f}ì´ˆ")
                                
                                # âœ… AI ì‘ë‹µ ì‹œì‘ (ì‚¬ìš©ì ì…ë ¥ ì°¨ë‹¨)
                                rtzr_stt.start_bot_speaking()
                                
                                # LLM ì‘ë‹µ ìƒì„±
                                logger.info("ğŸ¤– [LLM] ì‘ë‹µ ìƒì„± ì‹œì‘")
                                llm_start_time = time.time()
                                ai_response = await process_streaming_response(
                                    websocket,
                                    stream_sid,
                                    text,
                                    conversation_history,
                                    None
                                )
                                llm_end_time = time.time()
                                llm_duration = llm_end_time - llm_start_time
                                
                                # âœ… AI ì‘ë‹µ ì¢…ë£Œ (1ì´ˆ í›„ ì‚¬ìš©ì ì…ë ¥ ì¬ê°œ)
                                rtzr_stt.stop_bot_speaking()
                                
                                logger.info("âœ… [LLM] ì‘ë‹µ ìƒì„± ì™„ë£Œ")
                                
                                # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ë¡œê¹…
                                if stt_complete_time:
                                    total_delay = llm_end_time - stt_complete_time
                                    logger.info(f"â±ï¸ [ì „ì²´ ì§€ì—°] ìµœì¢… ì¸ì‹ â†’ LLM ì™„ë£Œ: {total_delay:.2f}ì´ˆ (LLM ì‘ë‹µ ìƒì„±: {llm_duration:.2f}ì´ˆ)")
                                
                                # AI ì‘ë‹µì„ ëŒ€í™” ì„¸ì…˜ì— ì¶”ê°€ (ì•ˆì „í•˜ê²Œ)
                                try:
                                    if ai_response and ai_response.strip():
                                        # conversation_sessionsì— ì—¬ì „íˆ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                                        if call_sid in conversation_sessions:
                                            conversation_sessions[call_sid].append({"role": "assistant", "content": ai_response})
                                        
                                        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
                                        if call_sid in conversation_sessions and len(conversation_sessions[call_sid]) > 20:
                                            conversation_sessions[call_sid] = conversation_sessions[call_sid][-20:]
                                    
                                    total_cycle_time = time.time() - cycle_start
                                    logger.info(f"â±ï¸  ì „ì²´ ì‘ë‹µ ì‚¬ì´í´: {total_cycle_time:.2f}ì´ˆ")
                                    logger.info(f"{'='*60}\n\n")
                                except KeyError:
                                    # ì„¸ì…˜ì´ ì´ë¯¸ ì‚­ì œëœ ê²½ìš° (í†µí™” ì¢…ë£Œ)
                                    logger.info("âš ï¸  ì„¸ì…˜ì´ ì´ë¯¸ ì‚­ì œë¨ (í†µí™” ì¢…ë£Œ ì¤‘)")
                                    break
                                except Exception as e:
                                    logger.error(f"âŒ ì‘ë‹µ ì €ì¥ ì˜¤ë¥˜: {e}")
                                
                            elif text:
                                # ë¶€ë¶„ ê²°ê³¼ë¥¼ LLMì— ë°±ê·¸ë¼ìš´ë“œ ì „ì†¡
                                llm_collector.add_partial(text)
                                logger.debug(f"ğŸ“ [RTZR ë¶€ë¶„] {text}")
                    
                    except Exception as e:
                        logger.error(f"âŒ RTZR ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        import traceback
                        logger.error(traceback.format_exc())
                
                # RTZR ìŠ¤íŠ¸ë¦¬ë° íƒœìŠ¤í¬ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
                rtzr_task = asyncio.create_task(process_rtzr_results())
                
            # ========== 2. ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  ë° RTZRë¡œ ì „ì†¡ ==========
            elif event_type == 'media':
                if rtzr_stt and rtzr_stt.is_active:
                    # âœ… AI ì‘ë‹µ ì¤‘ì´ë©´ ì˜¤ë””ì˜¤ ë¬´ì‹œ (ì—ì½” ë°©ì§€)
                    if rtzr_stt.is_bot_speaking:
                        continue
                    
                    # âœ… AI ì‘ë‹µ ì¢…ë£Œ í›„ 1ì´ˆ ëŒ€ê¸° ì¤‘ì´ë©´ ë¬´ì‹œ
                    if rtzr_stt.bot_silence_delay > 0:
                        rtzr_stt.bot_silence_delay -= 1
                        continue
                    
                    # Base64 ë””ì½”ë”© (TwilioëŠ” mulaw 8kHzë¡œ ì „ì†¡)
                    audio_payload = base64.b64decode(data['media']['payload'])
                    
                    # RTZRë¡œ ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡
                    await rtzr_stt.add_audio_chunk(audio_payload)
                        
            # ========== 3. ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ==========
            elif event_type == 'stop':
                logger.info(f"\n{'='*60}")
                logger.info(f"ğŸ“ Twilio í†µí™” ì¢…ë£Œ - Call: {call_sid}")
                logger.info(f"{'='*60}")
                
                # âœ… RTZR ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì·¨ì†Œ
                if 'rtzr_task' in locals() and rtzr_task:
                    logger.info("ğŸ›‘ RTZR ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì·¨ì†Œ ì¤‘...")
                    rtzr_task.cancel()
                    try:
                        await asyncio.wait_for(rtzr_task, timeout=2.0)
                    except (asyncio.CancelledError, asyncio.TimeoutError):
                        logger.info("âœ… RTZR ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì¢…ë£Œ ì™„ë£Œ")
                
                # RTZR ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ
                if rtzr_stt:
                    await rtzr_stt.end_streaming()
                    logger.info("ğŸ›‘ RTZR ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ")
                
                # âœ… ëŒ€í™” ì„¸ì…˜ì„ DBì— ì €ì¥ (í•¨ìˆ˜ í˜¸ì¶œ)
                if call_sid in conversation_sessions:
                    conversation = conversation_sessions[call_sid]
                    
                    # ëŒ€í™” ë‚´ìš© ì¶œë ¥
                    if conversation:
                        logger.info(f"\nğŸ“‹ ì „ì²´ ëŒ€í™” ë‚´ìš©:")
                        logger.info(f"â”€" * 60)
                        for msg in conversation:
                            role = "ğŸ‘¤ ì‚¬ìš©ì" if msg['role'] == 'user' else "ğŸ¤– AI"
                            logger.info(f"{role}: {msg['content']}")
                        logger.info(f"â”€" * 60)
                    
                    await save_conversation_to_db(call_sid, conversation)
                
                logger.info(f"â”Œ{'â”€'*58}â”")
                logger.info(f"â”‚ âœ… Twilio í†µí™” ì •ë¦¬ ì™„ë£Œ                               â”‚")
                logger.info(f"â””{'â”€'*58}â”˜\n")
                break
                
    except WebSocketDisconnect:
        logger.info(f"ğŸ“ Twilio WebSocket ì—°ê²° í•´ì œ (Call: {call_sid})")
        # WebSocket ì—°ê²° í•´ì œ ì‹œì—ë„ ì •ë¦¬
        if call_sid and call_sid in call_sessions:
            await call_sessions[call_sid].close()
            del call_sessions[call_sid]
            logger.info("ğŸ”„ Cartesia WebSocket ì—°ê²° ì •ë¦¬ ì™„ë£Œ (ì—°ê²° í•´ì œ)")
    except Exception as e:
        logger.error(f"âŒ Twilio WebSocket ì˜¤ë¥˜: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì •ë¦¬
        if call_sid and call_sid in call_sessions:
            await call_sessions[call_sid].close()
            del call_sessions[call_sid]
            logger.info("ğŸ”„ Cartesia WebSocket ì—°ê²° ì •ë¦¬ ì™„ë£Œ (ì˜¤ë¥˜ ë°œìƒ)")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        # âœ… ì—°ê²° ì¢…ë£Œ ì‹œ í•­ìƒ DB ì €ì¥ (í•µì‹¬!)
        # ì‚¬ìš©ìê°€ ì§ì ‘ ì „í™”ë¥¼ ëŠì–´ë„ ëŒ€í™” ë‚´ìš© ë³´ì¡´
        if call_sid and call_sid in conversation_sessions:
            try:
                conversation = conversation_sessions[call_sid]
                await save_conversation_to_db(call_sid, conversation)
                logger.info(f"ğŸ”„ Finally ë¸”ë¡ì—ì„œ DB ì €ì¥ ì™„ë£Œ: {call_sid}")
            except Exception as e:
                logger.error(f"âŒ Finally ë¸”ë¡ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ì •ë¦¬ ì‘ì—… (ë©”ëª¨ë¦¬ì—ì„œ ì œê±°)
        if call_sid and call_sid in active_connections:
            del active_connections[call_sid]
        if call_sid and call_sid in conversation_sessions:
            del conversation_sessions[call_sid]
        
        logger.info(f"ğŸ§¹ WebSocket ì •ë¦¬ ì™„ë£Œ: {call_sid}")


@app.post("/api/twilio/call-status", tags=["Twilio"])
async def call_status_handler(
    CallSid: str = Form(None),
    CallStatus: str = Form(None)
):
    """
    Twilio í†µí™” ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°±
    í†µí™” ìƒíƒœ: initiated, ringing, answered, completed
    """
    logger.info(f"ğŸ“ í†µí™” ìƒíƒœ ì—…ë°ì´íŠ¸: {CallSid} - {CallStatus}")
    
    # í†µí™” ìƒíƒœì— ë”°ë¥¸ DB ì—…ë°ì´íŠ¸
    try:
        from app.models.call import CallLog, CallStatus as CallStatusEnum
        db = next(get_db())
        
        call_log = db.query(CallLog).filter(CallLog.call_id == CallSid).first()
        
        if call_log:
            if CallStatus == 'answered':
                # í†µí™” ì—°ê²° ì‹œ ì‹œì‘ ì‹œê°„ ì„¤ì •
                if not call_log.call_start_time:
                    call_log.call_start_time = datetime.utcnow()
                    call_log.call_status = CallStatusEnum.ANSWERED
                    db.commit()
                    logger.info(f"âœ… í†µí™” ì‹œì‘ ì‹œê°„ ì„¤ì •: {CallSid}")
            
            elif CallStatus == 'completed':
                # í†µí™” ì¢…ë£Œ ì‹œ ì¢…ë£Œ ì‹œê°„ ì„¤ì •
                call_log.call_end_time = datetime.utcnow()
                call_log.call_status = CallStatusEnum.COMPLETED
                
                # í†µí™” ì‹œê°„ ê³„ì‚°
                if call_log.call_start_time:
                    duration = (call_log.call_end_time - call_log.call_start_time).total_seconds()
                    call_log.call_duration = int(duration)
                    logger.info(f"âœ… í†µí™” ì¢…ë£Œ ì‹œê°„ ì„¤ì •: {CallSid}, ì§€ì†ì‹œê°„: {duration}ì´ˆ")
                
                db.commit()
                
                # âœ… í†µí™” ì¢…ë£Œ ì‹œ DB ì €ì¥ (ë°±ì—…ìš© - ì¤‘ë³µ ë°©ì§€ ë¡œì§ í¬í•¨)
                if CallSid in conversation_sessions:
                    try:
                        conversation = conversation_sessions[CallSid]
                        await save_conversation_to_db(CallSid, conversation)
                        logger.info(f"ğŸ’¾ ì½œë°±ì—ì„œ í†µí™” ê¸°ë¡ ì €ì¥ ì™„ë£Œ: {CallSid}")
                    except Exception as e:
                        logger.error(f"âŒ ì½œë°± DB ì €ì¥ ì‹¤íŒ¨: {e}")
                
                # ì„¸ì…˜ ì •ë¦¬
                if CallSid in conversation_sessions:
                    del conversation_sessions[CallSid]
                if CallSid in active_connections:
                    del active_connections[CallSid]
        
        db.close()
        
    except Exception as e:
        logger.error(f"âŒ í†µí™” ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        if 'db' in locals():
            db.close()
    
    return {"status": "ok", "call_sid": CallSid, "call_status": CallStatus}


# ==================== Startup Message ====================
if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=is_development(),
        log_level=settings.LOG_LEVEL.lower(),
    )
