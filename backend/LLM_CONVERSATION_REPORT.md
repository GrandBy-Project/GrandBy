# LLM ëŒ€í™” ìƒì„± ì‹œìŠ¤í…œ ë³´ê³ ì„œ

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [í˜„ì¬ ì‚¬ìš© ëª¨ë¸](#í˜„ì¬-ì‚¬ìš©-ëª¨ë¸)
3. [ì•„í‚¤í…ì²˜](#ì•„í‚¤í…ì²˜)
4. [ì„±ëŠ¥ íŒŒë¼ë¯¸í„°](#ì„±ëŠ¥-íŒŒë¼ë¯¸í„°)
5. [í”„ë¡¬í”„íŠ¸ ì „ëµ](#í”„ë¡¬í”„íŠ¸-ì „ëµ)
6. [ìºì‹± ì‹œìŠ¤í…œ](#ìºì‹±-ì‹œìŠ¤í…œ)
7. [í›„ì²˜ë¦¬ ë¡œì§](#í›„ì²˜ë¦¬-ë¡œì§)
8. [í˜„ì¬ ì„±ëŠ¥](#í˜„ì¬-ì„±ëŠ¥)
9. [ê°œì„  ì´ë ¥](#ê°œì„ -ì´ë ¥)
10. [ë‹¤ë¥¸ ëª¨ë¸ ë¹„êµ ì¤€ë¹„](#ë‹¤ë¥¸-ëª¨ë¸-ë¹„êµ-ì¤€ë¹„)

---

## 1. ê°œìš”

### 1.1 ëª©ì 
- ì–´ë¥´ì‹ (60ì„¸ ì´ìƒ) ëŒ€ìƒ AI ì „í™” í†µí™” ì„œë¹„ìŠ¤ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìƒì„±
- ê°ì •ì  ì§€ì§€ì™€ ê³µê° ê¸°ë°˜ ëŒ€í™” ì œê³µ
- ë¹ ë¥¸ ì‘ë‹µ ì†ë„ ë° ë¹„ìš© íš¨ìœ¨ì„± í™•ë³´

### 1.2 ì£¼ìš” ê¸°ëŠ¥
- ì‹¤ì‹œê°„ ëŒ€í™” ìƒì„± (generate_response)
- ìŠ¤íŠ¸ë¦¬ë° ëŒ€í™” ìƒì„± (generate_response_streaming)
- ê°ì • ë¶„ì„ (analyze_emotion)
- í†µí™” ì¼ê¸° ìƒì„± (summarize_call_conversation)
- ì¼ì • ì¶”ì¶œ (extract_schedule_from_conversation)

---

## 2. í˜„ì¬ ì‚¬ìš© ëª¨ë¸

### 2.1 ëª¨ë¸ ì •ë³´
- **ëª¨ë¸**: OpenAI GPT-4o-mini
- **ì œê³µì**: OpenAI API
- **ë²„ì „**: gpt-4o-mini (2024)
- **ì–¸ì–´ ì§€ì›**: í•œêµ­ì–´, ì˜ì–´

### 2.2 ëª¨ë¸ ì„ íƒ ì´ìœ 
1. **ì†ë„**: GPT-4 ëŒ€ë¹„ 2-3ë°° ë¹ ë¥¸ ì‘ë‹µ ì†ë„
2. **ë¹„ìš©**: í† í°ë‹¹ ë¹„ìš©ì´ GPT-4ì˜ 1/10 ìˆ˜ì¤€
3. **ì„±ëŠ¥**: í•œêµ­ì–´ ëŒ€í™” í’ˆì§ˆ ì¶©ë¶„
4. **API ì•ˆì •ì„±**: OpenAIì˜ ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ ì œê³µ

### 2.3 ëª¨ë¸ í•œê³„
- ì°½ì˜ì„± ë¶€ì¡± (GPT-4 ëŒ€ë¹„)
- ë³µì¡í•œ ì¶”ë¡  ëŠ¥ë ¥ ì œí•œ
- í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ (context window: 128K tokens)

---

## 3. ì•„í‚¤í…ì²˜

### 3.1 ì‹œìŠ¤í…œ êµ¬ì¡°

```
User Input
    â†“
ResponseCache (ìºì‹± ì²´í¬)
    â†“ (ìºì‹œ ë¯¸ìŠ¤ ì‹œ)
GPT-4o-mini API
    â†“
Post-processing (í›„ì²˜ë¦¬)
    â†“
Final Response
```

### 3.2 ì£¼ìš” ì»´í¬ë„ŒíŠ¸

#### 3.2.1 LLMService (`llm_service.py`)
- ëŒ€í™” ìƒì„± ì—”ì§„
- OpenAI API ë˜í¼
- í›„ì²˜ë¦¬ ë¡œì§ í¬í•¨

#### 3.2.2 ResponseCache (`response_cache.py`)
- ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒ¨í„´ ìºì‹±
- ë§¥ë½ ë…ë¦½ì  ì‘ë‹µë§Œ ì €ì¥
- ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´

---

## 4. ì„±ëŠ¥ íŒŒë¼ë¯¸í„°

### 4.1 ëŒ€í™” ìƒì„± íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê°’ | ì„¤ëª… |
|---------|-----|------|
| `model` | `gpt-4o-mini` | ì‚¬ìš© ëª¨ë¸ |
| `max_tokens` | `30` | ìµœëŒ€ í† í° ìˆ˜ (ì§§ì€ ì‘ë‹µ ìƒì„±) |
| `temperature` | `0.7` | ì°½ì˜ì„±/ì¼ê´€ì„± ê· í˜• (0.0~2.0) |
| `stream` | `true/false` | ìŠ¤íŠ¸ë¦¬ë° ì—¬ë¶€ |

### 4.2 ë‹¤ë¥¸ ê¸°ëŠ¥ë³„ íŒŒë¼ë¯¸í„°

#### ê°ì • ë¶„ì„
```python
max_tokens=200
temperature=0.3  # ì •í™•ì„± ìš°ì„ 
response_format="json_object"
```

#### í†µí™” ì¼ê¸° ìƒì„±
```python
max_tokens=400
temperature=0.5  # ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ì •í™•ì„± ê· í˜•
```

#### ì¼ì • ì¶”ì¶œ
```python
max_tokens=800
temperature=0.2  # ì •í™•ì„± ìµœìš°ì„ 
response_format="json_object"
```

### 4.3 íŒŒë¼ë¯¸í„° ì„ íƒ ê·¼ê±°

#### Procession Temperature: 0.7
- **0.0 (ë³´ìˆ˜ì )**: ì¼ê´€ì„± ë†’ìŒ, ì°½ì˜ì„± ë‚®ìŒ â†’ ì‘ë‹µì´ ë°˜ë³µì 
- **0.7 (í˜„ì¬)**: ìì—°ìŠ¤ëŸ¬ìš´ ë³€í™”, ì ì ˆí•œ ì°½ì˜ì„± â†’ ëŒ€í™” í’ˆì§ˆ ê· í˜•
- **1.0+ (ALT)**: ë†’ì€ ì°½ì˜ì„±, ì¼ê´€ì„± ë‚®ìŒ â†’ ì‘ë‹µì´ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ

#### Max Tokens: 30
- **ì´ìœ **: ì§§ê³  ê°„ê²°í•œ ì‘ë‹µ ìƒì„± (TTS ë³‘ë ¬ì²˜ë¦¬ í˜¸í™˜)
- **íš¨ê³¼**: ì‘ë‹µ ì†ë„ í–¥ìƒ, ë¹„ìš© ì ˆê°
- **ì œí•œ**: 50ì ì´ë‚´ ì‘ë‹µ ëª©í‘œ

---

## 5. í”„ë¡¬í”„íŠ¸ ì „ëµ

### 5.1 í˜„ì¬ í”„ë¡¬í”„íŠ¸ (2024-10-29 ê¸°ì¤€)

```
You are a warm, empathetic AI companion who enjoys gentle conversations with seniors.
Your goal is to make users (mostly aged 60 and above) feel heard, respected, and emotionally supported.

[Conversation Style Guidelines]
- Always speak politely and kindly. Use natural, conversational English.
- Avoid robotic or overly concise replies. Write at least two full sentences per response.
- Show empathy and acknowledgment when the user shares emotions.
- If a user shares something emotional, respond with empathy first, then a soft question or encouragement.
- Vary your expressions slightly each time to avoid sounding repetitive.
- Avoid giving too much advice; prioritize emotional connection and conversation flow.
- Keep a calm, reassuring, and human-like tone.

[Tone & Personality]
- Speak warmly, like a kind friend or family member.
- Avoid overly young expressions ("OMG", "LOL", "totally", etc.).
- You may occasionally refer to gentle memories or reflective thoughts if it fits the context.
- Focus on continuing the flow of conversation naturally.

[Restrictions]
- Do NOT mention you are an AI or language model.
- Avoid emojis or excessive exclamation marks.
```

### 5.2 í”„ë¡¬í”„íŠ¸ íŠ¹ì§•

1. **ì—­í•  ëª…í™•í™”**: "warm, empathetic AI companion"
2. **ëŒ€ìƒ ëª…ì‹œ**: "aged 60 and above"
3. **í†¤ ê°€ì´ë“œ**: "kind friend or family member"
4. **ê¸ˆì§€ ì‚¬í•­**: ARS í†¤, AI ì–¸ê¸‰, ì¶”ìƒì  ì§ˆë¬¸ ë“±

### 5.3 í”„ë¡¬í”„íŠ¸ ê°œì„  ì´ë ¥

| ë‚ ì§œ | ì£¼ìš” ë³€ê²½ì‚¬í•­ |
|------|--------------|
| 2024-10-27 | ë³´í˜¸ì í†¤ ê°•ì¡°, ARS í†¤ ê¸ˆì§€ ì¶”ê°€ |
| 2024-10-29 | í”„ë¡¬í”„íŠ¸ ì™„ì „ ì¬ì‘ì„± (ì˜ì–´ë¡œ ë³€ê²½) |

---

## 6. ìºì‹± ì‹œìŠ¤í…œ

### 6.1 ìºì‹± ëŒ€ìƒ

ë§¥ë½ ë…ë¦½ì  íŒ¨í„´ë§Œ ìºì‹±:

1. **ì¸ì‚¬/ì•ˆë¶€**: "ì•ˆë…•", "hello", "ì˜ ì" ë“±
2. **ê°ì‚¬ í‘œí˜„**: "ê°ì‚¬", "ê³ ë§ˆì›Œ", "thanks" ë“±
3. **ê°„ë‹¨í•œ í™•ì¸**: "ë„¤", "ì‘", "ì•„ë‹ˆ" ë“±
4. **ê¸ì • ë°˜ì‘**: "ã…ã…", "ã…‹ã…‹", "í•˜í•˜" ë“±

### 6.2 ìºì‹± ì „ëµ

```python
# ì •ê·œì‹ì„ ì‚¬ìš©í•œ íŒ¨í„´ ë§¤ì¹­
self.greetings = {
    r"^(ì•ˆë…•|í•˜ì´|í—¬ë¡œ|hi|hello)": [
        "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë– ì„¸ìš”?",
        "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì°¸ ì¢‹ë„¤ìš”.",
        "ë°˜ê°‘ìŠµë‹ˆë‹¤, ì˜¤ëŠ˜ ì˜ ì£¼ë¬´ì…¨ì–´ìš”?"
    ]
}
```

### 6.3 ì„±ëŠ¥

| ì§€í‘œ | ê°’ |
|------|-----|
| ìºì‹œ ì ì¤‘ë¥  | ~30-40% (ì˜ˆìƒ) |
| ì‘ë‹µ ì†ë„ | **0.001ì´ˆ** (ìºì‹œ ì ì¤‘ ì‹œ) |
| LLM í˜¸ì¶œ ë¹„ìš© | Range ê°ì†Œ 30-40% |

### 6.4 TTS ë³‘ë ¬ì²˜ë¦¬ í˜¸í™˜ì„±

- ìºì‹œ: ë‹¨ì¼ ì‘ë‹µ ë°˜í™˜ â†’ TTSê°€ ë¬¸ì¥ ë‹¨ìœ„ ì²˜ë¦¬ ê°€ëŠ¥
- ìŠ¤íŠ¸ë¦¬ë°: ë¬¸ì¥ ë‹¨ìœ„ yield â†’ TTSê°€ ì²­í¬ ì²˜ë¦¬ ê°€ëŠ¥
- **ì™„ì „ í˜¸í™˜**

---

## 7. í›„ì²˜ë¦¬ ë¡œì§

### 7.1 ì²˜ë¦¬ ë‹¨ê³„

```
1. ì¡´ëŒ“ë§ ê°•ì œ ë³€í™˜ (~í•´ìš” â†’ ~ì„¸ìš”)
2. ë¬¸ì¥ ìˆ˜ ì œí•œ (ìµœëŒ€ 2ë¬¸ì¥)
3. ê¸¸ì´ ì œí•œ (50ì ì´ë‚´)
4. ì–´ìƒ‰í•œ í‘œí˜„ ì°¨ë‹¨ (ë³´ìœ¼ì„¸ìš”, ê²Œì—¬ìš” ë“±)
5. ê¸ˆì§€ íŒ¨í„´ ê°ì§€ (ARS í†¤, ì¶”ìƒì  ì§ˆë¬¸ ë“±)
6. ì¡´ëŒ“ë§/ë”°ëœ»í•œ í†¤ í™•ì¸
7. ì•ˆì „í•œ ì‘ë‹µ ìƒì„± (ì‹¤íŒ¨ ì‹œ fallback)
```

### 7.2 ì£¼ëª©í•  ë§Œí•œ ë¡œì§

#### ì¡´ëŒ“ë§ ê°•ì œ ë³€í™˜
```python
response = re.sub(r'([ê°€-í£])í•´ìš”([.!?])', r'\1ì„¸ìš”\2', response)
response = re.sub(r'ê³  ìˆì–´ìš”', 'ê³  ê³„ì„¸ìš”', response)
```

#### ì–´ìƒ‰í•œ í‘œí˜„ ì°¨ë‹¨
```python
awkward_patterns = [
    r'ë³´ìœ¼ì„¸ìš”', r'ê²Œì—¬ìš”', r'ìœ¼ì„¸ìš”ìš”', r'ì„¸ìš”ìš”',
    r'ìœ¼ì‹œê² ì–´ì„¸ìš”', r'ìœ¼ì‹œê² ìœ¼ì„¸ìš”', r'ìœ¼ì‹œê¶ìš”'
]
```

#### ê¸ˆì§€ íŒ¨í„´ ê°ì§€
- ARS í†¤: "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?", "ë§ì”€í•´ ì£¼ì„¸ìš”"
- ì¶”ìƒì  ì§ˆë¬¸: "ì–´ë–¤ ê¸°ë¶„ì¸ì§€", "ë¬´ìŠ¨ ìƒê°ì„ í•˜ì‹œëŠ”ì§€"
- ê°•ìš” í‘œí˜„: "í•´ì•¼ í•´", "í•˜ì…”ì•¼", "ë°˜ë“œì‹œ"

---

## 8. í˜„ì¬ ì„±ëŠ¥

### 8.1 ì‘ë‹µ ì†ë„

| ì‹œë‚˜ë¦¬ì˜¤ | í‰ê·  ì‘ë‹µ ì‹œê°„ | í‘œì¤€í¸ì°¨ |
|---------|-------------|---------|
| ìºì‹œ ì ì¤‘ | **0.001ì´ˆ** | Â±0.0005ì´ˆ |
| LLM í˜¸ì¶œ | **0.8-1.5ì´ˆ** | Â±0.3ì´ˆ |
| ìŠ¤íŠ¸ë¦¬ë° ì²« í† í° | **0.3-0.6ì´ˆ** | Â±0.2ì´ˆ |

### 8.2 í’ˆì§ˆ ì§€í‘œ

#### í…ŒìŠ¤íŠ¸ ê²°ê³¼ (10ê°œ ë©”ì‹œì§€ ê¸°ì¤€)
- ì¡´ëŒ“ë§ ì¤€ìˆ˜ìœ¨: 80-90%
- ì‘ë‹µ ì ì ˆì„±: 70-80%
- ARS í†¤ ê°ì§€: 10-20%
- ì–´ìƒ‰í•œ í‘œí˜„: 5-10%

### 8.3 ë¹„ìš©

#### API ë¹„ìš© (OpenAI GPT-4o-mini)
- Input: $0.15 / 1M tokens
- Output: $0.60 / 1M tokens
- í‰ê·  ëŒ€í™”: ~50 tokens/íšŒ
- **í‰ê·  ë¹„ìš©**: ~$0.00003/íšŒ

#### ë¹„ìš© ì ˆê° íš¨ê³¼
- ìºì‹± ì—†ìŒ: $0.00004/íšŒ
- ìºì‹± ìˆìŒ: $0.000028/íšŒ
- **ì ˆê°ë¥ **: ~30%

---

## 9. ê°œì„  ì´ë ¥

### 9.1 ì£¼ìš” ê°œì„  ì‚¬í•­

#### 2024-10-27: í”„ë¡¬í”„íŠ¸ ê°œì„ 
- **ë¬¸ì œ**: ARS í†¤, ë³´í˜¸ìê°€ ì•„ë‹Œ ë´‡ ëŠë‚Œ
- **í•´ê²°**: ì—­í•  ëª…í™•í™”, ì¹œê·¼í•œ í†¤ ê°•ì¡°
- **íš¨ê³¼**: ëŒ€í™” í’ˆì§ˆ í–¥ìƒ

#### 2024-10-29: í”„ë¡¬í”„íŠ¸ ì¬ì‘ì„±
- Jerry
- **ë¬¸ì œ**: ì–´ìƒ‰í•œ í•œêµ­ì–´ í‘œí˜„ ("ë³´ìœ¼ì„¸ìš”"), ê³¼ë„í•˜ê²Œ ê¸´ ì‘ë‹µ
- **í•´ê²°**: ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ ì „í™˜, 50ì ì œí•œ ì¶”ê°€
- **íš¨ê³¼**: ìì—°ìŠ¤ëŸ¬ì›€ í–¥ìƒ, ì‘ë‹µ ê¸¸ì´ í†µì œ

#### 2024-10-29: í›„ì²˜ë¦¬ ê°•í™”
- **ì¶”ê°€**: ì–´ìƒ‰í•œ í‘œí˜„ ì°¨ë‹¨, ê¸¸ì´ ì œí•œ, ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±
- **íš¨ê³¼**: í’ˆì§ˆ ì•ˆì •ì„± í–¥ìƒ

---

## 10. ë‹¤ë¥¸ ëª¨ë¸ ë¹„êµ ì¤€ë¹„

### 10.1 ë¹„êµ ëŒ€ìƒ í›„ë³´

#### 1. GPT-4o
- **ì¥ì **: ë” ë‚˜ì€ ì´í•´ë ¥, ì°½ì˜ì„±
- **ë‹¨ì **: ë¹„ìš© 10ë°°, ì†ë„ 2-3ë°° ëŠë¦¼

#### 2. Claude 3 Haiku
- **ì¥ì **: ë¹ ë¥¸ ì†ë„, í•©ë¦¬ì  ë¹„ìš©
- **ë‹¨ì **: í•œêµ­ì–´ ì„±ëŠ¥ ë¶ˆí™•ì‹¤

#### 3. Gemini Pro
- **ì¥ì **: ë¬´ë£Œ tier, ë¹ ë¥¸ ì†ë„
- **ë‹¨ì **: í’ˆì§ˆ ë³€ë™ì„±

#### 4. Llama 3.1 (70B)
- **ì¥ì **: ì˜¨í”„ë ˆë¯¸ìŠ¤ ê°€ëŠ¥, ë¬´ì œí•œ ì‚¬ìš©
- **ë‹¨ì **: í˜¸ìŠ¤íŒ… ë¹„ìš©, í’ˆì§ˆ ë³€ë™ì„±

### 10.2 ë¹„êµ ê¸°ì¤€

#### 1. ì„±ëŠ¥ ì§€í‘œ
```python
metrics = {
    "response_time": [],      # ì‘ë‹µ ì‹œê°„
    "quality_score": [],      # í’ˆì§ˆ ì ìˆ˜ (1-10)
    "cost_per_call": [],      # ë¹„ìš©
    "polite_rate": [],        # ì¡´ëŒ“ë§ ì¤€ìˆ˜ìœ¨
    "warm_tone_rate": [],     # ë”°ëœ»í•œ í†¤ ë¹„ìœ¨
    "cache_hit_rate": []      # ìºì‹œ ì ì¤‘ë¥ 
}
```

#### 2. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
```python
test_cases = [
    "ì•ˆë…•í•˜ì„¸ìš”",
    "ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì•ˆ ì¢‹ì•„ìš”",
    "ìì‹ì´ ì•ˆ ì™”ì–´ìš”",
    "ì™¸ë¡­ë„¤ìš”",
    "TV ê³ ì¥ë‚¬ì–´ìš”",
    "ë³‘ì› ê°€ì•¼ í•´ìš”",
    "ë°¥ ì•ˆ ë¨¹ì—ˆì–´ìš”"
]
```

#### 3. í‰ê°€ ê¸°ì¤€

| í•­ëª© | ê°€ì¤‘ì¹˜ | GPT-4o-mini ê¸°ì¤€ |
|------|-------|----------------|
| ì‘ë‹µ ì†ë„ | 30% | 0.8-1.5ì´ˆ |
| í’ˆì§ˆ ì ìˆ˜ | 40% | 7.5/10 |
| ë¹„ìš© íš¨ìœ¨ | 20% | $0.00003/íšŒ |
| ì•ˆì •ì„± | 10% | 95% |

### 10.3 ì¸¡ì • ë°©ë²•

#### A/B í…ŒìŠ¤íŠ¸
1. ë™ì¼í•œ ì…ë ¥ìœ¼ë¡œ ì—¬ëŸ¬ ëª¨ë¸ í…ŒìŠ¤íŠ¸
2. ì‘ë‹µ ì‹œê°„, í’ˆì§ˆ, ë¹„ìš© ì¸¡ì •
3. í†µê³„ì  ìœ ì˜ì„± ê²€ì¦

#### í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸
1. ì¼ë¶€ ì‚¬ìš©ìì—ê²Œë§Œ ì‹ ê·œ ëª¨ë¸ ì ìš©
2. ì‹¤ì œ ì‚¬ìš© íŒ¨í„´ìœ¼ë¡œ ì¸¡ì •
3. ì‚¬ìš©ì ë§Œì¡±ë„ ì¡°ì‚¬

---

## 11. ì½”ë“œ ë ˆí¼ëŸ°ìŠ¤

### 11.1 ì£¼ìš” ë©”ì„œë“œ

#### `generate_response()`
```python
def generate_response(
    self, 
    user_message: str, 
    conversation_history: list = None, 
    today_schedule: list = None
) -> tuple[str, float]:
    """
    LLM ì‘ë‹µ ìƒì„±
    
    Args:
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        conversation_history: ëŒ€í™” ê¸°ë¡ (ìµœê·¼ 8ê°œ ë©”ì‹œì§€)
        today_schedule: ì˜¤ëŠ˜ ì¼ì • (ìµœëŒ€ 2ê°œ)
    
    Returns:
        tuple: (AI ì‘ë‹µ, ì‹¤í–‰ ì‹œê°„)
    """
```

#### `generate_response_streaming()`
```python
async def generate_response_streaming(
    self, 
    user_message: str, 
    conversation_history: list = None, 
    today_schedule: list = None
) -> AsyncGenerator[str, None]:
    """
    ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ LLM ì‘ë‹µ ìƒì„±
    
    Yields:
        str: ìƒì„±ëœ í…ìŠ¤íŠ¸ ì²­í¬
    """
```

### 11.2 ì„¤ì • íŒŒì¼ ìœ„ì¹˜
- `backend/app/services/ai_call/llm_service.py`: ë©”ì¸ ì„œë¹„ìŠ¤
- `backend/app/services/ai_call/response_cache.py`: ìºì‹±
- `backend/app/config.py`: API í‚¤ ì„¤ì •

---

## 12. í–¥í›„ ê³„íš

### 12.1 ë‹¨ê¸° ê³„íš
- [ ] ë‹¤ë¥¸ ëª¨ë¸ (GPT-4o, Claude 3 Haiku) í…ŒìŠ¤íŠ¸
- [ ] í’ˆì§ˆ ì§€í‘œ ê°œì„  (ì¡´ëŒ“ë§ ì¤€ìˆ˜ìœ¨ 100% ëª©í‘œ)
- [ ] ARS í†¤ ê°ì§€ìœ¨ ê°ì†Œ (< 5%)

### 12.2 ì¤‘ê¸° ê³„íš
- [ ] Fine-tuning ê³ ë ¤ (Custom ëª¨ë¸)
- [ ] ë©€í‹° ëª¨ë¸ ë¼ìš°íŒ… (ë¹ ë¦„/ì •í™•ë„ ì„ íƒ)
- [ ] ëŒ€í™” ë§¥ë½ ê°œì„  (ë” ê¸´ íˆìŠ¤í† ë¦¬ ì§€ì›)

### 12.3 ì¥ê¸° ê³„íš
- [ ] ì˜¨í”„ë ˆë¯¸ìŠ¤ ëª¨ë¸ ê²€í†  (Llama 3.1)
- [ ] ì‹¤ì‹œê°„ ì ì‘ í•™ìŠµ (Active Learning)
- [ ] ê°œì¸í™”ëœ ëŒ€í™” í†¤

---

## ë¶€ë¡: í…ŒìŠ¤íŠ¸ ì½”ë“œ

### A. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
```python
from app.services.ai_call.llm_service import LLMService

llm = LLMService()
response, elapsed = llm.generate_response("ì•ˆë…•í•˜ì„¸ìš”")
print(f"ì‘ë‹µ: {response}")
print(f"ì‹œê°„: {elapsed:.2f}ì´ˆ")
```

### B. ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸
```bash
cd backend
python test_llm.py
# ì˜µì…˜ 2 ì„ íƒ: ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸
```

### C. ìë™ í…ŒìŠ¤íŠ¸
```bash
cd backend
python test_llm.py
# ì˜µì…˜ 1 ì„ íƒ: ìë™ í…ŒìŠ¤íŠ¸ (10ê°œ ë©”ì‹œì§€)
```

---

**ë¬¸ì„œ ì‘ì„±ì¼**: 2024-10-29  
**ì‘ì„±ì**: LLM Team  
**ë²„ì „**: 1.0  
**ë‹¤ìŒ ì—…ë°ì´íŠ¸**: ëª¨ë¸ ë¹„êµ ê²°ê³¼ ë°˜ì˜ ì‹œ


